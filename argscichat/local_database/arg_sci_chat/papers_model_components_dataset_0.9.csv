Doc,Source Idx,Source,Target Idx,Target,Distance,Difference,relation_type
A Multimodal Dataset of Images and Text to Study Abusive Language,0,"1In order to study abusive language online, the availability of datasets containing the linguistic phenomena of interest are of crucial importance.",1,"The dataset is freely available on Github 2 and, since the comments were collected with the written consent of parents and teachers, they can be freely used for research purposes, without the ethical implications that would derive from using real data posted by teenage users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
A Multimodal Dataset of Images and Text to Study Abusive Language,0,"1In order to study abusive language online, the availability of datasets containing the linguistic phenomena of interest are of crucial importance.",2,"Furthermore, while text-only datasets for abusive language detection have been widely developed and used by the NLP community, limitations set by image-based social media platforms like Instagram make it difficult for researchers to experiment with multimodal data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
A Multimodal Dataset of Images and Text to Study Abusive Language,1,"The dataset is freely available on Github 2 and, since the comments were collected with the written consent of parents and teachers, they can be freely used for research purposes, without the ethical implications that would derive from using real data posted by teenage users.",2,"Furthermore, while text-only datasets for abusive language detection have been widely developed and used by the NLP community, limitations set by image-based social media platforms like Instagram make it difficult for researchers to experiment with multimodal data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,0,Readers of academic research papers often read with the goal of answering specific questions.,1,Question Answering systems that can answer those questions can make consumption of the content much more efficient.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,0,Readers of academic research papers often read with the goal of answering specific questions.,2,"In contrast, existing informationseeking question answering datasets usually contain questions about generic factoid-type information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,0,Readers of academic research papers often read with the goal of answering specific questions.,3,"We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F 1 points when answering them from entire papers, motivating further research in document-grounded, information-seeking QA, which our dataset is designed to facilitate.Machines built to assist humans who engage with texts to seek information ought to be designed with an awareness of the information need.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,0,Readers of academic research papers often read with the goal of answering specific questions.,4,"Abstractly, the human's need should define the lens through which the system views the text in order to find desired information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,0,Readers of academic research papers often read with the goal of answering specific questions.,5,"Existing information-seeking machine reading datasets (e.g., Kwiatkowski et al. , 2019; have led to significant progress in reading at scale (e.g., Asai et al. , 2020; Guu et al. , 2020 ;.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,0,Readers of academic research papers often read with the goal of answering specific questions.,6,"However, most of those benchmarks focus on an``open domain""setting where the questions are not anchored in any particular user context.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,0,Readers of academic research papers often read with the goal of answering specific questions.,7,"To the best of our knowledge, QASPER is the first QA dataset in the academic research domain focusing on entire papers, and not just abstracts.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,1,Question Answering systems that can answer those questions can make consumption of the content much more efficient.,2,"In contrast, existing informationseeking question answering datasets usually contain questions about generic factoid-type information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,1,Question Answering systems that can answer those questions can make consumption of the content much more efficient.,3,"We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F 1 points when answering them from entire papers, motivating further research in document-grounded, information-seeking QA, which our dataset is designed to facilitate.Machines built to assist humans who engage with texts to seek information ought to be designed with an awareness of the information need.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,1,Question Answering systems that can answer those questions can make consumption of the content much more efficient.,4,"Abstractly, the human's need should define the lens through which the system views the text in order to find desired information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,1,Question Answering systems that can answer those questions can make consumption of the content much more efficient.,5,"Existing information-seeking machine reading datasets (e.g., Kwiatkowski et al. , 2019; have led to significant progress in reading at scale (e.g., Asai et al. , 2020; Guu et al. , 2020 ;.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,1,Question Answering systems that can answer those questions can make consumption of the content much more efficient.,6,"However, most of those benchmarks focus on an``open domain""setting where the questions are not anchored in any particular user context.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,1,Question Answering systems that can answer those questions can make consumption of the content much more efficient.,7,"To the best of our knowledge, QASPER is the first QA dataset in the academic research domain focusing on entire papers, and not just abstracts.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,2,"In contrast, existing informationseeking question answering datasets usually contain questions about generic factoid-type information.",3,"We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F 1 points when answering them from entire papers, motivating further research in document-grounded, information-seeking QA, which our dataset is designed to facilitate.Machines built to assist humans who engage with texts to seek information ought to be designed with an awareness of the information need.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,2,"In contrast, existing informationseeking question answering datasets usually contain questions about generic factoid-type information.",4,"Abstractly, the human's need should define the lens through which the system views the text in order to find desired information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,2,"In contrast, existing informationseeking question answering datasets usually contain questions about generic factoid-type information.",5,"Existing information-seeking machine reading datasets (e.g., Kwiatkowski et al. , 2019; have led to significant progress in reading at scale (e.g., Asai et al. , 2020; Guu et al. , 2020 ;.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,2,"In contrast, existing informationseeking question answering datasets usually contain questions about generic factoid-type information.",6,"However, most of those benchmarks focus on an``open domain""setting where the questions are not anchored in any particular user context.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,2,"In contrast, existing informationseeking question answering datasets usually contain questions about generic factoid-type information.",7,"To the best of our knowledge, QASPER is the first QA dataset in the academic research domain focusing on entire papers, and not just abstracts.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,3,"We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F 1 points when answering them from entire papers, motivating further research in document-grounded, information-seeking QA, which our dataset is designed to facilitate.Machines built to assist humans who engage with texts to seek information ought to be designed with an awareness of the information need.",4,"Abstractly, the human's need should define the lens through which the system views the text in order to find desired information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,3,"We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F 1 points when answering them from entire papers, motivating further research in document-grounded, information-seeking QA, which our dataset is designed to facilitate.Machines built to assist humans who engage with texts to seek information ought to be designed with an awareness of the information need.",5,"Existing information-seeking machine reading datasets (e.g., Kwiatkowski et al. , 2019; have led to significant progress in reading at scale (e.g., Asai et al. , 2020; Guu et al. , 2020 ;.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,3,"We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F 1 points when answering them from entire papers, motivating further research in document-grounded, information-seeking QA, which our dataset is designed to facilitate.Machines built to assist humans who engage with texts to seek information ought to be designed with an awareness of the information need.",6,"However, most of those benchmarks focus on an``open domain""setting where the questions are not anchored in any particular user context.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,3,"We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F 1 points when answering them from entire papers, motivating further research in document-grounded, information-seeking QA, which our dataset is designed to facilitate.Machines built to assist humans who engage with texts to seek information ought to be designed with an awareness of the information need.",7,"To the best of our knowledge, QASPER is the first QA dataset in the academic research domain focusing on entire papers, and not just abstracts.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,4,"Abstractly, the human's need should define the lens through which the system views the text in order to find desired information.",5,"Existing information-seeking machine reading datasets (e.g., Kwiatkowski et al. , 2019; have led to significant progress in reading at scale (e.g., Asai et al. , 2020; Guu et al. , 2020 ;.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,4,"Abstractly, the human's need should define the lens through which the system views the text in order to find desired information.",6,"However, most of those benchmarks focus on an``open domain""setting where the questions are not anchored in any particular user context.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,4,"Abstractly, the human's need should define the lens through which the system views the text in order to find desired information.",7,"To the best of our knowledge, QASPER is the first QA dataset in the academic research domain focusing on entire papers, and not just abstracts.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,5,"Existing information-seeking machine reading datasets (e.g., Kwiatkowski et al. , 2019; have led to significant progress in reading at scale (e.g., Asai et al. , 2020; Guu et al. , 2020 ;.",6,"However, most of those benchmarks focus on an``open domain""setting where the questions are not anchored in any particular user context.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,5,"Existing information-seeking machine reading datasets (e.g., Kwiatkowski et al. , 2019; have led to significant progress in reading at scale (e.g., Asai et al. , 2020; Guu et al. , 2020 ;.",7,"To the best of our knowledge, QASPER is the first QA dataset in the academic research domain focusing on entire papers, and not just abstracts.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,6,"However, most of those benchmarks focus on an``open domain""setting where the questions are not anchored in any particular user context.",7,"To the best of our knowledge, QASPER is the first QA dataset in the academic research domain focusing on entire papers, and not just abstracts.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Do Language Embeddings Capture Scales?,0,"Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge.",1,One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Do Language Embeddings Capture Scales?,0,"Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge.",2,1 * Both authors contributed equally.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Do Language Embeddings Capture Scales?,0,"Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge.",3,"† Work done during an internship at Google Research.The success of contextualized pretrained Language Models like BERT (Devlin et al. , 2018) and ELMo (Peters et al. , 2018) on tasks like Question Answering and Natural Language Inference, has led to speculation that they are good at Common Sense Reasoning (CSR).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Do Language Embeddings Capture Scales?,0,"Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge.",4,"On one hand, recent work has approached this question by measuring the ability of LMs to answer questions about physical common sense (Bisk et al. , 2020) (`` How to separate egg whites from yolks?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Do Language Embeddings Capture Scales?,0,"Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge.",5,"\""), temporal reasoning (Zhou et al. , 2020) (`` How long does a basketball game take?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Do Language Embeddings Capture Scales?,0,"Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge.",6,"\""), and numerical common sense (Lin et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Do Language Embeddings Capture Scales?,0,"Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge.",7,Figure 1: Scalar probing example.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Do Language Embeddings Capture Scales?,0,"Pretrained Language Models (LMs) have been shown to possess significant linguistic, common sense and factual knowledge.",8,"Given an object (such as a``wedding ring"") and an attribute with continuous numeric values (such as Mass or Price), can an LM's representation of the object predict the value of that attribute?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Do Language Embeddings Capture Scales?,1,One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects.,2,1 * Both authors contributed equally.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Do Language Embeddings Capture Scales?,1,One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects.,3,"† Work done during an internship at Google Research.The success of contextualized pretrained Language Models like BERT (Devlin et al. , 2018) and ELMo (Peters et al. , 2018) on tasks like Question Answering and Natural Language Inference, has led to speculation that they are good at Common Sense Reasoning (CSR).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Do Language Embeddings Capture Scales?,1,One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects.,4,"On one hand, recent work has approached this question by measuring the ability of LMs to answer questions about physical common sense (Bisk et al. , 2020) (`` How to separate egg whites from yolks?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Do Language Embeddings Capture Scales?,1,One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects.,5,"\""), temporal reasoning (Zhou et al. , 2020) (`` How long does a basketball game take?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Do Language Embeddings Capture Scales?,1,One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects.,6,"\""), and numerical common sense (Lin et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Do Language Embeddings Capture Scales?,1,One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects.,7,Figure 1: Scalar probing example.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Do Language Embeddings Capture Scales?,1,One form of knowledge that has not been studied yet in this context is information about the scalar magnitudes of objects.,8,"Given an object (such as a``wedding ring"") and an attribute with continuous numeric values (such as Mass or Price), can an LM's representation of the object predict the value of that attribute?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Do Language Embeddings Capture Scales?,2,1 * Both authors contributed equally.,3,"† Work done during an internship at Google Research.The success of contextualized pretrained Language Models like BERT (Devlin et al. , 2018) and ELMo (Peters et al. , 2018) on tasks like Question Answering and Natural Language Inference, has led to speculation that they are good at Common Sense Reasoning (CSR).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Do Language Embeddings Capture Scales?,2,1 * Both authors contributed equally.,4,"On one hand, recent work has approached this question by measuring the ability of LMs to answer questions about physical common sense (Bisk et al. , 2020) (`` How to separate egg whites from yolks?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Do Language Embeddings Capture Scales?,2,1 * Both authors contributed equally.,5,"\""), temporal reasoning (Zhou et al. , 2020) (`` How long does a basketball game take?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Do Language Embeddings Capture Scales?,2,1 * Both authors contributed equally.,6,"\""), and numerical common sense (Lin et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Do Language Embeddings Capture Scales?,2,1 * Both authors contributed equally.,7,Figure 1: Scalar probing example.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Do Language Embeddings Capture Scales?,2,1 * Both authors contributed equally.,8,"Given an object (such as a``wedding ring"") and an attribute with continuous numeric values (such as Mass or Price), can an LM's representation of the object predict the value of that attribute?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Do Language Embeddings Capture Scales?,3,"† Work done during an internship at Google Research.The success of contextualized pretrained Language Models like BERT (Devlin et al. , 2018) and ELMo (Peters et al. , 2018) on tasks like Question Answering and Natural Language Inference, has led to speculation that they are good at Common Sense Reasoning (CSR).",4,"On one hand, recent work has approached this question by measuring the ability of LMs to answer questions about physical common sense (Bisk et al. , 2020) (`` How to separate egg whites from yolks?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Do Language Embeddings Capture Scales?,3,"† Work done during an internship at Google Research.The success of contextualized pretrained Language Models like BERT (Devlin et al. , 2018) and ELMo (Peters et al. , 2018) on tasks like Question Answering and Natural Language Inference, has led to speculation that they are good at Common Sense Reasoning (CSR).",5,"\""), temporal reasoning (Zhou et al. , 2020) (`` How long does a basketball game take?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Do Language Embeddings Capture Scales?,3,"† Work done during an internship at Google Research.The success of contextualized pretrained Language Models like BERT (Devlin et al. , 2018) and ELMo (Peters et al. , 2018) on tasks like Question Answering and Natural Language Inference, has led to speculation that they are good at Common Sense Reasoning (CSR).",6,"\""), and numerical common sense (Lin et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Do Language Embeddings Capture Scales?,3,"† Work done during an internship at Google Research.The success of contextualized pretrained Language Models like BERT (Devlin et al. , 2018) and ELMo (Peters et al. , 2018) on tasks like Question Answering and Natural Language Inference, has led to speculation that they are good at Common Sense Reasoning (CSR).",7,Figure 1: Scalar probing example.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Do Language Embeddings Capture Scales?,3,"† Work done during an internship at Google Research.The success of contextualized pretrained Language Models like BERT (Devlin et al. , 2018) and ELMo (Peters et al. , 2018) on tasks like Question Answering and Natural Language Inference, has led to speculation that they are good at Common Sense Reasoning (CSR).",8,"Given an object (such as a``wedding ring"") and an attribute with continuous numeric values (such as Mass or Price), can an LM's representation of the object predict the value of that attribute?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Do Language Embeddings Capture Scales?,4,"On one hand, recent work has approached this question by measuring the ability of LMs to answer questions about physical common sense (Bisk et al. , 2020) (`` How to separate egg whites from yolks?",5,"\""), temporal reasoning (Zhou et al. , 2020) (`` How long does a basketball game take?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Do Language Embeddings Capture Scales?,4,"On one hand, recent work has approached this question by measuring the ability of LMs to answer questions about physical common sense (Bisk et al. , 2020) (`` How to separate egg whites from yolks?",6,"\""), and numerical common sense (Lin et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Do Language Embeddings Capture Scales?,4,"On one hand, recent work has approached this question by measuring the ability of LMs to answer questions about physical common sense (Bisk et al. , 2020) (`` How to separate egg whites from yolks?",7,Figure 1: Scalar probing example.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Do Language Embeddings Capture Scales?,4,"On one hand, recent work has approached this question by measuring the ability of LMs to answer questions about physical common sense (Bisk et al. , 2020) (`` How to separate egg whites from yolks?",8,"Given an object (such as a``wedding ring"") and an attribute with continuous numeric values (such as Mass or Price), can an LM's representation of the object predict the value of that attribute?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Do Language Embeddings Capture Scales?,5,"\""), temporal reasoning (Zhou et al. , 2020) (`` How long does a basketball game take?",6,"\""), and numerical common sense (Lin et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Do Language Embeddings Capture Scales?,5,"\""), temporal reasoning (Zhou et al. , 2020) (`` How long does a basketball game take?",7,Figure 1: Scalar probing example.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Do Language Embeddings Capture Scales?,5,"\""), temporal reasoning (Zhou et al. , 2020) (`` How long does a basketball game take?",8,"Given an object (such as a``wedding ring"") and an attribute with continuous numeric values (such as Mass or Price), can an LM's representation of the object predict the value of that attribute?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Do Language Embeddings Capture Scales?,6,"\""), and numerical common sense (Lin et al. , 2020).",7,Figure 1: Scalar probing example.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Do Language Embeddings Capture Scales?,6,"\""), and numerical common sense (Lin et al. , 2020).",8,"Given an object (such as a``wedding ring"") and an attribute with continuous numeric values (such as Mass or Price), can an LM's representation of the object predict the value of that attribute?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Do Language Embeddings Capture Scales?,7,Figure 1: Scalar probing example.,8,"Given an object (such as a``wedding ring"") and an attribute with continuous numeric values (such as Mass or Price), can an LM's representation of the object predict the value of that attribute?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,2,"Thus, there has been a lot of research aiming at automating the process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,3,"Interestingly, previous work has largely ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,9,"Recently, a growing number of claims have been about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,0,The recent explosion of false claims in social media and on the Web in general has given rise to a lot of manual fact-checking initiatives.,16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",2,"Thus, there has been a lot of research aiming at automating the process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",3,"Interestingly, previous work has largely ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",9,"Recently, a growing number of claims have been about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,1,"Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",3,"Interestingly, previous work has largely ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",9,"Recently, a growing number of claims have been about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,2,"Thus, there has been a lot of research aiming at automating the process.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",9,"Recently, a growing number of claims have been about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,3,"Interestingly, previous work has largely ignored the growing number of claims about images.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,9,"Recently, a growing number of claims have been about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,4,This is despite the fact that visual imagery is more influential than text and naturally appears alongside fake news.,16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",9,"Recently, a growing number of claims have been about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,5,"We release our dataset, hoping to enable further research on fact-checking claims about images.As social media become a bigger part of our daily lives, their influence over the way people think and make decisions increases.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",9,"Recently, a growing number of claims have been about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,6,"Inevitably, this has offered opportunities for fake content to arise and to spread faster than ever, e.g., recent research has shown that fake news spreads six time faster than real news (Vosoughi et al. , 2018).",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).",8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).",9,"Recently, a growing number of claims have been about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).",10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).",11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,7,"Sometimes such content is created for pure entertainment or for financial gain from advertisement shown alongside the fake content, but more often and especially recently it has been used to spread disinformation, e.g., with the aim to influence political elections (Atanasov et al. , 2019).",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.",9,"Recently, a growing number of claims have been about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.",10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.",11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,8,"To deal with the problem, a number of manual fact-checking initiatives have been launched, but they remain insufficient to cope with the ever growing number of checkworthy claims.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,9,"Recently, a growing number of claims have been about images.",10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,9,"Recently, a growing number of claims have been about images.",11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,9,"Recently, a growing number of claims have been about images.",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,9,"Recently, a growing number of claims have been about images.",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,9,"Recently, a growing number of claims have been about images.",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,9,"Recently, a growing number of claims have been about images.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,9,"Recently, a growing number of claims have been about images.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.",11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,10,"The word Fauxtography has been used to describe images, especially news photographs, that convey a questionable, or outright false, sense of the events they seem to depict.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).",12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,11,"The term was coined over a decade ago (Cooper , 2007), and there is growing research interest in the topic in the Computer Vision community (Bayar and Stamm , 2016; de Carvalho et al. , 2016).",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.",13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,12,"Given the recent proliferation of fake news, and given that many of the questionable claims are about images, it would be natural to expect similar interest in the Computational Linguistics community, especially given the fact that visual imagery is more influential than text and naturally appears alongside fake news.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.",14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,13,"Yet, computational fact-checking has mostly ignored the growing number of claims about images.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.",15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,14,"6 As we have seen above, there are a number of reasons why an image may be deemed fake.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Fact-Checking Meets Fauxtography: Verifying Claims About Images,15,"In most cases, this involves some kind of digital manipulation, e.g., cropping, splicing, etc.",16,"However, there are cases when an image is completely legitimate, but it is published alongside some text that does not reflect its content accurately.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,9,This is demonstrated on a much larger scale by Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,0,Recent progress in pretraining language models on large corpora has resulted in large performance gains on many NLP tasks.,21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",9,This is demonstrated on a much larger scale by Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,1,"These large models acquire linguistic knowledge during pretraining, which helps to improve performance on downstream tasks via fine-tuning.To assess what kind of knowledge is acquired, language models are commonly probed by querying them with 'fill in the blank' style cloze questions.",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,9,This is demonstrated on a much larger scale by Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,2,Existing probing datasets mainly focus on knowledge about relations between words and entities.,21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",9,This is demonstrated on a much larger scale by Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,3,"In our experiments, three popular pretrained language models struggle to match words and their definitions.",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",9,This is demonstrated on a much larger scale by Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,4,"This indicates that they understand many words poorly and that our new probing task is a difficult challenge that could help guide research on LMs in the future.Natural language processing (NLP) has advanced drastically in the last decade with the design of larger and more sophisticated models, availability of larger corpora and increasing computational power.",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",9,This is demonstrated on a much larger scale by Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,5,"Pretrained word embeddings (Mikolov et al. , 2013; Pennington et al. , 2014) popularized the use of distributed word representations, which became a fundamental building block for NLP systems.",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",9,This is demonstrated on a much larger scale by Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,6,"( 2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on tasks after unsupervised pretraining (Radford et al. , 2018; Howard and Ruder , 2018).",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",9,This is demonstrated on a much larger scale by Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,7,"More recently, the attention based transformer architecture was shown to use context more effectively (Vaswani et al. , 2017) and several subsequent models achieved state of the art results in many NLP tasks by combining the transformer architecture with unsupervised pretraining and task specific fine-tuning (Devlin et al. , 2019; Liu et al. , 2019).",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,9,This is demonstrated on a much larger scale by Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,8,( 2019) showed that language models can be applied to a variety of tasks without task specific fine tuning.,21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,10,Deep models improve performance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,9,This is demonstrated on a much larger scale by Brown et al.,21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,10,Deep models improve performance.,21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,11,"For static word embeddings, researchers used word similarity (Hill et al. , 2015) and word analogy (Gladkova et al. , 2016) tests to shed light on what information is captured in these dense vector spaces.",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).",13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).",14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).",15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).",16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).",17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,12,"For language models, a great amount of linguistic knowledge is stored in the model parameters (Peters et al. , 2018b).",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,13,Several studies proposed using 'fill in the blank' type cloze statements to test knowledge learned by these models during unsupervised pretraining.,21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,14,( 2019) proposed the LAMA (LAnguage Model Analysis) probe to test the factual and common sense knowledge stored in language models.,21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.",16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.",17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,15,"Similarly, Schick and Schütze (2020) introduced WNLaMPro (WordNet Language Model Probing) to assess the ability of language models to understand words based on their frequency.",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,16,The existing probing datasets mainly focus on investigating the knowledge about relations between words or entities.,21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.",18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,17,"However, a more direct way of testing whether a language model understands the meaning of a word is to use its dictionary definition.",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.",19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.",20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,18,"Based on this motivation, we introduce the Word Definition Language Model Probing (WDLMPro) dataset; 1 it is a challenging benchmark for testing NLP models for their ability to understand words.",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,19,WDLMPro is essentially a set of thousands of synset groups; each synset group consists of a target word (with its definition) and its taxonomic sisters (with their definitions).,21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Does He Wink or Does He Nod? A Challenging Benchmark for Evaluating Word Understanding of Language Models,20,"We evaluate two masked language models, BERT and RoBERTa, and the auto-regressive model GPT-2 on WDLMPro using two different probing tests: (i) match definition to word (D2W) (ii) match word to definition (W2D).",21,"We also provide a baseline using static fastText embeddings (Mikolov et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",7,( 2020); Gehrmann et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",8,( 2019) ).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Identifying Automatically Generated Headlines using Transformers,0,"False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",7,( 2020); Gehrmann et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",8,( 2019) ).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Identifying Automatically Generated Headlines using Transformers,1,"However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.Fake content has been rapidly spreading across the internet and social media, misinforming and affecting users' opinion (Kumar and Shah , 2018; Guo et al. , 2020).",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",7,( 2020); Gehrmann et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",8,( 2019) ).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Identifying Automatically Generated Headlines using Transformers,2,"While much of this content is being written by paid writers (Luca and Zervas , 2013), content generated by automated systems is rising.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",7,( 2020); Gehrmann et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",8,( 2019) ).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Identifying Automatically Generated Headlines using Transformers,3,"Models can produce text on a far greater scale than it is possible to manually, with a corresponding increase in the potential to influence public opinion.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",7,( 2020); Gehrmann et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",8,( 2019) ).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Identifying Automatically Generated Headlines using Transformers,4,"There is therefore a need for methods that can distinguish between human and computer-generated text, to filter out deceiving content before it reaches a wider audience.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",7,( 2020); Gehrmann et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",8,( 2019) ).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Identifying Automatically Generated Headlines using Transformers,5,"While text generation models have received consistent attention from the public as well as from the academic community (Dathathri et al. , 2020; Subramanian et al. , 2018), interest in the detection of automatically generated text has only arisen more recently (Jawahar et al. , 2020).",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",7,( 2020); Gehrmann et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",8,( 2019) ).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Identifying Automatically Generated Headlines using Transformers,6,"Generative models have several shortcomings and their output text has characteristics that distinguish it from humanwritten text, including lower variance and smaller vocabulary (Holtzman et al.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,8,( 2019) ).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Identifying Automatically Generated Headlines using Transformers,7,( 2020); Gehrmann et al.,26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,8,( 2019) ).,26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,9,"( 2020) investigated the pitfalls of automatic text generation, showing that sampling methods such as Beam search can lead to low quality and repetitive text.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,10,"Kumar and Shah (2018) compiled a survey on fake content on the internet, providing an overview of how false information targets users and how automatic detection models operate.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,12,( 2018) and Ott et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,11,The sharing of false information is boosted by the natural susceptibility of humans to believe such information.,26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,12,( 2018) and Ott et al.,26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,13,( 2011) reported that humans are able to identify fake content with an accuracy between 50% and 75 %.,26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,14,"Information that is well presented, using long text with limited errors, was shown to deceive the majority of readers.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,16,"( 2020), showing that humans struggle at the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,15,The ability of humans to detect machinegenerated text was evaluated by Dugan et al.,26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,16,"( 2020), showing that humans struggle at the task.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Identifying Automatically Generated Headlines using Transformers,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.",18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,17,"( 2019) showed that automatic text generation models use a more limited vocabulary than humans, tending to avoid low-probability words more often.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Identifying Automatically Generated Headlines using Transformers,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.",19,In Zellers et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.",20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,18,"Consequently, text written by humans tends to exhibit more variation than that generated by models.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Identifying Automatically Generated Headlines using Transformers,19,In Zellers et al.,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,19,In Zellers et al.,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,19,In Zellers et al.,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,19,In Zellers et al.,23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,19,In Zellers et al.,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,19,In Zellers et al.,25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,19,In Zellers et al.,26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Identifying Automatically Generated Headlines using Transformers,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.",21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,20,"( 2019), neural fake news detection and generation are jointly examined in an adversarial setting.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Identifying Automatically Generated Headlines using Transformers,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.",22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,21,"Their model, called Grover, achieves an accuracy of 92% when identifying real from generated news articles.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Identifying Automatically Generated Headlines using Transformers,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.",23,In Brown et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.",24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,22,"Human evaluation though is lacking, so the potential of Grover to fool human readers has not been thoroughly explored.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Identifying Automatically Generated Headlines using Transformers,23,In Brown et al.,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,23,In Brown et al.,25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,23,In Brown et al.,26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Identifying Automatically Generated Headlines using Transformers,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.",25,"The model, though, is prohibitively large to be applied at scale.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Identifying Automatically Generated Headlines using Transformers,24,"( 2020), news articles generated by their largest model (175B parameters) managed to fool humans 48% of the time.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Identifying Automatically Generated Headlines using Transformers,25,"The model, though, is prohibitively large to be applied at scale.",26,"So even though news headlines are a very potent weapon in the hands of fake news spreaders, it has not been yet examined how difficult it is for humans and models to detect machine-generated headlines.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,0,Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB).,1,"It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,0,Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB).,2,"The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,0,Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB).,3,"Existing approaches are mostly inappropriate for this, as they depend on training data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,0,Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB).,4,"In a user study, the annotation speed improves by 35% compared to annotating without interactive support; users report that they strongly prefer our system.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,0,Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB).,5,"An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .Entity linking (EL) describes the task of disambiguating entity mentions in a text by linking them to a knowledge base (KB), e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,0,Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB).,6,"Earl of Cork, thereby disambiguating it.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,0,Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB).,7,"Therefore, entity linking is frequently performed against domainspecific knowledge bases (Munnelly and Lawless , 2018a; Bartsch , 2004).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,0,Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB).,8,"Tools like named entity recognizers are unavailable or perform poorly (Erdmann et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,1,"It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge.",2,"The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,1,"It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge.",3,"Existing approaches are mostly inappropriate for this, as they depend on training data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,1,"It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge.",4,"In a user study, the annotation speed improves by 35% compared to annotating without interactive support; users report that they strongly prefer our system.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,1,"It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge.",5,"An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .Entity linking (EL) describes the task of disambiguating entity mentions in a text by linking them to a knowledge base (KB), e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,1,"It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge.",6,"Earl of Cork, thereby disambiguating it.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,1,"It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge.",7,"Therefore, entity linking is frequently performed against domainspecific knowledge bases (Munnelly and Lawless , 2018a; Bartsch , 2004).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,1,"It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge.",8,"Tools like named entity recognizers are unavailable or perform poorly (Erdmann et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,2,"The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs.",3,"Existing approaches are mostly inappropriate for this, as they depend on training data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,2,"The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs.",4,"In a user study, the annotation speed improves by 35% compared to annotating without interactive support; users report that they strongly prefer our system.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,2,"The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs.",5,"An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .Entity linking (EL) describes the task of disambiguating entity mentions in a text by linking them to a knowledge base (KB), e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,2,"The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs.",6,"Earl of Cork, thereby disambiguating it.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,2,"The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs.",7,"Therefore, entity linking is frequently performed against domainspecific knowledge bases (Munnelly and Lawless , 2018a; Bartsch , 2004).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,2,"The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs.",8,"Tools like named entity recognizers are unavailable or perform poorly (Erdmann et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,3,"Existing approaches are mostly inappropriate for this, as they depend on training data.",4,"In a user study, the annotation speed improves by 35% compared to annotating without interactive support; users report that they strongly prefer our system.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,3,"Existing approaches are mostly inappropriate for this, as they depend on training data.",5,"An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .Entity linking (EL) describes the task of disambiguating entity mentions in a text by linking them to a knowledge base (KB), e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,3,"Existing approaches are mostly inappropriate for this, as they depend on training data.",6,"Earl of Cork, thereby disambiguating it.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,3,"Existing approaches are mostly inappropriate for this, as they depend on training data.",7,"Therefore, entity linking is frequently performed against domainspecific knowledge bases (Munnelly and Lawless , 2018a; Bartsch , 2004).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,3,"Existing approaches are mostly inappropriate for this, as they depend on training data.",8,"Tools like named entity recognizers are unavailable or perform poorly (Erdmann et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,4,"In a user study, the annotation speed improves by 35% compared to annotating without interactive support; users report that they strongly prefer our system.",5,"An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .Entity linking (EL) describes the task of disambiguating entity mentions in a text by linking them to a knowledge base (KB), e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,4,"In a user study, the annotation speed improves by 35% compared to annotating without interactive support; users report that they strongly prefer our system.",6,"Earl of Cork, thereby disambiguating it.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,4,"In a user study, the annotation speed improves by 35% compared to annotating without interactive support; users report that they strongly prefer our system.",7,"Therefore, entity linking is frequently performed against domainspecific knowledge bases (Munnelly and Lawless , 2018a; Bartsch , 2004).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,4,"In a user study, the annotation speed improves by 35% compared to annotating without interactive support; users report that they strongly prefer our system.",8,"Tools like named entity recognizers are unavailable or perform poorly (Erdmann et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,5,"An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .Entity linking (EL) describes the task of disambiguating entity mentions in a text by linking them to a knowledge base (KB), e.g.",6,"Earl of Cork, thereby disambiguating it.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,5,"An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .Entity linking (EL) describes the task of disambiguating entity mentions in a text by linking them to a knowledge base (KB), e.g.",7,"Therefore, entity linking is frequently performed against domainspecific knowledge bases (Munnelly and Lawless , 2018a; Bartsch , 2004).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,5,"An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .Entity linking (EL) describes the task of disambiguating entity mentions in a text by linking them to a knowledge base (KB), e.g.",8,"Tools like named entity recognizers are unavailable or perform poorly (Erdmann et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,6,"Earl of Cork, thereby disambiguating it.",7,"Therefore, entity linking is frequently performed against domainspecific knowledge bases (Munnelly and Lawless , 2018a; Bartsch , 2004).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,6,"Earl of Cork, thereby disambiguating it.",8,"Tools like named entity recognizers are unavailable or perform poorly (Erdmann et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,7,"Therefore, entity linking is frequently performed against domainspecific knowledge bases (Munnelly and Lawless , 2018a; Bartsch , 2004).",8,"Tools like named entity recognizers are unavailable or perform poorly (Erdmann et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,0,"Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs.",1,"Voters, however, seldom read them and often prefer other channels, such as newspaper articles, to understand the party positions on various policy issues.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,0,"Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs.",2,"Ordinary citizens, however, rarely read the manifestos (Budge , 1987; Volkens and Bara , 2013).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,0,"Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs.",3,News articles present the reader with the political claims put forward by different parties and often directly contrast them.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,0,"Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs.",4,Information about claims is routinely used by readers to infer the parties' standpoints.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,0,"Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs.",5,Recent advances in the application of NLP methods to political reporting can reliably extract such claims with models trained on manually annotated claims in newspapers.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,0,"Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs.",6,"colloquial vs. technical terms, as in``sent back""vs.``deport""in Figure 1 c) and d).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,0,"Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs.",7,Section 2) hold.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,0,"Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs.",8,"Third, we extend the scope of our investigation to a concrete application scenario, namely a discourse network analysis of the debate at issue (right panel, Figure 1).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,0,"Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs.",9,"In this perspective, individual actors/parties and claims are two distinct types of vertices that are connected via edges that express support or opposition (Leifeld , 2009 (Leifeld, , 2016.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,1,"Voters, however, seldom read them and often prefer other channels, such as newspaper articles, to understand the party positions on various policy issues.",2,"Ordinary citizens, however, rarely read the manifestos (Budge , 1987; Volkens and Bara , 2013).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,1,"Voters, however, seldom read them and often prefer other channels, such as newspaper articles, to understand the party positions on various policy issues.",3,News articles present the reader with the political claims put forward by different parties and often directly contrast them.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,1,"Voters, however, seldom read them and often prefer other channels, such as newspaper articles, to understand the party positions on various policy issues.",4,Information about claims is routinely used by readers to infer the parties' standpoints.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,1,"Voters, however, seldom read them and often prefer other channels, such as newspaper articles, to understand the party positions on various policy issues.",5,Recent advances in the application of NLP methods to political reporting can reliably extract such claims with models trained on manually annotated claims in newspapers.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,1,"Voters, however, seldom read them and often prefer other channels, such as newspaper articles, to understand the party positions on various policy issues.",6,"colloquial vs. technical terms, as in``sent back""vs.``deport""in Figure 1 c) and d).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,1,"Voters, however, seldom read them and often prefer other channels, such as newspaper articles, to understand the party positions on various policy issues.",7,Section 2) hold.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,1,"Voters, however, seldom read them and often prefer other channels, such as newspaper articles, to understand the party positions on various policy issues.",8,"Third, we extend the scope of our investigation to a concrete application scenario, namely a discourse network analysis of the debate at issue (right panel, Figure 1).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,1,"Voters, however, seldom read them and often prefer other channels, such as newspaper articles, to understand the party positions on various policy issues.",9,"In this perspective, individual actors/parties and claims are two distinct types of vertices that are connected via edges that express support or opposition (Leifeld , 2009 (Leifeld, , 2016.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,2,"Ordinary citizens, however, rarely read the manifestos (Budge , 1987; Volkens and Bara , 2013).",3,News articles present the reader with the political claims put forward by different parties and often directly contrast them.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,2,"Ordinary citizens, however, rarely read the manifestos (Budge , 1987; Volkens and Bara , 2013).",4,Information about claims is routinely used by readers to infer the parties' standpoints.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,2,"Ordinary citizens, however, rarely read the manifestos (Budge , 1987; Volkens and Bara , 2013).",5,Recent advances in the application of NLP methods to political reporting can reliably extract such claims with models trained on manually annotated claims in newspapers.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,2,"Ordinary citizens, however, rarely read the manifestos (Budge , 1987; Volkens and Bara , 2013).",6,"colloquial vs. technical terms, as in``sent back""vs.``deport""in Figure 1 c) and d).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,2,"Ordinary citizens, however, rarely read the manifestos (Budge , 1987; Volkens and Bara , 2013).",7,Section 2) hold.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,2,"Ordinary citizens, however, rarely read the manifestos (Budge , 1987; Volkens and Bara , 2013).",8,"Third, we extend the scope of our investigation to a concrete application scenario, namely a discourse network analysis of the debate at issue (right panel, Figure 1).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,2,"Ordinary citizens, however, rarely read the manifestos (Budge , 1987; Volkens and Bara , 2013).",9,"In this perspective, individual actors/parties and claims are two distinct types of vertices that are connected via edges that express support or opposition (Leifeld , 2009 (Leifeld, , 2016.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,3,News articles present the reader with the political claims put forward by different parties and often directly contrast them.,4,Information about claims is routinely used by readers to infer the parties' standpoints.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,3,News articles present the reader with the political claims put forward by different parties and often directly contrast them.,5,Recent advances in the application of NLP methods to political reporting can reliably extract such claims with models trained on manually annotated claims in newspapers.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,3,News articles present the reader with the political claims put forward by different parties and often directly contrast them.,6,"colloquial vs. technical terms, as in``sent back""vs.``deport""in Figure 1 c) and d).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,3,News articles present the reader with the political claims put forward by different parties and often directly contrast them.,7,Section 2) hold.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,3,News articles present the reader with the political claims put forward by different parties and often directly contrast them.,8,"Third, we extend the scope of our investigation to a concrete application scenario, namely a discourse network analysis of the debate at issue (right panel, Figure 1).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,3,News articles present the reader with the political claims put forward by different parties and often directly contrast them.,9,"In this perspective, individual actors/parties and claims are two distinct types of vertices that are connected via edges that express support or opposition (Leifeld , 2009 (Leifeld, , 2016.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,4,Information about claims is routinely used by readers to infer the parties' standpoints.,5,Recent advances in the application of NLP methods to political reporting can reliably extract such claims with models trained on manually annotated claims in newspapers.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,4,Information about claims is routinely used by readers to infer the parties' standpoints.,6,"colloquial vs. technical terms, as in``sent back""vs.``deport""in Figure 1 c) and d).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,4,Information about claims is routinely used by readers to infer the parties' standpoints.,7,Section 2) hold.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,4,Information about claims is routinely used by readers to infer the parties' standpoints.,8,"Third, we extend the scope of our investigation to a concrete application scenario, namely a discourse network analysis of the debate at issue (right panel, Figure 1).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,4,Information about claims is routinely used by readers to infer the parties' standpoints.,9,"In this perspective, individual actors/parties and claims are two distinct types of vertices that are connected via edges that express support or opposition (Leifeld , 2009 (Leifeld, , 2016.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,5,Recent advances in the application of NLP methods to political reporting can reliably extract such claims with models trained on manually annotated claims in newspapers.,6,"colloquial vs. technical terms, as in``sent back""vs.``deport""in Figure 1 c) and d).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,5,Recent advances in the application of NLP methods to political reporting can reliably extract such claims with models trained on manually annotated claims in newspapers.,7,Section 2) hold.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,5,Recent advances in the application of NLP methods to political reporting can reliably extract such claims with models trained on manually annotated claims in newspapers.,8,"Third, we extend the scope of our investigation to a concrete application scenario, namely a discourse network analysis of the debate at issue (right panel, Figure 1).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,5,Recent advances in the application of NLP methods to political reporting can reliably extract such claims with models trained on manually annotated claims in newspapers.,9,"In this perspective, individual actors/parties and claims are two distinct types of vertices that are connected via edges that express support or opposition (Leifeld , 2009 (Leifeld, , 2016.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,6,"colloquial vs. technical terms, as in``sent back""vs.``deport""in Figure 1 c) and d).",7,Section 2) hold.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,6,"colloquial vs. technical terms, as in``sent back""vs.``deport""in Figure 1 c) and d).",8,"Third, we extend the scope of our investigation to a concrete application scenario, namely a discourse network analysis of the debate at issue (right panel, Figure 1).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,6,"colloquial vs. technical terms, as in``sent back""vs.``deport""in Figure 1 c) and d).",9,"In this perspective, individual actors/parties and claims are two distinct types of vertices that are connected via edges that express support or opposition (Leifeld , 2009 (Leifeld, , 2016.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,7,Section 2) hold.,8,"Third, we extend the scope of our investigation to a concrete application scenario, namely a discourse network analysis of the debate at issue (right panel, Figure 1).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,7,Section 2) hold.,9,"In this perspective, individual actors/parties and claims are two distinct types of vertices that are connected via edges that express support or opposition (Leifeld , 2009 (Leifeld, , 2016.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Swimming with the Tide? Positional Claim Detection across Political Text Types,8,"Third, we extend the scope of our investigation to a concrete application scenario, namely a discourse network analysis of the debate at issue (right panel, Figure 1).",9,"In this perspective, individual actors/parties and claims are two distinct types of vertices that are connected via edges that express support or opposition (Leifeld , 2009 (Leifeld, , 2016.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Argotario: Computational Argumentation Meets Serious Games,0,An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies.,20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Argotario: Computational Argumentation Meets Serious Games,1,"Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion.",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Argotario: Computational Argumentation Meets Serious Games,2,"Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically.",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Argotario: Computational Argumentation Meets Serious Games,3,"The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative.",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Argotario: Computational Argumentation Meets Serious Games,4,"Argumentation theories and critical thinking textbooks, however, offer an alternative view on quality of arguments, namely the notion of fallacies: prototypical argument schemes or types that pretend to be correct and valid arguments but suffer logically, emotionally, or rhetorically (Tindale , 2007; Hamblin , 1970).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Argotario: Computational Argumentation Meets Serious Games,5,"Although this topic was first brought up by Aristotle already some 2,300 years ago, contemporary research on fallacies still does not provide a unifying view and clashes even in the fundamental questions (Boudry et al. , 2015; Paglieri , 2016).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Argotario: Computational Argumentation Meets Serious Games,6,"While understanding the structure of an argument is the predominant task of argument mining/computational argumentation (Mochales and Moens , 2011; Stab and Gurevych , 2014;, a parallel strand of research tries to assess qualitative properties of arguments (Habernal and Gurevych , 2016b; Stab and Gurevych , 2017).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Argotario: Computational Argumentation Meets Serious Games,7,"Yet the gap between theories and everyday argumentation, in understanding what 'argument quality' actually is, remains an open research question (Wachsmuth et al. , 2017; Habernal and Gurevych , 2016a).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,8,"Their powerful and sometimes detrimental impact was revealed in a few manual analyses (Sahlane , 2012; Nieminen and Mustonen , 2014).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,9,"To the best of our knowledge, there is neither any NLP research dealing with fallacies, nor any resources that would allow for empirical investigation of that matter.",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,10,"The lack of fallacy-annotated linguistic resources and thus the need for creating and labeling a new dataset from scratch motivated us to investigate serious games (also games with a purpose) -a scenario in which a task is gamified and users (players) enjoy playing a game without thinking much of the burden of annotations (von Ahn and Dabbish , 2008; Mayer et al. , 2014).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Argotario: Computational Argumentation Meets Serious Games,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,11,The main research contributions and features of Argotario include: • Gamification of the fallacy recognition task including player vs. player interaction • Learning by playing and educational aspects Hamblin (1970) showed that the concept of fallacies as arguments 'that seem to be valid but are not so' deserves to be put under scrutiny.,20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Argotario: Computational Argumentation Meets Serious Games,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).",13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Argotario: Computational Argumentation Meets Serious Games,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,12,"3 Theories about fallacies evolved into various categorizations and treatments, ranging from rather practical education-oriented approaches (Tindale , 2007; Schiappa and Nordin , 2013) to rhetorical ones in informal logic (Walton , 1995) or pragma-dialectic (Van Eemeren and Grootendorst , 1987).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Argotario: Computational Argumentation Meets Serious Games,13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).",14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,13,"For a historical overview of fallacies see, e.g., (Hansen , 2015).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Argotario: Computational Argumentation Meets Serious Games,14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).",15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,14,"Surprisingly, the vast majority of current works on fallacies, and especially textbooks, present only toy examples that one is unlikely to encounter in real life (Boudry et al. , 2015, p. 432).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Argotario: Computational Argumentation Meets Serious Games,15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).",16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,15,"The distinction between fallacies and acceptable inference is fuzzy and theories do not offer any practical guidance: fully-fledged fallacies are harder to find in real life than is commonly assumed (Boudry et al. , 2015).",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Argotario: Computational Argumentation Meets Serious Games,16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.",17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.",18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.",19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,16,"To this account, analysis of fallacies in actual argumentative discourse has been rather limited in scope and size.",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Argotario: Computational Argumentation Meets Serious Games,17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,17,Nieminen and Mustonen (2014) examined fallacies found in articles supporting creationism.,20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Argotario: Computational Argumentation Meets Serious Games,18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Argotario: Computational Argumentation Meets Serious Games,18,Sahlane (2012) manualy analysed fallacies in newswire editorials in major U.S. newspapers before invading Iraq in 2003.,20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Argotario: Computational Argumentation Meets Serious Games,19,"• When scaling up annotations and resource acquisitions, serious games provide an alternative to paid crowdsourcing.",20,"Recent successful applications include knowledge base extension (Vannella et al. , 2014), answering quizes related to medical topics (Ipeirotis and Gabrilovich , 2014), word definition acquisition (Parasca et al. , 2016), or word sense labeling (Venhuizen et al. , 2013); where the latter one resembles a standard annotation task with bonus rewards rather than a traditional entertaining game.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",0,"Despite widespread adoption, machine learning models remain mostly black boxes.",1,"Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",0,"Despite widespread adoption, machine learning models remain mostly black boxes.",2,random forests) and image classification (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",0,"Despite widespread adoption, machine learning models remain mostly black boxes.",3,"We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.Machine learning is at the core of many recent advances in science and technology.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",0,"Despite widespread adoption, machine learning models remain mostly black boxes.",4,"Unfortunately, the important role of humans is an oft-overlooked aspect in the field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",0,"Despite widespread adoption, machine learning models remain mostly black boxes.",5,"whether a user trusts an individual prediction sufficiently to take some action based on it, and (2) trusting a model, i.e.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",0,"Despite widespread adoption, machine learning models remain mostly black boxes.",6,whether the user trusts a model to behave in reasonable ways if deployed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",0,"Despite widespread adoption, machine learning models remain mostly black boxes.",7,"Currently, models are evaluated using accuracy metrics on an available validation dataset.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",1,"Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.",2,random forests) and image classification (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",1,"Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.",3,"We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.Machine learning is at the core of many recent advances in science and technology.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",1,"Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.",4,"Unfortunately, the important role of humans is an oft-overlooked aspect in the field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",1,"Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.",5,"whether a user trusts an individual prediction sufficiently to take some action based on it, and (2) trusting a model, i.e.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",1,"Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.",6,whether the user trusts a model to behave in reasonable ways if deployed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",1,"Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.",7,"Currently, models are evaluated using accuracy metrics on an available validation dataset.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",2,random forests) and image classification (e.g.,3,"We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.Machine learning is at the core of many recent advances in science and technology.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",2,random forests) and image classification (e.g.,4,"Unfortunately, the important role of humans is an oft-overlooked aspect in the field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",2,random forests) and image classification (e.g.,5,"whether a user trusts an individual prediction sufficiently to take some action based on it, and (2) trusting a model, i.e.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",2,random forests) and image classification (e.g.,6,whether the user trusts a model to behave in reasonable ways if deployed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",2,random forests) and image classification (e.g.,7,"Currently, models are evaluated using accuracy metrics on an available validation dataset.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",3,"We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.Machine learning is at the core of many recent advances in science and technology.",4,"Unfortunately, the important role of humans is an oft-overlooked aspect in the field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",3,"We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.Machine learning is at the core of many recent advances in science and technology.",5,"whether a user trusts an individual prediction sufficiently to take some action based on it, and (2) trusting a model, i.e.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",3,"We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.Machine learning is at the core of many recent advances in science and technology.",6,whether the user trusts a model to behave in reasonable ways if deployed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",3,"We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.Machine learning is at the core of many recent advances in science and technology.",7,"Currently, models are evaluated using accuracy metrics on an available validation dataset.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",4,"Unfortunately, the important role of humans is an oft-overlooked aspect in the field.",5,"whether a user trusts an individual prediction sufficiently to take some action based on it, and (2) trusting a model, i.e.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",4,"Unfortunately, the important role of humans is an oft-overlooked aspect in the field.",6,whether the user trusts a model to behave in reasonable ways if deployed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",4,"Unfortunately, the important role of humans is an oft-overlooked aspect in the field.",7,"Currently, models are evaluated using accuracy metrics on an available validation dataset.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",5,"whether a user trusts an individual prediction sufficiently to take some action based on it, and (2) trusting a model, i.e.",6,whether the user trusts a model to behave in reasonable ways if deployed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",5,"whether a user trusts an individual prediction sufficiently to take some action based on it, and (2) trusting a model, i.e.",7,"Currently, models are evaluated using accuracy metrics on an available validation dataset.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
"""Why Should I Trust You?"" Explaining the Predictions of Any Classifier",6,whether the user trusts a model to behave in reasonable ways if deployed.,7,"Currently, models are evaluated using accuracy metrics on an available validation dataset.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",4,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",7,Past research has mainly investigated two approaches to reduce,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,0,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",4,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",7,Past research has mainly investigated two approaches to reduce,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,1,"This can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",4,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",7,Past research has mainly investigated two approaches to reduce,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,2,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,4,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,7,Past research has mainly investigated two approaches to reduce,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,3,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,7,Past research has mainly investigated two approaches to reduce,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,4,2018; Devlin et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",7,Past research has mainly investigated two approaches to reduce,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,5,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",7,Past research has mainly investigated two approaches to reduce,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,6,"However, labels are costly to obtain and require domain experts or a large crowd of non-expert annotators (Snow et al.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,7,Past research has mainly investigated two approaches to reduce,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,8,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,9,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,10,Label suggestions directly target annotators by providing them with suggestions from a pre-trained model.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,11,Although they are capable of effectively reducing the annotation time (Schulz et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,12,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",14,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,13,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,14,2015; Sakaguchi et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",16,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,15,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,16,2020; Rogers 2021).,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,17,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,18,"Annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,19,"1Supervised learning and, consequently, annotated corpora are crucial for many downstream tasks to train and develop well-performing models.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,21,2018; Devlin et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,20,Despite increasing performances of models trained in a semi-or unsupervised fashion (Peters et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,21,2018; Devlin et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,22,"2019), they still substantially benefit from labeled data (Peters, Ruder, and Smith 2019; Gururangan et al.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,23,Active learning assumes that resources for annotating data are limited and aims to reduce the number of labeled instances by only annotating those which contribute most to model training (Lewis and Gale 1994; Settles 2012).,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,24,"This often results in sampled instances that are more difficult to annotate, putting an increased cognitive load on annotators, and potentially leading to a lower agreement or an increased annotation time (Settles, Craven, and Friedland 2008).",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,25,Label suggestions directly target annotators by providing them with suggestions from a pre-trained,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,26,Although they are capable of effectively reducing the annotation time (Schulz et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,27,"2019; Klie, Eckart de Castilho, and Gurevych 2020), they bear the risk of biasing annotators towards the (possibly erroneous) suggested label (Fort and Sagot 2010).",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",29,2015; Sakaguchi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,28,"At the same time, the rising popularity of large-scale datasets that are annotated by non-expert annotators (`` Bowman et al.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,29,2015; Sakaguchi et al.,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,29,2015; Sakaguchi et al.,31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,29,2015; Sakaguchi et al.,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,29,2015; Sakaguchi et al.,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,29,2015; Sakaguchi et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",31,2020; Rogers 2021).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Annotation Curricula to Implicitly Train Non-Expert Annotators,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,30,"2020), further increases the need for better training methods targeting non-expert annotators (Geva, Goldberg, and Berant 2019; Nie et al.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,31,2020; Rogers 2021).,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,31,2020; Rogers 2021).,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,31,2020; Rogers 2021).,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.",33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,32,"Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.",34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Annotation Curricula to Implicitly Train Non-Expert Annotators,33,The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al.,34,"are difficult to annotate, they explicitly emphasize the needs of a human annotator and gradually familiarize them with the annotation task.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Cross-lingual Annotation Projection in Legal Texts,0,"Our results indicate that a combination of word embeddings and dynamic time warping performs best.The European Union considers cultural and linguistic diversity, and in particular multilinguality, as some of its fundamental principles.",1,"So much so, that all the regulations and laws given by the Parliament are published in all of EU's twenty-four official languages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Cross-lingual Annotation Projection in Legal Texts,0,"Our results indicate that a combination of word embeddings and dynamic time warping performs best.The European Union considers cultural and linguistic diversity, and in particular multilinguality, as some of its fundamental principles.",2,"These could be an immense resource towards transparency, egalitarianism, accountability and democracy, giving the EU citizen access to legislative and policy proposals in their own and also in other languages (Steinberger et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Cross-lingual Annotation Projection in Legal Texts,0,"Our results indicate that a combination of word embeddings and dynamic time warping performs best.The European Union considers cultural and linguistic diversity, and in particular multilinguality, as some of its fundamental principles.",3,"Moreover, the vast majority of linguistic resources and tools focus on English.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Cross-lingual Annotation Projection in Legal Texts,0,"Our results indicate that a combination of word embeddings and dynamic time warping performs best.The European Union considers cultural and linguistic diversity, and in particular multilinguality, as some of its fundamental principles.",4,"Likewise, the workforce of professionals needed for annotating legal documents may not be readily available in each language.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Cross-lingual Annotation Projection in Legal Texts,0,"Our results indicate that a combination of word embeddings and dynamic time warping performs best.The European Union considers cultural and linguistic diversity, and in particular multilinguality, as some of its fundamental principles.",5,"Other EU official documents published in multiple languages include, for instance, EU Parliament laws and regulations, documents of the EU Court of Justice, policy documents, documents for public consultations, and so on.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Cross-lingual Annotation Projection in Legal Texts,1,"So much so, that all the regulations and laws given by the Parliament are published in all of EU's twenty-four official languages.",2,"These could be an immense resource towards transparency, egalitarianism, accountability and democracy, giving the EU citizen access to legislative and policy proposals in their own and also in other languages (Steinberger et al. , 2014).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Cross-lingual Annotation Projection in Legal Texts,1,"So much so, that all the regulations and laws given by the Parliament are published in all of EU's twenty-four official languages.",3,"Moreover, the vast majority of linguistic resources and tools focus on English.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Cross-lingual Annotation Projection in Legal Texts,1,"So much so, that all the regulations and laws given by the Parliament are published in all of EU's twenty-four official languages.",4,"Likewise, the workforce of professionals needed for annotating legal documents may not be readily available in each language.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Cross-lingual Annotation Projection in Legal Texts,1,"So much so, that all the regulations and laws given by the Parliament are published in all of EU's twenty-four official languages.",5,"Other EU official documents published in multiple languages include, for instance, EU Parliament laws and regulations, documents of the EU Court of Justice, policy documents, documents for public consultations, and so on.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Cross-lingual Annotation Projection in Legal Texts,2,"These could be an immense resource towards transparency, egalitarianism, accountability and democracy, giving the EU citizen access to legislative and policy proposals in their own and also in other languages (Steinberger et al. , 2014).",3,"Moreover, the vast majority of linguistic resources and tools focus on English.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Cross-lingual Annotation Projection in Legal Texts,2,"These could be an immense resource towards transparency, egalitarianism, accountability and democracy, giving the EU citizen access to legislative and policy proposals in their own and also in other languages (Steinberger et al. , 2014).",4,"Likewise, the workforce of professionals needed for annotating legal documents may not be readily available in each language.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Cross-lingual Annotation Projection in Legal Texts,2,"These could be an immense resource towards transparency, egalitarianism, accountability and democracy, giving the EU citizen access to legislative and policy proposals in their own and also in other languages (Steinberger et al. , 2014).",5,"Other EU official documents published in multiple languages include, for instance, EU Parliament laws and regulations, documents of the EU Court of Justice, policy documents, documents for public consultations, and so on.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Cross-lingual Annotation Projection in Legal Texts,3,"Moreover, the vast majority of linguistic resources and tools focus on English.",4,"Likewise, the workforce of professionals needed for annotating legal documents may not be readily available in each language.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Cross-lingual Annotation Projection in Legal Texts,3,"Moreover, the vast majority of linguistic resources and tools focus on English.",5,"Other EU official documents published in multiple languages include, for instance, EU Parliament laws and regulations, documents of the EU Court of Justice, policy documents, documents for public consultations, and so on.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Cross-lingual Annotation Projection in Legal Texts,4,"Likewise, the workforce of professionals needed for annotating legal documents may not be readily available in each language.",5,"Other EU official documents published in multiple languages include, for instance, EU Parliament laws and regulations, documents of the EU Court of Justice, policy documents, documents for public consultations, and so on.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",5,RL searches for the (near-) optimal trajectories (i.e.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",6,"sequences of decisions) by directly optimising the objective functions, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",7,"the ROUGE metrics [Lin , 2004].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,0,"Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms.",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",5,RL searches for the (near-) optimal trajectories (i.e.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",6,"sequences of decisions) by directly optimising the objective functions, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",7,"the ROUGE metrics [Lin , 2004].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,1,"The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards.",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",5,RL searches for the (near-) optimal trajectories (i.e.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",6,"sequences of decisions) by directly optimising the objective functions, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",7,"the ROUGE metrics [Lin , 2004].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,2,"Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance.",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",5,RL searches for the (near-) optimal trajectories (i.e.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",6,"sequences of decisions) by directly optimising the objective functions, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",7,"the ROUGE metrics [Lin , 2004].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,3,"We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.Extractive document summarization, as a challenging instance of natural language generation (NLG), is a popular summarisation paradigm, which builds summaries by selecting an appropriate sequence of important phrases or sentences from the input document (s).",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",5,RL searches for the (near-) optimal trajectories (i.e.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",6,"sequences of decisions) by directly optimising the objective functions, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",7,"the ROUGE metrics [Lin , 2004].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,4,"Extractive summarisation can be formulated as a sequential decision-making problem, and hence can be tackled by the Reinforcement Learning (RL) algorithms.",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,6,"sequences of decisions) by directly optimising the objective functions, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,7,"the ROUGE metrics [Lin , 2004].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,5,RL searches for the (near-) optimal trajectories (i.e.,18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",7,"the ROUGE metrics [Lin , 2004].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,6,"sequences of decisions) by directly optimising the objective functions, e.g.",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,7,"the ROUGE metrics [Lin , 2004].",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,8,Such objectives are non-differentiable and therefore difficult to be directly optimised by deep neural networks.,18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.",10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.",11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.",12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.",13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,9,"In addition, RL alleviates the exposure bias problem faced by sequential supervised learning paradigms in NLG.",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].",11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].",12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].",13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,10,"performance in summarisation [Narayan et al. , 2018; Yao et al. , 2018].",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,12,For cross-input RL (upper part in Fig.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,11,Existing RL-based summarisation systems fall into two categories: cross-input RL and input-specific RL.,18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,12,For cross-input RL (upper part in Fig.,13,"However, learning such cross-input policies is very expensive because of the huge search space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,12,For cross-input RL (upper part in Fig.,14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,12,For cross-input RL (upper part in Fig.,15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,12,For cross-input RL (upper part in Fig.,16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,12,For cross-input RL (upper part in Fig.,17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,12,For cross-input RL (upper part in Fig.,18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,13,"However, learning such cross-input policies is very expensive because of the huge search space.",14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,13,"However, learning such cross-input policies is very expensive because of the huge search space.",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,13,"However, learning such cross-input policies is very expensive because of the huge search space.",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,13,"However, learning such cross-input policies is very expensive because of the huge search space.",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,13,"However, learning such cross-input policies is very expensive because of the huge search space.",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.",15,input documents and reference summaries for them) nor a reward oracle.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.",16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,14,"Although multiple techniques have been proposed to speed up the training of RL, e.g.",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,15,input documents and reference summaries for them) nor a reward oracle.,16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,15,input documents and reference summaries for them) nor a reward oracle.,17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,15,input documents and reference summaries for them) nor a reward oracle.,18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.",17,translation and sentence simplification.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,16,"RELIS is inspired by inverse RL [Abbeel and Ng , 2004], which requires a demonstrator to present optimal trajectories.",18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,17,translation and sentence simplification.,18,Source code and supplementary material are available at https: //github.com/UKPLab/ijcai2019-relis.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,1,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,4,to accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,8,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",64,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",65,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",66,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",67,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",68,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",69,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",70,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",71,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,0,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",72,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",4,to accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",8,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",64,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",65,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",66,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",67,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",68,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",69,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",70,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,1,"However, a shortcoming of data-driven approaches is poor explainability.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",71,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,4,to accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,8,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",64,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",65,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",66,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",67,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",68,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",69,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,2,We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",70,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",4,to accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",8,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",64,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",65,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",66,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",67,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",68,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,3,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",69,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,8,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",64,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",65,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",66,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",67,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,4,to accept (Obar and Oeldorf-Hirsch 2016).,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",68,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,8,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",64,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",65,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",66,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,5,by supporting the automatic analysis and exposure of unfair ToS clauses (Lippi et al.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",67,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",8,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",64,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",65,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,6,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",66,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,8,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",64,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,7,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",65,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,8,There are good reasons for such a great interest.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",64,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",10,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,9,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",63,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,11,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,10,Consider for instance the following story: Joe went to the kitchen.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",62,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,12,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,11,Fred went to the kitchen.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",61,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,13,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,12,Joe picked up the milk.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",60,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,14,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,13,Joe travelled to the office.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",59,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,15,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,14,Joe left the milk.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",58,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,15,Joe went to the bathroom.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",57,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,16,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",56,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,17,"Such explanations could be especially useful to legal experts and consumers because, rather than aiming to explain an underlying logical model or uncover the role of particular neural network connections, they would be more in line with a dialectical and communicative viewpoint, as advocated by Miller (2019).",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",55,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,18,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",54,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,19,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",53,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,20,", a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",52,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,21,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",51,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,23,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,22,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",50,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,23,"However, a shortcoming of data-driven approaches is poor explainability.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",49,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,24,"language explanations of otherwise opaque classifier outcomes.Terms of service (ToS), also known as terms and conditions or simply terms, are consumer contracts governing the relation between providers and users.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",48,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,25,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",47,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",27,( Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,26,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",46,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,27,( Lippi et al.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",45,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,28,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",44,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,30,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,29,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et al.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",43,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,30,There are good reasons for such a great interest.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",42,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,31,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",41,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,32,outcomes of neural-network classifiers could be enabled by Memory-Augmented Neural Networks or MANNs (Sukhbaatar et al.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",40,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,34,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,33,The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",39,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,35,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,34,Consider for instance the following story: Joe went to the kitchen.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",38,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,36,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,35,Fred went to the kitchen.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",37,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,37,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,36,Joe picked up the milk.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",36,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,38,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,37,Joe travelled to the office.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",35,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,39,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,38,Joe left the milk.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",34,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,40,Answering the question requires comprehension of the,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,39,Joe went to the bathroom.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",33,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,40,Answering the question requires comprehension of the,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",32,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,41,"The list of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",31,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,42,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",30,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,43,"Accordingly, if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,44,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,45,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,46,"of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,47,"We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,48,consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,50,"( 2019), and it gave promising results.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,49,A pilot study on the use of MANN for detecting and explaining unfair clauses in consumer contracts was recently presented by Lagioia et al.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,50,"( 2019), and it gave promising results.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,52,"However, a shortcoming of data-driven approaches is poor explainability.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,51,Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,52,"However, a shortcoming of data-driven approaches is poor explainability.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,53,"Terms that cause a significant imbalance in the parties' rights and obligations, to the detriment of the consumer, are deemed unfair by Consumer Law.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",55,accept (Obar and Oeldorf-Hirsch 2016).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,54,"Despite substantive law in place, and despite the competence of enforcers for abstract control, providers of online services still tend to use unfair and unlawful clauses in these documents (Loos and Luzak 2016; Micklitz et al.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,56,the potentially unfair clauses it contains (Lippi et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,55,accept (Obar and Oeldorf-Hirsch 2016).,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,56,the potentially unfair clauses it contains (Lippi et al.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,57,"Indeed, in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,59,The basic idea behind MANNs is to combine the successful learning,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,58,This adds to the growing concern that data-driven machine-learning systems may exasperate existing biases and social inequalities (O'Neil 2016; Lippi et,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,60,There are good reasons for such a great interest.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,59,The basic idea behind MANNs is to combine the successful learning,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,60,There are good reasons for such a great interest.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",62,Consider for instance the following story: Joe went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,61,"Research in social science suggests that providing explanations for recommended actions deeply influences users' confidence in, and acceptance of, AI-based decisions and recommendations (Cramer et al.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,63,Fred went to the kitchen.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,62,Consider for instance the following story: Joe went to the kitchen.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,63,Fred went to the kitchen.,64,Joe picked up the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,63,Fred went to the kitchen.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,63,Fred went to the kitchen.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,63,Fred went to the kitchen.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,63,Fred went to the kitchen.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,63,Fred went to the kitchen.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,63,Fred went to the kitchen.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,63,Fred went to the kitchen.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,63,Fred went to the kitchen.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,64,Joe picked up the milk.,65,Joe travelled to the office.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,64,Joe picked up the milk.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,64,Joe picked up the milk.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,64,Joe picked up the milk.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,64,Joe picked up the milk.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,64,Joe picked up the milk.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,64,Joe picked up the milk.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,64,Joe picked up the milk.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,65,Joe travelled to the office.,66,Joe left the milk.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,65,Joe travelled to the office.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,65,Joe travelled to the office.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,65,Joe travelled to the office.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,65,Joe travelled to the office.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,65,Joe travelled to the office.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,65,Joe travelled to the office.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,66,Joe left the milk.,67,Joe went to the bathroom.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,66,Joe left the milk.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,66,Joe left the milk.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,66,Joe left the milk.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,66,Joe left the milk.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,66,Joe left the milk.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,67,Joe went to the bathroom.,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,67,Joe went to the bathroom.,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,67,Joe went to the bathroom.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,67,Joe went to the bathroom.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,67,Joe went to the bathroom.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,68,"of memories used to answer a given query, for example``Joe travelled to the office""and``Joe left the milk""constitutes, in a way, an explanation to the answer``The milk is in the kitchen"".",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,69,ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.,72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,70,"Consider for example a unilateral termination clause, giving the provider the right to suspend or terminate the service and/or the contract.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Detecting and explaining unfairness in consumer contracts through memory networks,71,"Indeed, the detection of a``unilateral termination""clause``with 98.8 percent confidence""could be a useful piece of information.",72,"Instead, a more specific rationale such as``the clause mentions the contract or access may be terminated but does not state the grounds for termination""could provide a more compelling argument in that regard.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,0,Position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence.,12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,1,We investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named Rotary Position Embedding (RoPE).,12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,2,"The undergoing experiment for English benchmark will soon be updated.1 A stack of multiple CNN layers can also capture longer intra-token relation, here we only consider single layer setting.The sequential order of words plays a vital role in natural language.",12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,3,Recurrent-based models (RNNs) encode tokens' order by recursively computing a hidden state along the time dimension.,12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.",5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.",6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.",7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.",8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.",9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.",10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.",11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,4,"Convolution-based models (CNNs) [5] were typically considered position-agnostic, but recent work [9] has shown that the commonly used padding operation can implicitly learn position information.",12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].",6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].",7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].",8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].",9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].",10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].",11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,5,"In recent years, the effectiveness of transformer-based models was shown on various natural language processing (NLP) tasks such as context representation learning [4], machine translation [21], and language modeling [16].",12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.",7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.",8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.",9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.",10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.",11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,6,"Unlike recurrent-based and convolution-based models, transformer-based models utilize the self-attention architecture to capture the dependency among tokens in the context, which provides better parallelization than RNNs and can model longer intra-token relations than CNNs.",12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.",8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.",9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.",10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.",11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,7,"1 Since transformer-based models contain no recurrence and no convolution, and the self-attention architecture is shown to be position-agnostic [26], different approaches have been proposed to inject position information into the model.",12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.",9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.",10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.",11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,8,"One line of works focuses on absolute position encoding, where absolute position encoding which are trainable [5 , 4 , 12 , 2 , 16 , 15] or generated by pre-defined function [21] were added to context representations.",12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.",10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.",11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,9,"The other line of works [14 , 18 , 7 , 3 , 25 , 17 , 11 , 6 , 8] focuses on relative position encoding, which typically injects relative position information into the attention calculation.",12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.",11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,10,"In addition to these approaches, [13] has proposed to model the dependency of position encoding from the perspective with Neural ODE [1], and [22] has proposed to model the position information in complex space.",12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING,11,Our contributions are as follows: • We investigate previous works on relative position encoding and find most of them based on the decomposition of adding position encoding to the context representations.,12,We argue that previous relative position encoding approaches are not compatible with linear self-attention and show that RoPE can be used in such mechanism.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,8,There are different settings for QG.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,0,Question Generation (QG) is a Natural Language Processing (NLP) task that aids advances in Question Answering (QA) and conversational assistants.,12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,8,There are different settings for QG.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,1,Existing models focus on generating a question based on a text and possibly the answer to the generated question.,12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,8,There are different settings for QG.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,2,They need to determine the type of interrogative word to be generated while having to pay attention to the grammar and vocabulary of the question.,12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.",4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.",5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.",6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.",7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.",8,There are different settings for QG.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.",9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.",10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.",11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,3,"Owing to an increased recall of deciding the interrogative words to be used for the generated questions, the proposed model achieves new state-of-the-art results on the task of QGQuestion Generation (QG) is the task of creating questions about a text in natural language.",12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).",5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).",6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).",7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).",8,There are different settings for QG.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).",9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).",10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).",11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,4,"One of the reasons for the fast advances in QA capabilities is the creation of large datasets like SQuAD (Rajpurkar et al. , 2016) and TriviaQA (Joshi et al. , 2017).",12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).",6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).",7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).",8,There are different settings for QG.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).",9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).",10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).",11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,5,"ingful QG can play a key role in the advances of QA (Lewis et al. , 2019).",12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,8,There are different settings for QG.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,6,The latter refers to the creation of a natural language question that is grammatically correct and semantically precise.,12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).",8,There are different settings for QG.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).",9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).",10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).",11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,7,"Most of the current approaches utilize sequence-to-sequence models, composed of an encoder model that first transforms a passage into a vector and a decoder model that given this vector, generates a question about the passage (Liu et al. , 2019; Sun et al. , 2018; Zhao et al. , 2018; Pan et al. , 2019).",12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,8,There are different settings for QG.,9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,8,There are different settings for QG.,10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,8,There are different settings for QG.,11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,8,There are different settings for QG.,12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).",10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).",11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,9,"Others follow an answer-aware setting, where the input is a passage and the answer to the question to create (Zhao et al. , 2018).",12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.",11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,10,"For example, a question with a wrong interrogative word for the answer``the owner""is:``what produces a list of requirements for a project? ``.",12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Let Me Know What to Ask: Interrogative-Word-Aware Question Generation,11,"However, with the right interrogative word, who, the question would be:``who produces a list of requirements for a project?",12,"The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Language Models for Lexical Inference in Context,0,"Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.",1,It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Language Models for Lexical Inference in Context,0,"Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.",2,"Consider, e.g., run ⇒ lead in a PERSON / COMPANY context (`` Bezos runs Amazon"") vs. run ⇒ execute in a COMPUTER / SOFTWARE context (`` My mac runs macOS"").","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Language Models for Lexical Inference in Context,0,"Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.",3,"Besides the important use case of evaluating NLI systems, this kind of predicate entailment has also been shown useful for question answering (Schoenmackers et al. , 2010), event coreference (Shwartz et al. , 2017; Meged et al. , 2020), and link prediction in knowledge graphs (Hosseini et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Language Models for Lexical Inference in Context,0,"Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.",4,"Despite its NLI nature, previous systems for LIiC have primarily been models of lexical similarity (Levy and Dagan , 2016) or models based on verb argument inclusion (Hosseini et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Language Models for Lexical Inference in Context,0,"Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.",5,"The reason is probably that supervised NLI models need large amounts of training data, which is unavailable for LIiC, and that systems trained on available large-scale NLI benchmarks (e.g., Williams et al. , 2018) have been reported to insufficiently cover lexical phenomena (Glockner et al. , 2018; Schmitt and Schütze , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Language Models for Lexical Inference in Context,0,"Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.",6,"Recently, transfer learning has become ubiquitous in NLP; Transformer (Vaswani et al. , 2017) language models (LMs) pretrained on large amounts of textual data (?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Language Models for Lexical Inference in Context,0,"Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.",7,"Liu et al. , 2019) form the basis of a lot of current state-of-the-art models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Language Models for Lexical Inference in Context,0,"Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.",8,"Besides zero-and few-shot capabilities (Radford et al. , 2019; Brown et al. , 2020), pretrained LMs have also been found to acquire factual and relational knowledge during pretraining (Petroni et al. , 2019; Bouraoui et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Language Models for Lexical Inference in Context,0,"Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.",9,"( 5) In contrast to previous work on relation induction (Bouraoui et al. , 2020), automatically retrieved patterns do not outperform handcrafted ones for LIiC.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Language Models for Lexical Inference in Context,1,It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.,2,"Consider, e.g., run ⇒ lead in a PERSON / COMPANY context (`` Bezos runs Amazon"") vs. run ⇒ execute in a COMPUTER / SOFTWARE context (`` My mac runs macOS"").","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Language Models for Lexical Inference in Context,1,It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.,3,"Besides the important use case of evaluating NLI systems, this kind of predicate entailment has also been shown useful for question answering (Schoenmackers et al. , 2010), event coreference (Shwartz et al. , 2017; Meged et al. , 2020), and link prediction in knowledge graphs (Hosseini et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Language Models for Lexical Inference in Context,1,It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.,4,"Despite its NLI nature, previous systems for LIiC have primarily been models of lexical similarity (Levy and Dagan , 2016) or models based on verb argument inclusion (Hosseini et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Language Models for Lexical Inference in Context,1,It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.,5,"The reason is probably that supervised NLI models need large amounts of training data, which is unavailable for LIiC, and that systems trained on available large-scale NLI benchmarks (e.g., Williams et al. , 2018) have been reported to insufficiently cover lexical phenomena (Glockner et al. , 2018; Schmitt and Schütze , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Language Models for Lexical Inference in Context,1,It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.,6,"Recently, transfer learning has become ubiquitous in NLP; Transformer (Vaswani et al. , 2017) language models (LMs) pretrained on large amounts of textual data (?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Language Models for Lexical Inference in Context,1,It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.,7,"Liu et al. , 2019) form the basis of a lot of current state-of-the-art models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Language Models for Lexical Inference in Context,1,It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.,8,"Besides zero-and few-shot capabilities (Radford et al. , 2019; Brown et al. , 2020), pretrained LMs have also been found to acquire factual and relational knowledge during pretraining (Petroni et al. , 2019; Bouraoui et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Language Models for Lexical Inference in Context,1,It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.,9,"( 5) In contrast to previous work on relation induction (Bouraoui et al. , 2020), automatically retrieved patterns do not outperform handcrafted ones for LIiC.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Language Models for Lexical Inference in Context,2,"Consider, e.g., run ⇒ lead in a PERSON / COMPANY context (`` Bezos runs Amazon"") vs. run ⇒ execute in a COMPUTER / SOFTWARE context (`` My mac runs macOS"").",3,"Besides the important use case of evaluating NLI systems, this kind of predicate entailment has also been shown useful for question answering (Schoenmackers et al. , 2010), event coreference (Shwartz et al. , 2017; Meged et al. , 2020), and link prediction in knowledge graphs (Hosseini et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Language Models for Lexical Inference in Context,2,"Consider, e.g., run ⇒ lead in a PERSON / COMPANY context (`` Bezos runs Amazon"") vs. run ⇒ execute in a COMPUTER / SOFTWARE context (`` My mac runs macOS"").",4,"Despite its NLI nature, previous systems for LIiC have primarily been models of lexical similarity (Levy and Dagan , 2016) or models based on verb argument inclusion (Hosseini et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Language Models for Lexical Inference in Context,2,"Consider, e.g., run ⇒ lead in a PERSON / COMPANY context (`` Bezos runs Amazon"") vs. run ⇒ execute in a COMPUTER / SOFTWARE context (`` My mac runs macOS"").",5,"The reason is probably that supervised NLI models need large amounts of training data, which is unavailable for LIiC, and that systems trained on available large-scale NLI benchmarks (e.g., Williams et al. , 2018) have been reported to insufficiently cover lexical phenomena (Glockner et al. , 2018; Schmitt and Schütze , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Language Models for Lexical Inference in Context,2,"Consider, e.g., run ⇒ lead in a PERSON / COMPANY context (`` Bezos runs Amazon"") vs. run ⇒ execute in a COMPUTER / SOFTWARE context (`` My mac runs macOS"").",6,"Recently, transfer learning has become ubiquitous in NLP; Transformer (Vaswani et al. , 2017) language models (LMs) pretrained on large amounts of textual data (?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Language Models for Lexical Inference in Context,2,"Consider, e.g., run ⇒ lead in a PERSON / COMPANY context (`` Bezos runs Amazon"") vs. run ⇒ execute in a COMPUTER / SOFTWARE context (`` My mac runs macOS"").",7,"Liu et al. , 2019) form the basis of a lot of current state-of-the-art models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Language Models for Lexical Inference in Context,2,"Consider, e.g., run ⇒ lead in a PERSON / COMPANY context (`` Bezos runs Amazon"") vs. run ⇒ execute in a COMPUTER / SOFTWARE context (`` My mac runs macOS"").",8,"Besides zero-and few-shot capabilities (Radford et al. , 2019; Brown et al. , 2020), pretrained LMs have also been found to acquire factual and relational knowledge during pretraining (Petroni et al. , 2019; Bouraoui et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Language Models for Lexical Inference in Context,2,"Consider, e.g., run ⇒ lead in a PERSON / COMPANY context (`` Bezos runs Amazon"") vs. run ⇒ execute in a COMPUTER / SOFTWARE context (`` My mac runs macOS"").",9,"( 5) In contrast to previous work on relation induction (Bouraoui et al. , 2020), automatically retrieved patterns do not outperform handcrafted ones for LIiC.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Language Models for Lexical Inference in Context,3,"Besides the important use case of evaluating NLI systems, this kind of predicate entailment has also been shown useful for question answering (Schoenmackers et al. , 2010), event coreference (Shwartz et al. , 2017; Meged et al. , 2020), and link prediction in knowledge graphs (Hosseini et al. , 2019).",4,"Despite its NLI nature, previous systems for LIiC have primarily been models of lexical similarity (Levy and Dagan , 2016) or models based on verb argument inclusion (Hosseini et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Language Models for Lexical Inference in Context,3,"Besides the important use case of evaluating NLI systems, this kind of predicate entailment has also been shown useful for question answering (Schoenmackers et al. , 2010), event coreference (Shwartz et al. , 2017; Meged et al. , 2020), and link prediction in knowledge graphs (Hosseini et al. , 2019).",5,"The reason is probably that supervised NLI models need large amounts of training data, which is unavailable for LIiC, and that systems trained on available large-scale NLI benchmarks (e.g., Williams et al. , 2018) have been reported to insufficiently cover lexical phenomena (Glockner et al. , 2018; Schmitt and Schütze , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Language Models for Lexical Inference in Context,3,"Besides the important use case of evaluating NLI systems, this kind of predicate entailment has also been shown useful for question answering (Schoenmackers et al. , 2010), event coreference (Shwartz et al. , 2017; Meged et al. , 2020), and link prediction in knowledge graphs (Hosseini et al. , 2019).",6,"Recently, transfer learning has become ubiquitous in NLP; Transformer (Vaswani et al. , 2017) language models (LMs) pretrained on large amounts of textual data (?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Language Models for Lexical Inference in Context,3,"Besides the important use case of evaluating NLI systems, this kind of predicate entailment has also been shown useful for question answering (Schoenmackers et al. , 2010), event coreference (Shwartz et al. , 2017; Meged et al. , 2020), and link prediction in knowledge graphs (Hosseini et al. , 2019).",7,"Liu et al. , 2019) form the basis of a lot of current state-of-the-art models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Language Models for Lexical Inference in Context,3,"Besides the important use case of evaluating NLI systems, this kind of predicate entailment has also been shown useful for question answering (Schoenmackers et al. , 2010), event coreference (Shwartz et al. , 2017; Meged et al. , 2020), and link prediction in knowledge graphs (Hosseini et al. , 2019).",8,"Besides zero-and few-shot capabilities (Radford et al. , 2019; Brown et al. , 2020), pretrained LMs have also been found to acquire factual and relational knowledge during pretraining (Petroni et al. , 2019; Bouraoui et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Language Models for Lexical Inference in Context,3,"Besides the important use case of evaluating NLI systems, this kind of predicate entailment has also been shown useful for question answering (Schoenmackers et al. , 2010), event coreference (Shwartz et al. , 2017; Meged et al. , 2020), and link prediction in knowledge graphs (Hosseini et al. , 2019).",9,"( 5) In contrast to previous work on relation induction (Bouraoui et al. , 2020), automatically retrieved patterns do not outperform handcrafted ones for LIiC.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Language Models for Lexical Inference in Context,4,"Despite its NLI nature, previous systems for LIiC have primarily been models of lexical similarity (Levy and Dagan , 2016) or models based on verb argument inclusion (Hosseini et al. , 2019).",5,"The reason is probably that supervised NLI models need large amounts of training data, which is unavailable for LIiC, and that systems trained on available large-scale NLI benchmarks (e.g., Williams et al. , 2018) have been reported to insufficiently cover lexical phenomena (Glockner et al. , 2018; Schmitt and Schütze , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Language Models for Lexical Inference in Context,4,"Despite its NLI nature, previous systems for LIiC have primarily been models of lexical similarity (Levy and Dagan , 2016) or models based on verb argument inclusion (Hosseini et al. , 2019).",6,"Recently, transfer learning has become ubiquitous in NLP; Transformer (Vaswani et al. , 2017) language models (LMs) pretrained on large amounts of textual data (?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Language Models for Lexical Inference in Context,4,"Despite its NLI nature, previous systems for LIiC have primarily been models of lexical similarity (Levy and Dagan , 2016) or models based on verb argument inclusion (Hosseini et al. , 2019).",7,"Liu et al. , 2019) form the basis of a lot of current state-of-the-art models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Language Models for Lexical Inference in Context,4,"Despite its NLI nature, previous systems for LIiC have primarily been models of lexical similarity (Levy and Dagan , 2016) or models based on verb argument inclusion (Hosseini et al. , 2019).",8,"Besides zero-and few-shot capabilities (Radford et al. , 2019; Brown et al. , 2020), pretrained LMs have also been found to acquire factual and relational knowledge during pretraining (Petroni et al. , 2019; Bouraoui et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Language Models for Lexical Inference in Context,4,"Despite its NLI nature, previous systems for LIiC have primarily been models of lexical similarity (Levy and Dagan , 2016) or models based on verb argument inclusion (Hosseini et al. , 2019).",9,"( 5) In contrast to previous work on relation induction (Bouraoui et al. , 2020), automatically retrieved patterns do not outperform handcrafted ones for LIiC.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Language Models for Lexical Inference in Context,5,"The reason is probably that supervised NLI models need large amounts of training data, which is unavailable for LIiC, and that systems trained on available large-scale NLI benchmarks (e.g., Williams et al. , 2018) have been reported to insufficiently cover lexical phenomena (Glockner et al. , 2018; Schmitt and Schütze , 2019).",6,"Recently, transfer learning has become ubiquitous in NLP; Transformer (Vaswani et al. , 2017) language models (LMs) pretrained on large amounts of textual data (?","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Language Models for Lexical Inference in Context,5,"The reason is probably that supervised NLI models need large amounts of training data, which is unavailable for LIiC, and that systems trained on available large-scale NLI benchmarks (e.g., Williams et al. , 2018) have been reported to insufficiently cover lexical phenomena (Glockner et al. , 2018; Schmitt and Schütze , 2019).",7,"Liu et al. , 2019) form the basis of a lot of current state-of-the-art models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Language Models for Lexical Inference in Context,5,"The reason is probably that supervised NLI models need large amounts of training data, which is unavailable for LIiC, and that systems trained on available large-scale NLI benchmarks (e.g., Williams et al. , 2018) have been reported to insufficiently cover lexical phenomena (Glockner et al. , 2018; Schmitt and Schütze , 2019).",8,"Besides zero-and few-shot capabilities (Radford et al. , 2019; Brown et al. , 2020), pretrained LMs have also been found to acquire factual and relational knowledge during pretraining (Petroni et al. , 2019; Bouraoui et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Language Models for Lexical Inference in Context,5,"The reason is probably that supervised NLI models need large amounts of training data, which is unavailable for LIiC, and that systems trained on available large-scale NLI benchmarks (e.g., Williams et al. , 2018) have been reported to insufficiently cover lexical phenomena (Glockner et al. , 2018; Schmitt and Schütze , 2019).",9,"( 5) In contrast to previous work on relation induction (Bouraoui et al. , 2020), automatically retrieved patterns do not outperform handcrafted ones for LIiC.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Language Models for Lexical Inference in Context,6,"Recently, transfer learning has become ubiquitous in NLP; Transformer (Vaswani et al. , 2017) language models (LMs) pretrained on large amounts of textual data (?",7,"Liu et al. , 2019) form the basis of a lot of current state-of-the-art models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Language Models for Lexical Inference in Context,6,"Recently, transfer learning has become ubiquitous in NLP; Transformer (Vaswani et al. , 2017) language models (LMs) pretrained on large amounts of textual data (?",8,"Besides zero-and few-shot capabilities (Radford et al. , 2019; Brown et al. , 2020), pretrained LMs have also been found to acquire factual and relational knowledge during pretraining (Petroni et al. , 2019; Bouraoui et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Language Models for Lexical Inference in Context,6,"Recently, transfer learning has become ubiquitous in NLP; Transformer (Vaswani et al. , 2017) language models (LMs) pretrained on large amounts of textual data (?",9,"( 5) In contrast to previous work on relation induction (Bouraoui et al. , 2020), automatically retrieved patterns do not outperform handcrafted ones for LIiC.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Language Models for Lexical Inference in Context,7,"Liu et al. , 2019) form the basis of a lot of current state-of-the-art models.",8,"Besides zero-and few-shot capabilities (Radford et al. , 2019; Brown et al. , 2020), pretrained LMs have also been found to acquire factual and relational knowledge during pretraining (Petroni et al. , 2019; Bouraoui et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Language Models for Lexical Inference in Context,7,"Liu et al. , 2019) form the basis of a lot of current state-of-the-art models.",9,"( 5) In contrast to previous work on relation induction (Bouraoui et al. , 2020), automatically retrieved patterns do not outperform handcrafted ones for LIiC.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Language Models for Lexical Inference in Context,8,"Besides zero-and few-shot capabilities (Radford et al. , 2019; Brown et al. , 2020), pretrained LMs have also been found to acquire factual and relational knowledge during pretraining (Petroni et al. , 2019; Bouraoui et al. , 2020).",9,"( 5) In contrast to previous work on relation induction (Bouraoui et al. , 2020), automatically retrieved patterns do not outperform handcrafted ones for LIiC.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Analyzing Political Parody in Social Media,0,Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts.,1,1 * Equal contribution.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Analyzing Political Parody in Social Media,0,Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts.,2,"Traditional forms of parody include editorial cartoons, sketches or articles pretending to have been authored by the parodied person.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Analyzing Political Parody in Social Media,0,Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts.,3,"A very popular type of parody is political parody which plays an important role in public speech by offering irreverent interpretations of political personas (Hariman , 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Analyzing Political Parody in Social Media,0,Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts.,4,"While closely related figurative devices such as irony and sarcasm have been extensively studied in computational linguistics (Wallace , 2015; Joshi et al. , 2017), parody yet to be explored using computational methods.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Analyzing Political Parody in Social Media,0,Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts.,5,"For example, the Speaker of the US House of Representatives, Nancy Pelosi, falsely cited a Michael Flynn parody tweet; 4 and many users were fooled by a Donald Trump parody tweet about 'Dow Joans'.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Analyzing Political Parody in Social Media,0,Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts.,6,"5 Thus, accurate parody classification methods can be useful in downstream NLP applications such as automatic fact checking (Vlachos and Riedel , 2014) and rumour verification (Karmakharm et al. , 2019), sentiment analysis (Pang et al. , 2008) or nowcasting voting intention (Tumasjan et al. , 2010; Lampos et al. , 2013; Tsakalidis et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Analyzing Political Parody in Social Media,0,Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts.,7,"Beyond NLP, parody detection can be used in: (i) political communication, to study and understand the effects of political parody in the public speech on a large scale (Hariman , 2008; Highfield , 2016); (ii) linguistics, to identify characteristics of figurative language (Rose , 1993; Kreuz and Roberts , 1993; Rossen-Knill and Henry , 1997); (iii) network science, to identify the adoption and diffusion mechanisms of parody (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Analyzing Political Parody in Social Media,1,1 * Equal contribution.,2,"Traditional forms of parody include editorial cartoons, sketches or articles pretending to have been authored by the parodied person.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Analyzing Political Parody in Social Media,1,1 * Equal contribution.,3,"A very popular type of parody is political parody which plays an important role in public speech by offering irreverent interpretations of political personas (Hariman , 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Analyzing Political Parody in Social Media,1,1 * Equal contribution.,4,"While closely related figurative devices such as irony and sarcasm have been extensively studied in computational linguistics (Wallace , 2015; Joshi et al. , 2017), parody yet to be explored using computational methods.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Analyzing Political Parody in Social Media,1,1 * Equal contribution.,5,"For example, the Speaker of the US House of Representatives, Nancy Pelosi, falsely cited a Michael Flynn parody tweet; 4 and many users were fooled by a Donald Trump parody tweet about 'Dow Joans'.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Analyzing Political Parody in Social Media,1,1 * Equal contribution.,6,"5 Thus, accurate parody classification methods can be useful in downstream NLP applications such as automatic fact checking (Vlachos and Riedel , 2014) and rumour verification (Karmakharm et al. , 2019), sentiment analysis (Pang et al. , 2008) or nowcasting voting intention (Tumasjan et al. , 2010; Lampos et al. , 2013; Tsakalidis et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Analyzing Political Parody in Social Media,1,1 * Equal contribution.,7,"Beyond NLP, parody detection can be used in: (i) political communication, to study and understand the effects of political parody in the public speech on a large scale (Hariman , 2008; Highfield , 2016); (ii) linguistics, to identify characteristics of figurative language (Rose , 1993; Kreuz and Roberts , 1993; Rossen-Knill and Henry , 1997); (iii) network science, to identify the adoption and diffusion mechanisms of parody (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Analyzing Political Parody in Social Media,2,"Traditional forms of parody include editorial cartoons, sketches or articles pretending to have been authored by the parodied person.",3,"A very popular type of parody is political parody which plays an important role in public speech by offering irreverent interpretations of political personas (Hariman , 2008).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Analyzing Political Parody in Social Media,2,"Traditional forms of parody include editorial cartoons, sketches or articles pretending to have been authored by the parodied person.",4,"While closely related figurative devices such as irony and sarcasm have been extensively studied in computational linguistics (Wallace , 2015; Joshi et al. , 2017), parody yet to be explored using computational methods.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Analyzing Political Parody in Social Media,2,"Traditional forms of parody include editorial cartoons, sketches or articles pretending to have been authored by the parodied person.",5,"For example, the Speaker of the US House of Representatives, Nancy Pelosi, falsely cited a Michael Flynn parody tweet; 4 and many users were fooled by a Donald Trump parody tweet about 'Dow Joans'.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Analyzing Political Parody in Social Media,2,"Traditional forms of parody include editorial cartoons, sketches or articles pretending to have been authored by the parodied person.",6,"5 Thus, accurate parody classification methods can be useful in downstream NLP applications such as automatic fact checking (Vlachos and Riedel , 2014) and rumour verification (Karmakharm et al. , 2019), sentiment analysis (Pang et al. , 2008) or nowcasting voting intention (Tumasjan et al. , 2010; Lampos et al. , 2013; Tsakalidis et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Analyzing Political Parody in Social Media,2,"Traditional forms of parody include editorial cartoons, sketches or articles pretending to have been authored by the parodied person.",7,"Beyond NLP, parody detection can be used in: (i) political communication, to study and understand the effects of political parody in the public speech on a large scale (Hariman , 2008; Highfield , 2016); (ii) linguistics, to identify characteristics of figurative language (Rose , 1993; Kreuz and Roberts , 1993; Rossen-Knill and Henry , 1997); (iii) network science, to identify the adoption and diffusion mechanisms of parody (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Analyzing Political Parody in Social Media,3,"A very popular type of parody is political parody which plays an important role in public speech by offering irreverent interpretations of political personas (Hariman , 2008).",4,"While closely related figurative devices such as irony and sarcasm have been extensively studied in computational linguistics (Wallace , 2015; Joshi et al. , 2017), parody yet to be explored using computational methods.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Analyzing Political Parody in Social Media,3,"A very popular type of parody is political parody which plays an important role in public speech by offering irreverent interpretations of political personas (Hariman , 2008).",5,"For example, the Speaker of the US House of Representatives, Nancy Pelosi, falsely cited a Michael Flynn parody tweet; 4 and many users were fooled by a Donald Trump parody tweet about 'Dow Joans'.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Analyzing Political Parody in Social Media,3,"A very popular type of parody is political parody which plays an important role in public speech by offering irreverent interpretations of political personas (Hariman , 2008).",6,"5 Thus, accurate parody classification methods can be useful in downstream NLP applications such as automatic fact checking (Vlachos and Riedel , 2014) and rumour verification (Karmakharm et al. , 2019), sentiment analysis (Pang et al. , 2008) or nowcasting voting intention (Tumasjan et al. , 2010; Lampos et al. , 2013; Tsakalidis et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Analyzing Political Parody in Social Media,3,"A very popular type of parody is political parody which plays an important role in public speech by offering irreverent interpretations of political personas (Hariman , 2008).",7,"Beyond NLP, parody detection can be used in: (i) political communication, to study and understand the effects of political parody in the public speech on a large scale (Hariman , 2008; Highfield , 2016); (ii) linguistics, to identify characteristics of figurative language (Rose , 1993; Kreuz and Roberts , 1993; Rossen-Knill and Henry , 1997); (iii) network science, to identify the adoption and diffusion mechanisms of parody (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Analyzing Political Parody in Social Media,4,"While closely related figurative devices such as irony and sarcasm have been extensively studied in computational linguistics (Wallace , 2015; Joshi et al. , 2017), parody yet to be explored using computational methods.",5,"For example, the Speaker of the US House of Representatives, Nancy Pelosi, falsely cited a Michael Flynn parody tweet; 4 and many users were fooled by a Donald Trump parody tweet about 'Dow Joans'.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Analyzing Political Parody in Social Media,4,"While closely related figurative devices such as irony and sarcasm have been extensively studied in computational linguistics (Wallace , 2015; Joshi et al. , 2017), parody yet to be explored using computational methods.",6,"5 Thus, accurate parody classification methods can be useful in downstream NLP applications such as automatic fact checking (Vlachos and Riedel , 2014) and rumour verification (Karmakharm et al. , 2019), sentiment analysis (Pang et al. , 2008) or nowcasting voting intention (Tumasjan et al. , 2010; Lampos et al. , 2013; Tsakalidis et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Analyzing Political Parody in Social Media,4,"While closely related figurative devices such as irony and sarcasm have been extensively studied in computational linguistics (Wallace , 2015; Joshi et al. , 2017), parody yet to be explored using computational methods.",7,"Beyond NLP, parody detection can be used in: (i) political communication, to study and understand the effects of political parody in the public speech on a large scale (Hariman , 2008; Highfield , 2016); (ii) linguistics, to identify characteristics of figurative language (Rose , 1993; Kreuz and Roberts , 1993; Rossen-Knill and Henry , 1997); (iii) network science, to identify the adoption and diffusion mechanisms of parody (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Analyzing Political Parody in Social Media,5,"For example, the Speaker of the US House of Representatives, Nancy Pelosi, falsely cited a Michael Flynn parody tweet; 4 and many users were fooled by a Donald Trump parody tweet about 'Dow Joans'.",6,"5 Thus, accurate parody classification methods can be useful in downstream NLP applications such as automatic fact checking (Vlachos and Riedel , 2014) and rumour verification (Karmakharm et al. , 2019), sentiment analysis (Pang et al. , 2008) or nowcasting voting intention (Tumasjan et al. , 2010; Lampos et al. , 2013; Tsakalidis et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Analyzing Political Parody in Social Media,5,"For example, the Speaker of the US House of Representatives, Nancy Pelosi, falsely cited a Michael Flynn parody tweet; 4 and many users were fooled by a Donald Trump parody tweet about 'Dow Joans'.",7,"Beyond NLP, parody detection can be used in: (i) political communication, to study and understand the effects of political parody in the public speech on a large scale (Hariman , 2008; Highfield , 2016); (ii) linguistics, to identify characteristics of figurative language (Rose , 1993; Kreuz and Roberts , 1993; Rossen-Knill and Henry , 1997); (iii) network science, to identify the adoption and diffusion mechanisms of parody (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Analyzing Political Parody in Social Media,6,"5 Thus, accurate parody classification methods can be useful in downstream NLP applications such as automatic fact checking (Vlachos and Riedel , 2014) and rumour verification (Karmakharm et al. , 2019), sentiment analysis (Pang et al. , 2008) or nowcasting voting intention (Tumasjan et al. , 2010; Lampos et al. , 2013; Tsakalidis et al. , 2018).",7,"Beyond NLP, parody detection can be used in: (i) political communication, to study and understand the effects of political parody in the public speech on a large scale (Hariman , 2008; Highfield , 2016); (ii) linguistics, to identify characteristics of figurative language (Rose , 1993; Kreuz and Roberts , 1993; Rossen-Knill and Henry , 1997); (iii) network science, to identify the adoption and diffusion mechanisms of parody (Vosoughi et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,1,By definition a Transformer is invariant with respect to reorderings of the input.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,9,"Similarly, many papers analyze and compare a subset of position embedding variants.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,0,Transformers are arguably the main workhorse in recent Natural Language Processing research.,10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,1,By definition a Transformer is invariant with respect to reorderings of the input.,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,1,By definition a Transformer is invariant with respect to reorderings of the input.,3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,1,By definition a Transformer is invariant with respect to reorderings of the input.,4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,1,By definition a Transformer is invariant with respect to reorderings of the input.,5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,1,By definition a Transformer is invariant with respect to reorderings of the input.,6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,1,By definition a Transformer is invariant with respect to reorderings of the input.,7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,1,By definition a Transformer is invariant with respect to reorderings of the input.,8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,1,By definition a Transformer is invariant with respect to reorderings of the input.,9,"Similarly, many papers analyze and compare a subset of position embedding variants.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,1,By definition a Transformer is invariant with respect to reorderings of the input.,10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.",3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.",4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.",5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.",6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.",7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.",8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.",9,"Similarly, many papers analyze and compare a subset of position embedding variants.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,2,"However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance.",10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.",4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.",5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.",6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.",7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.",8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.",9,"Similarly, many papers analyze and compare a subset of position embedding variants.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,3,"In this paper, we provide an overview of common methods to incorporate position information into Transformer models.",10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.",5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.",6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.",7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.",8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.",9,"Similarly, many papers analyze and compare a subset of position embedding variants.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,4,"With the rise of pretrained language models (PLMs) (Peters et al. , 2018; Howard & Ruder , 2018; Devlin et al. , 2019; Brown et al. , 2020) Transformer models have become even more popular.",10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).",6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).",7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).",8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).",9,"Similarly, many papers analyze and compare a subset of position embedding variants.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,5,"Without position information the meaning of a sentence is not well-defined (e.g., the sequence``the cat chases the dog""vs. the multi-set {the, the, dog, chases, cat} ).",10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.",7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.",8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.",9,"Similarly, many papers analyze and compare a subset of position embedding variants.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,6,"Therefore, there is a range of different methods to incorporate position information into NLP models, especially PLMs that are based on Transformer models.",10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.",8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.",9,"Similarly, many papers analyze and compare a subset of position embedding variants.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,7,"Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.",10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,9,"Similarly, many papers analyze and compare a subset of position embedding variants.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,8,Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.,10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Work in progress POSITION INFORMATION IN TRANSFORMERS: AN OVERVIEW,9,"Similarly, many papers analyze and compare a subset of position embedding variants.",10,The objective of this paper is to provide an overview of methods that incorporate and analyze position information in Transformer models.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,0,"Broadly speaking, existing methods either approach argument mining from the discourse-level perspective (aiming to analyze local argumentation structures), or from an information-seeking perspective (aiming to detect arguments relevant to a predefined topic).",1,"While discourse-level approaches mostly focus on the analysis of single documents or document collections (Eger et al. , 2017), information-seeking approaches need to be capable of dealing with heterogeneous sources and topics (Shnarch et al. , 2018) and also face the problem of redundancy, as arguments might be repeated across sources.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,0,"Broadly speaking, existing methods either approach argument mining from the discourse-level perspective (aiming to analyze local argumentation structures), or from an information-seeking perspective (aiming to detect arguments relevant to a predefined topic).",2,Identifying arguments for unseen topics is a challenging task for machine learning systems.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,0,"Broadly speaking, existing methods either approach argument mining from the discourse-level perspective (aiming to analyze local argumentation structures), or from an information-seeking perspective (aiming to detect arguments relevant to a predefined topic).",3,"The lexical appearance for two topics, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,0,"Broadly speaking, existing methods either approach argument mining from the discourse-level perspective (aiming to analyze local argumentation structures), or from an information-seeking perspective (aiming to detect arguments relevant to a predefined topic).",4,"\"" net neutrality""and``school uniforms"", is vastly different.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,0,"Broadly speaking, existing methods either approach argument mining from the discourse-level perspective (aiming to analyze local argumentation structures), or from an information-seeking perspective (aiming to detect arguments relevant to a predefined topic).",5,"A1 The ultimate goal is fast, affordable, open Internet access for everyone, everywhere.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,0,"Broadly speaking, existing methods either approach argument mining from the discourse-level perspective (aiming to analyze local argumentation structures), or from an information-seeking perspective (aiming to detect arguments relevant to a predefined topic).",6,"GloVe (Pennington et al. , 2014), these methods compute the embeddings for a sentence on the fly by taking the context of a target word into account.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,0,"Broadly speaking, existing methods either approach argument mining from the discourse-level perspective (aiming to analyze local argumentation structures), or from an information-seeking perspective (aiming to detect arguments relevant to a predefined topic).",7,"In cross-topic scenarios, with which we are dealing in open-domain argument search, contextualized representations need to be able to adapt to new, unseen textual topics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,0,"Broadly speaking, existing methods either approach argument mining from the discourse-level perspective (aiming to analyze local argumentation structures), or from an information-seeking perspective (aiming to detect arguments relevant to a predefined topic).",8,( 2018b) and the IBM Debater R: Evidence Sentences corpus by Shnarch et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,0,"Broadly speaking, existing methods either approach argument mining from the discourse-level perspective (aiming to analyze local argumentation structures), or from an information-seeking perspective (aiming to detect arguments relevant to a predefined topic).",9,"For argument clustering, we introduce a novel corpus on aspect-based argument clustering and evaluate the proposed methods on this corpus as well as on the Argument Facet Similarity Corpus (Misra et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,1,"While discourse-level approaches mostly focus on the analysis of single documents or document collections (Eger et al. , 2017), information-seeking approaches need to be capable of dealing with heterogeneous sources and topics (Shnarch et al. , 2018) and also face the problem of redundancy, as arguments might be repeated across sources.",2,Identifying arguments for unseen topics is a challenging task for machine learning systems.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,1,"While discourse-level approaches mostly focus on the analysis of single documents or document collections (Eger et al. , 2017), information-seeking approaches need to be capable of dealing with heterogeneous sources and topics (Shnarch et al. , 2018) and also face the problem of redundancy, as arguments might be repeated across sources.",3,"The lexical appearance for two topics, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,1,"While discourse-level approaches mostly focus on the analysis of single documents or document collections (Eger et al. , 2017), information-seeking approaches need to be capable of dealing with heterogeneous sources and topics (Shnarch et al. , 2018) and also face the problem of redundancy, as arguments might be repeated across sources.",4,"\"" net neutrality""and``school uniforms"", is vastly different.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,1,"While discourse-level approaches mostly focus on the analysis of single documents or document collections (Eger et al. , 2017), information-seeking approaches need to be capable of dealing with heterogeneous sources and topics (Shnarch et al. , 2018) and also face the problem of redundancy, as arguments might be repeated across sources.",5,"A1 The ultimate goal is fast, affordable, open Internet access for everyone, everywhere.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,1,"While discourse-level approaches mostly focus on the analysis of single documents or document collections (Eger et al. , 2017), information-seeking approaches need to be capable of dealing with heterogeneous sources and topics (Shnarch et al. , 2018) and also face the problem of redundancy, as arguments might be repeated across sources.",6,"GloVe (Pennington et al. , 2014), these methods compute the embeddings for a sentence on the fly by taking the context of a target word into account.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,1,"While discourse-level approaches mostly focus on the analysis of single documents or document collections (Eger et al. , 2017), information-seeking approaches need to be capable of dealing with heterogeneous sources and topics (Shnarch et al. , 2018) and also face the problem of redundancy, as arguments might be repeated across sources.",7,"In cross-topic scenarios, with which we are dealing in open-domain argument search, contextualized representations need to be able to adapt to new, unseen textual topics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,1,"While discourse-level approaches mostly focus on the analysis of single documents or document collections (Eger et al. , 2017), information-seeking approaches need to be capable of dealing with heterogeneous sources and topics (Shnarch et al. , 2018) and also face the problem of redundancy, as arguments might be repeated across sources.",8,( 2018b) and the IBM Debater R: Evidence Sentences corpus by Shnarch et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,1,"While discourse-level approaches mostly focus on the analysis of single documents or document collections (Eger et al. , 2017), information-seeking approaches need to be capable of dealing with heterogeneous sources and topics (Shnarch et al. , 2018) and also face the problem of redundancy, as arguments might be repeated across sources.",9,"For argument clustering, we introduce a novel corpus on aspect-based argument clustering and evaluate the proposed methods on this corpus as well as on the Argument Facet Similarity Corpus (Misra et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,2,Identifying arguments for unseen topics is a challenging task for machine learning systems.,3,"The lexical appearance for two topics, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,2,Identifying arguments for unseen topics is a challenging task for machine learning systems.,4,"\"" net neutrality""and``school uniforms"", is vastly different.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,2,Identifying arguments for unseen topics is a challenging task for machine learning systems.,5,"A1 The ultimate goal is fast, affordable, open Internet access for everyone, everywhere.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,2,Identifying arguments for unseen topics is a challenging task for machine learning systems.,6,"GloVe (Pennington et al. , 2014), these methods compute the embeddings for a sentence on the fly by taking the context of a target word into account.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,2,Identifying arguments for unseen topics is a challenging task for machine learning systems.,7,"In cross-topic scenarios, with which we are dealing in open-domain argument search, contextualized representations need to be able to adapt to new, unseen textual topics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,2,Identifying arguments for unseen topics is a challenging task for machine learning systems.,8,( 2018b) and the IBM Debater R: Evidence Sentences corpus by Shnarch et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,2,Identifying arguments for unseen topics is a challenging task for machine learning systems.,9,"For argument clustering, we introduce a novel corpus on aspect-based argument clustering and evaluate the proposed methods on this corpus as well as on the Argument Facet Similarity Corpus (Misra et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,3,"The lexical appearance for two topics, e.g.",4,"\"" net neutrality""and``school uniforms"", is vastly different.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Classification and Clustering of Arguments with Contextualized Word Embeddings,3,"The lexical appearance for two topics, e.g.",5,"A1 The ultimate goal is fast, affordable, open Internet access for everyone, everywhere.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,3,"The lexical appearance for two topics, e.g.",6,"GloVe (Pennington et al. , 2014), these methods compute the embeddings for a sentence on the fly by taking the context of a target word into account.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,3,"The lexical appearance for two topics, e.g.",7,"In cross-topic scenarios, with which we are dealing in open-domain argument search, contextualized representations need to be able to adapt to new, unseen textual topics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,3,"The lexical appearance for two topics, e.g.",8,( 2018b) and the IBM Debater R: Evidence Sentences corpus by Shnarch et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,3,"The lexical appearance for two topics, e.g.",9,"For argument clustering, we introduce a novel corpus on aspect-based argument clustering and evaluate the proposed methods on this corpus as well as on the Argument Facet Similarity Corpus (Misra et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,4,"\"" net neutrality""and``school uniforms"", is vastly different.",5,"A1 The ultimate goal is fast, affordable, open Internet access for everyone, everywhere.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,4,"\"" net neutrality""and``school uniforms"", is vastly different.",6,"GloVe (Pennington et al. , 2014), these methods compute the embeddings for a sentence on the fly by taking the context of a target word into account.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,4,"\"" net neutrality""and``school uniforms"", is vastly different.",7,"In cross-topic scenarios, with which we are dealing in open-domain argument search, contextualized representations need to be able to adapt to new, unseen textual topics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,4,"\"" net neutrality""and``school uniforms"", is vastly different.",8,( 2018b) and the IBM Debater R: Evidence Sentences corpus by Shnarch et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,4,"\"" net neutrality""and``school uniforms"", is vastly different.",9,"For argument clustering, we introduce a novel corpus on aspect-based argument clustering and evaluate the proposed methods on this corpus as well as on the Argument Facet Similarity Corpus (Misra et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,5,"A1 The ultimate goal is fast, affordable, open Internet access for everyone, everywhere.",6,"GloVe (Pennington et al. , 2014), these methods compute the embeddings for a sentence on the fly by taking the context of a target word into account.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,5,"A1 The ultimate goal is fast, affordable, open Internet access for everyone, everywhere.",7,"In cross-topic scenarios, with which we are dealing in open-domain argument search, contextualized representations need to be able to adapt to new, unseen textual topics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,5,"A1 The ultimate goal is fast, affordable, open Internet access for everyone, everywhere.",8,( 2018b) and the IBM Debater R: Evidence Sentences corpus by Shnarch et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,5,"A1 The ultimate goal is fast, affordable, open Internet access for everyone, everywhere.",9,"For argument clustering, we introduce a novel corpus on aspect-based argument clustering and evaluate the proposed methods on this corpus as well as on the Argument Facet Similarity Corpus (Misra et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,6,"GloVe (Pennington et al. , 2014), these methods compute the embeddings for a sentence on the fly by taking the context of a target word into account.",7,"In cross-topic scenarios, with which we are dealing in open-domain argument search, contextualized representations need to be able to adapt to new, unseen textual topics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,6,"GloVe (Pennington et al. , 2014), these methods compute the embeddings for a sentence on the fly by taking the context of a target word into account.",8,( 2018b) and the IBM Debater R: Evidence Sentences corpus by Shnarch et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,6,"GloVe (Pennington et al. , 2014), these methods compute the embeddings for a sentence on the fly by taking the context of a target word into account.",9,"For argument clustering, we introduce a novel corpus on aspect-based argument clustering and evaluate the proposed methods on this corpus as well as on the Argument Facet Similarity Corpus (Misra et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,7,"In cross-topic scenarios, with which we are dealing in open-domain argument search, contextualized representations need to be able to adapt to new, unseen textual topics.",8,( 2018b) and the IBM Debater R: Evidence Sentences corpus by Shnarch et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,7,"In cross-topic scenarios, with which we are dealing in open-domain argument search, contextualized representations need to be able to adapt to new, unseen textual topics.",9,"For argument clustering, we introduce a novel corpus on aspect-based argument clustering and evaluate the proposed methods on this corpus as well as on the Argument Facet Similarity Corpus (Misra et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Classification and Clustering of Arguments with Contextualized Word Embeddings,8,( 2018b) and the IBM Debater R: Evidence Sentences corpus by Shnarch et al.,9,"For argument clustering, we introduce a novel corpus on aspect-based argument clustering and evaluate the proposed methods on this corpus as well as on the Argument Facet Similarity Corpus (Misra et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Substituto -A Synchronous Educational Language Game for Simultaneous Teaching and Crowdsourcing,0,This paper investigates a general framework for synchronous educational language games that simultaneously allows researchers to crowdsource learner answers in a controlled environment.,1,"The preliminary results we achieved in order to evaluate the educational value, the user experience and the crowdsourcing capacity of Substituto confirm that it has the potential to become a valuable asset for language learning, a pleasant learning instrument and a crowdsourcing tool for collecting linguistic knowledge.In the last few years there has been a substantial growth in the number of language learning educational tools, and recent works have shown the importance of gamification and more specifically how game-based student response systems (SRS) help foster student motivation, engagement and learning (Turan and Meral , 2018; Göksün and Gürsoy , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Substituto -A Synchronous Educational Language Game for Simultaneous Teaching and Crowdsourcing,0,This paper investigates a general framework for synchronous educational language games that simultaneously allows researchers to crowdsource learner answers in a controlled environment.,2,"In this work, we focus on a single type of exercises for learning English verb-particle constructions (VPCs) in context (such as give in, check out and come along).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Substituto -A Synchronous Educational Language Game for Simultaneous Teaching and Crowdsourcing,0,This paper investigates a general framework for synchronous educational language games that simultaneously allows researchers to crowdsource learner answers in a controlled environment.,3,"Students are presented with sentences containing one VPC for which they have to simultaneously find an appropriate synonym (e.g., one or multiple words expressing an identical meaning that is also syntactically appropriate within the context).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Substituto -A Synchronous Educational Language Game for Simultaneous Teaching and Crowdsourcing,1,"The preliminary results we achieved in order to evaluate the educational value, the user experience and the crowdsourcing capacity of Substituto confirm that it has the potential to become a valuable asset for language learning, a pleasant learning instrument and a crowdsourcing tool for collecting linguistic knowledge.In the last few years there has been a substantial growth in the number of language learning educational tools, and recent works have shown the importance of gamification and more specifically how game-based student response systems (SRS) help foster student motivation, engagement and learning (Turan and Meral , 2018; Göksün and Gürsoy , 2019).",2,"In this work, we focus on a single type of exercises for learning English verb-particle constructions (VPCs) in context (such as give in, check out and come along).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Substituto -A Synchronous Educational Language Game for Simultaneous Teaching and Crowdsourcing,1,"The preliminary results we achieved in order to evaluate the educational value, the user experience and the crowdsourcing capacity of Substituto confirm that it has the potential to become a valuable asset for language learning, a pleasant learning instrument and a crowdsourcing tool for collecting linguistic knowledge.In the last few years there has been a substantial growth in the number of language learning educational tools, and recent works have shown the importance of gamification and more specifically how game-based student response systems (SRS) help foster student motivation, engagement and learning (Turan and Meral , 2018; Göksün and Gürsoy , 2019).",3,"Students are presented with sentences containing one VPC for which they have to simultaneously find an appropriate synonym (e.g., one or multiple words expressing an identical meaning that is also syntactically appropriate within the context).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Substituto -A Synchronous Educational Language Game for Simultaneous Teaching and Crowdsourcing,2,"In this work, we focus on a single type of exercises for learning English verb-particle constructions (VPCs) in context (such as give in, check out and come along).",3,"Students are presented with sentences containing one VPC for which they have to simultaneously find an appropriate synonym (e.g., one or multiple words expressing an identical meaning that is also syntactically appropriate within the context).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",2,"AM consists of several different tasks ,","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",8,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Multi-Task Attentive Residual Networks for Argument Mining,0,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",29,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,2,"AM consists of several different tasks ,","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,8,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Multi-Task Attentive Residual Networks for Argument Mining,1,On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",28,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",8,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Multi-Task Attentive Residual Networks for Argument Mining,2,"AM consists of several different tasks ,",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",27,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",8,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Multi-Task Attentive Residual Networks for Argument Mining,3,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",26,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",8,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Multi-Task Attentive Residual Networks for Argument Mining,4,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",25,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",8,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Multi-Task Attentive Residual Networks for Argument Mining,5,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",24,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",8,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Multi-Task Attentive Residual Networks for Argument Mining,6,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",23,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",8,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Multi-Task Attentive Residual Networks for Argument Mining,7,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",22,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,8,Section IV describes the data used for evaluation.,29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",21,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",10,which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,9,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,10,which aims to extract arguments from text collections [1].,29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,11,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,12,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,13,"AM approaches are very often tailored to specific corpora or genres [4] - [6], with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,14,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",16,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,15,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,17,for argument mining and in particular link prediction.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,16,Section IV describes the data used for evaluation.,29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,17,for argument mining and in particular link prediction.,29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,18,"On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,19,it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1].,29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Multi-Task Attentive Residual Networks for Argument Mining,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Multi-Task Attentive Residual Networks for Argument Mining,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,20,"AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2].",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Multi-Task Attentive Residual Networks for Argument Mining,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",22,"Relations between arguments, or argument components, typically consist of either support or attack links.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,21,"While there is no unique definition of an argument, one of the most popular ones was proposed by Douglas Walton [3], who defined an argument as the collection of three parts: (i) a claim, or assertion, about a given topic; (ii) a set of premises supporting the claim; (iii) the inference between the premises and the claim.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Multi-Task Attentive Residual Networks for Argument Mining,22,"Relations between arguments, or argument components, typically consist of either support or attack links.",23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,22,"Relations between arguments, or argument components, typically consist of either support or attack links.",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,22,"Relations between arguments, or argument components, typically consist of either support or attack links.",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,22,"Relations between arguments, or argument components, typically consist of either support or attack links.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,22,"Relations between arguments, or argument components, typically consist of either support or attack links.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,22,"Relations between arguments, or argument components, typically consist of either support or attack links.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,22,"Relations between arguments, or argument components, typically consist of either support or attack links.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Multi-Task Attentive Residual Networks for Argument Mining,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],",24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],",25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,23,"AM approaches are very often tailored to specific corpora or genres [4] - [6],",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Multi-Task Attentive Residual Networks for Argument Mining,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,24,with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.,29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Multi-Task Attentive Residual Networks for Argument Mining,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,25,"It is very often the case that AM systems build upon sets of handcrafted features which encode information about the underlying argument model, the genre, or the topic of interest.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Multi-Task Attentive Residual Networks for Argument Mining,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",27,Section III introduces our architectures.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,26,"These approaches typically make some assumptions on the argumentative structure of the given input document, thus constraining the resulting argument graph.",29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Multi-Task Attentive Residual Networks for Argument Mining,27,Section III introduces our architectures.,28,Section IV describes the data used for evaluation.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Multi-Task Attentive Residual Networks for Argument Mining,27,Section III introduces our architectures.,29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Multi-Task Attentive Residual Networks for Argument Mining,28,Section IV describes the data used for evaluation.,29,"Section V describes our experimental setting, whereas results are presented and discussed in Section VI.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",5,"Indeed, studies have shown that replacing static embeddings (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",6,word2vec) with contextualized ones (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,0,"In three supervised tasks, we find that clipping does not affect the performance.A major area of NLP research in the deep learning era has concerned the representation of words in low-dimensional, continuous vector spaces.",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",5,"Indeed, studies have shown that replacing static embeddings (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",6,word2vec) with contextualized ones (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,1,"Traditional methods for achieving this have included word embedding models such as Word2Vec (Mikolov et al. , 2013), GloVe (Pennington et al. , 2014), and FastText (Bojanowski et al. , 2017).",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",5,"Indeed, studies have shown that replacing static embeddings (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",6,word2vec) with contextualized ones (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,2,"However, though influential, such approaches all share a uniform pitfall in assigning a single, static vector to a word type.",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",5,"Indeed, studies have shown that replacing static embeddings (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",6,word2vec) with contextualized ones (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,3,"In recent years, deep language models, like ELMo (Peters et al. , 2018), BERT (Devlin et al. , 2019) and RoBERTa (Liu et al. , 2019b), have achieved great success across many NLP tasks.",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.",5,"Indeed, studies have shown that replacing static embeddings (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.",6,word2vec) with contextualized ones (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.",7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.",8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.",9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.",10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,4,"Such models introduce a new type of word vectors, deemed the contextualized variety, where the representation is computed with respect to the context of the target word.",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,5,"Indeed, studies have shown that replacing static embeddings (e.g.",6,word2vec) with contextualized ones (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Positional Artefacts Propagate Through Masked Language Model Embeddings,5,"Indeed, studies have shown that replacing static embeddings (e.g.",7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,link
Positional Artefacts Propagate Through Masked Language Model Embeddings,5,"Indeed, studies have shown that replacing static embeddings (e.g.",8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,5,"Indeed, studies have shown that replacing static embeddings (e.g.",9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,5,"Indeed, studies have shown that replacing static embeddings (e.g.",10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,5,"Indeed, studies have shown that replacing static embeddings (e.g.",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,5,"Indeed, studies have shown that replacing static embeddings (e.g.",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,5,"Indeed, studies have shown that replacing static embeddings (e.g.",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,6,word2vec) with contextualized ones (e.g.,7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,6,word2vec) with contextualized ones (e.g.,8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,6,word2vec) with contextualized ones (e.g.,9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,6,word2vec) with contextualized ones (e.g.,10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,6,word2vec) with contextualized ones (e.g.,11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,6,word2vec) with contextualized ones (e.g.,12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,6,word2vec) with contextualized ones (e.g.,13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.",8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.",9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.",10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,7,"BERT) can benefit many NLP tasks, including constituency parsing (Kitaev and Klein , 2018), coreference resolution (Joshi et al. , 2019) and machine translation.",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.",9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.",10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,8,"However, despite the major success in deploying these representations across linguistic tasks, there remains little understanding about information embedded in contextualized vectors and the mechanisms that generate them.",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).",10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,9,"Indeed, an entire research area central to this core issue -the interpretability of neural NLP models -has recently emerged (Linzen et al. , 2018 (Linzen et al., , 2019 Alishahi et al. , 2020).",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).",11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,10,"A key theme in this line of work has been the use of linear probes in investigating the linguistic properties of contextualized vectors (Tenney et al. , 2019; Hewitt and Manning , 2019).",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.",12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,11,"Such studies, among many others, show that contextualization is an important factor that sets these embeddings apart from static ones, the latter of which are unreliable in extracting features central to context or linguistic hierarchy.",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Positional Artefacts Propagate Through Masked Language Model Embeddings,12,"Nonetheless, much of this work likewise fails to engage with the raw vector spaces of language models, preferring instead to focus its analysis on the transformed vectors.",13,"Indeed, the fraction of work that has done the former has shed some curious insights: that untransformed BERT sentence representations still lag behind word embeddings across a variety arXiv:2011.04393v3 [cs.CL] 25 May 2021 of semantic benchmarks (Reimers and Gurevych , 2019) and that the vector spaces of language models are explicitly anisotropic (Ethayarajh , 2019; Li et al. , 2020a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",5,"BLEU, and manually collected human feedback.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,0,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g.",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",5,"BLEU, and manually collected human feedback.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,1,"nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels.",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.",3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.",4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.",5,"BLEU, and manually collected human feedback.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.",6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.",7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.",8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.",9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.",10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,2,"It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels.",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).",4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).",5,"BLEU, and manually collected human feedback.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).",6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).",7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).",8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).",9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).",10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,3,"We release our source code 1 .Considering rapid progresses in developing open-domain dialogue agents Ghazvininejad et al. , 2018; Dinan et al. , 2019; Li et al. , 2019), the need for models that compare these agents in various dialogue aspects becomes extremely important (Liu et al. , 2016; Dinan et al. , 2019).",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.",5,"BLEU, and manually collected human feedback.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.",6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.",7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.",8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.",9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.",10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,4,"Most available methods for dialogue evaluation rely on word-overlap metrics, e.g.",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,5,"BLEU, and manually collected human feedback.",6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,5,"BLEU, and manually collected human feedback.",7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,5,"BLEU, and manually collected human feedback.",8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,5,"BLEU, and manually collected human feedback.",9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,5,"BLEU, and manually collected human feedback.",10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,5,"BLEU, and manually collected human feedback.",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).",7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).",8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).",9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).",10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,6,"high-quality dialogue from a random sequence of dialogue utterances (Halliday and Hasan , 1976; Grosz and Sidner , 1986; Byron and Stent , 1998).",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).",8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).",9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).",10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,7,"Dialogue coherence deals with semantic relations between utterances considering their dialogue acts (Perrault and Allen , 1978; Cervone et al. , 2018).",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).",9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).",10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,8,"A Dialogue Act (henceforth DA) gives a meaning to an utterance in a dialogue at the level of``illocutionary force"", and therefore, constitutes the basic unit of communication (Searle , 1969; Raheja and Tetreault , 2019).",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,9,A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance.,11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,10,"Recent approaches to dialogue coherence modeling use the coherence features designed for monologue texts, e.g.",11,"entity transitions (Barzilay and Lapata , 2005), and augment them with dialogue-relevant features, e.g., DA labels (Cervone et al. , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,0,"Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,1,"In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal.The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document (Lippi and Torroni , 2016).",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,2,"The majority of AM systems follows a pipeline scheme, starting with simpler tasks, such as argument component detection, down to more complex tasks, such as argumentation structure prediction.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,3,"Recent years have seen the development of a large number of techniques in this area, on the wake of the advancements produced by deep learning on the whole research field of natural language processing (NLP).",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,4,"Yet, it is widely recognized that the existing AM systems still have a large margin of improvement, as good results have been obtained with some genres where prior knowledge on the structure of the text eases some AM tasks, but other genres, such as legal cases and social media documents still require more work (Cabrio and Villata , 2018).",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.",6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.",7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.",8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.",9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,5,"Understanding whether a given piece of evidence supports a given claim, or whether two claims attack each other, are complex problems that humans can address thanks to their ability to exploit commonsense knowledge, and to perform reasoning and inference.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.",7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.",8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.",9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,6,"Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.",8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.",9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,7,"We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al. , 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar , 2007; De Raedt et al. , 2016; Kordjamshidi et al. , 2018) communities.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).",9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,8,"In computational argumentation, structured arguments have been studied and formalized for decades using models that can be expressed in a logic framework (Bench-Capon and Dunne , 2007).",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.",10,"So far, these two worlds have progressed largely independently of each other.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,9,"At the same time, AM has rapidly evolved by exploiting state-of-the-art neural architectures coming from deep learning.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,10,"So far, these two worlds have progressed largely independently of each other.",11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,10,"So far, these two worlds have progressed largely independently of each other.",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,10,"So far, these two worlds have progressed largely independently of each other.",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,10,"So far, these two worlds have progressed largely independently of each other.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.",12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,11,"Only recently, a few works have taken some steps toward the integration of such methods, by applying techniques combining sub-symbolic classifiers with knowledge expressed in the form of rules and constraints to AM.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.",13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,12,"( 2017) adopted structured support vector machines and recurrent neural networks to collectively classify argument components and their relations in short documents, by hardcoding contextual dependencies and constraints of the argument model in a factor graph.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Neural-Symbolic Argumentation Mining: An Argument in Favor of Deep Learning and Reasoning,13,"A joint inference approach for argument component classification and relation identification was instead proposed by Persing and Ng (2016), following a pipeline scheme where integer linear programming is used to enforce mathematical constraints on the outcomes of a first-stage set of classifiers.",14,"More recently, Cocarascu and Toni (2018) combined a deep network for relation extraction with an argumentative reasoning system that computes the dialectical strength of arguments, for the task of determining whether a review is truthful or deceptive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,0,Learning sentence embeddings often requires large amount of labeled data.,1,"However, for most tasks and domains, labeled data is seldom available and creating it is expensive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,0,Learning sentence embeddings often requires large amount of labeled data.,2,It can achieve up to 93.1% of the performance of in-domain supervised approaches.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,0,Learning sentence embeddings often requires large amount of labeled data.,3,"1 A crucial shortcoming of previous studies is the narrow evaluation: Most work mainly evaluates on the single task of Semantic Textual Similarity (STS), which does not require any domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,0,Learning sentence embeddings often requires large amount of labeled data.,4,It is unclear if these proposed methods generalize to other domains and tasks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,0,Learning sentence embeddings often requires large amount of labeled data.,5,"We fill this gap and evaluate TS-DAE and other recent approaches on four different datasets from heterogeneous domains.Sentence embedding techniques encode sentences into a fixed-sized, dense vector space such that semantically similar sentences are close.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,0,Learning sentence embeddings often requires large amount of labeled data.,6,"The most successful previous approaches like InferSent (Conneau et al. , 2017), Universial Sentence Encoder (USE) (Cer et al. , 2018) and SBERT (Reimers and Gurevych , 2019) heavily relied on labeled data to train sentence embedding models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,0,Learning sentence embeddings often requires large amount of labeled data.,7,"To overcome this limitation, unsupervised approaches have been proposed which learn to embed sentences just using an unlabeled corpus for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,0,Learning sentence embeddings often requires large amount of labeled data.,8,"Often, approaches are only evaluated on the Semantic Textual Similarity (STS) task from SemEval (Li et al. , 2020; Carlsson et al. , 2021; Giorgi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,1,"However, for most tasks and domains, labeled data is seldom available and creating it is expensive.",2,It can achieve up to 93.1% of the performance of in-domain supervised approaches.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,1,"However, for most tasks and domains, labeled data is seldom available and creating it is expensive.",3,"1 A crucial shortcoming of previous studies is the narrow evaluation: Most work mainly evaluates on the single task of Semantic Textual Similarity (STS), which does not require any domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,1,"However, for most tasks and domains, labeled data is seldom available and creating it is expensive.",4,It is unclear if these proposed methods generalize to other domains and tasks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,1,"However, for most tasks and domains, labeled data is seldom available and creating it is expensive.",5,"We fill this gap and evaluate TS-DAE and other recent approaches on four different datasets from heterogeneous domains.Sentence embedding techniques encode sentences into a fixed-sized, dense vector space such that semantically similar sentences are close.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,1,"However, for most tasks and domains, labeled data is seldom available and creating it is expensive.",6,"The most successful previous approaches like InferSent (Conneau et al. , 2017), Universial Sentence Encoder (USE) (Cer et al. , 2018) and SBERT (Reimers and Gurevych , 2019) heavily relied on labeled data to train sentence embedding models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,1,"However, for most tasks and domains, labeled data is seldom available and creating it is expensive.",7,"To overcome this limitation, unsupervised approaches have been proposed which learn to embed sentences just using an unlabeled corpus for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,1,"However, for most tasks and domains, labeled data is seldom available and creating it is expensive.",8,"Often, approaches are only evaluated on the Semantic Textual Similarity (STS) task from SemEval (Li et al. , 2020; Carlsson et al. , 2021; Giorgi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,2,It can achieve up to 93.1% of the performance of in-domain supervised approaches.,3,"1 A crucial shortcoming of previous studies is the narrow evaluation: Most work mainly evaluates on the single task of Semantic Textual Similarity (STS), which does not require any domain knowledge.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,2,It can achieve up to 93.1% of the performance of in-domain supervised approaches.,4,It is unclear if these proposed methods generalize to other domains and tasks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,2,It can achieve up to 93.1% of the performance of in-domain supervised approaches.,5,"We fill this gap and evaluate TS-DAE and other recent approaches on four different datasets from heterogeneous domains.Sentence embedding techniques encode sentences into a fixed-sized, dense vector space such that semantically similar sentences are close.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,2,It can achieve up to 93.1% of the performance of in-domain supervised approaches.,6,"The most successful previous approaches like InferSent (Conneau et al. , 2017), Universial Sentence Encoder (USE) (Cer et al. , 2018) and SBERT (Reimers and Gurevych , 2019) heavily relied on labeled data to train sentence embedding models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,2,It can achieve up to 93.1% of the performance of in-domain supervised approaches.,7,"To overcome this limitation, unsupervised approaches have been proposed which learn to embed sentences just using an unlabeled corpus for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,2,It can achieve up to 93.1% of the performance of in-domain supervised approaches.,8,"Often, approaches are only evaluated on the Semantic Textual Similarity (STS) task from SemEval (Li et al. , 2020; Carlsson et al. , 2021; Giorgi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,3,"1 A crucial shortcoming of previous studies is the narrow evaluation: Most work mainly evaluates on the single task of Semantic Textual Similarity (STS), which does not require any domain knowledge.",4,It is unclear if these proposed methods generalize to other domains and tasks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,3,"1 A crucial shortcoming of previous studies is the narrow evaluation: Most work mainly evaluates on the single task of Semantic Textual Similarity (STS), which does not require any domain knowledge.",5,"We fill this gap and evaluate TS-DAE and other recent approaches on four different datasets from heterogeneous domains.Sentence embedding techniques encode sentences into a fixed-sized, dense vector space such that semantically similar sentences are close.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,3,"1 A crucial shortcoming of previous studies is the narrow evaluation: Most work mainly evaluates on the single task of Semantic Textual Similarity (STS), which does not require any domain knowledge.",6,"The most successful previous approaches like InferSent (Conneau et al. , 2017), Universial Sentence Encoder (USE) (Cer et al. , 2018) and SBERT (Reimers and Gurevych , 2019) heavily relied on labeled data to train sentence embedding models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,3,"1 A crucial shortcoming of previous studies is the narrow evaluation: Most work mainly evaluates on the single task of Semantic Textual Similarity (STS), which does not require any domain knowledge.",7,"To overcome this limitation, unsupervised approaches have been proposed which learn to embed sentences just using an unlabeled corpus for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,3,"1 A crucial shortcoming of previous studies is the narrow evaluation: Most work mainly evaluates on the single task of Semantic Textual Similarity (STS), which does not require any domain knowledge.",8,"Often, approaches are only evaluated on the Semantic Textual Similarity (STS) task from SemEval (Li et al. , 2020; Carlsson et al. , 2021; Giorgi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,4,It is unclear if these proposed methods generalize to other domains and tasks.,5,"We fill this gap and evaluate TS-DAE and other recent approaches on four different datasets from heterogeneous domains.Sentence embedding techniques encode sentences into a fixed-sized, dense vector space such that semantically similar sentences are close.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,4,It is unclear if these proposed methods generalize to other domains and tasks.,6,"The most successful previous approaches like InferSent (Conneau et al. , 2017), Universial Sentence Encoder (USE) (Cer et al. , 2018) and SBERT (Reimers and Gurevych , 2019) heavily relied on labeled data to train sentence embedding models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,4,It is unclear if these proposed methods generalize to other domains and tasks.,7,"To overcome this limitation, unsupervised approaches have been proposed which learn to embed sentences just using an unlabeled corpus for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,4,It is unclear if these proposed methods generalize to other domains and tasks.,8,"Often, approaches are only evaluated on the Semantic Textual Similarity (STS) task from SemEval (Li et al. , 2020; Carlsson et al. , 2021; Giorgi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,5,"We fill this gap and evaluate TS-DAE and other recent approaches on four different datasets from heterogeneous domains.Sentence embedding techniques encode sentences into a fixed-sized, dense vector space such that semantically similar sentences are close.",6,"The most successful previous approaches like InferSent (Conneau et al. , 2017), Universial Sentence Encoder (USE) (Cer et al. , 2018) and SBERT (Reimers and Gurevych , 2019) heavily relied on labeled data to train sentence embedding models.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,5,"We fill this gap and evaluate TS-DAE and other recent approaches on four different datasets from heterogeneous domains.Sentence embedding techniques encode sentences into a fixed-sized, dense vector space such that semantically similar sentences are close.",7,"To overcome this limitation, unsupervised approaches have been proposed which learn to embed sentences just using an unlabeled corpus for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,5,"We fill this gap and evaluate TS-DAE and other recent approaches on four different datasets from heterogeneous domains.Sentence embedding techniques encode sentences into a fixed-sized, dense vector space such that semantically similar sentences are close.",8,"Often, approaches are only evaluated on the Semantic Textual Similarity (STS) task from SemEval (Li et al. , 2020; Carlsson et al. , 2021; Giorgi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,6,"The most successful previous approaches like InferSent (Conneau et al. , 2017), Universial Sentence Encoder (USE) (Cer et al. , 2018) and SBERT (Reimers and Gurevych , 2019) heavily relied on labeled data to train sentence embedding models.",7,"To overcome this limitation, unsupervised approaches have been proposed which learn to embed sentences just using an unlabeled corpus for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,6,"The most successful previous approaches like InferSent (Conneau et al. , 2017), Universial Sentence Encoder (USE) (Cer et al. , 2018) and SBERT (Reimers and Gurevych , 2019) heavily relied on labeled data to train sentence embedding models.",8,"Often, approaches are only evaluated on the Semantic Textual Similarity (STS) task from SemEval (Li et al. , 2020; Carlsson et al. , 2021; Giorgi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,link
TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,7,"To overcome this limitation, unsupervised approaches have been proposed which learn to embed sentences just using an unlabeled corpus for training.",8,"Often, approaches are only evaluated on the Semantic Textual Similarity (STS) task from SemEval (Li et al. , 2020; Carlsson et al. , 2021; Giorgi et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Syntactically-informed word representations from graph neural network,0,"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",20,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Syntactically-informed word representations from graph neural network,1,"These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",19,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Syntactically-informed word representations from graph neural network,2,"We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs).",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Syntactically-informed word representations from graph neural network,3,We also conduct extensive experiments to analyse the proposed method.Word representations have been widely used in natural language processing (NLP) tasks.,20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Syntactically-informed word representations from graph neural network,4,"Most approaches rely on language models (LMs) to obtain static word representations [1] [2] [3], which conflate all possible meanings of a word in a single real-valued vector.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Syntactically-informed word representations from graph neural network,5,"Recent work investigated contextualised word representations, which assign a different representation to each occurrence of a word based on its local context [4 , 5].",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Syntactically-informed word representations from graph neural network,6,These contextual word representations have demonstrated improvements in downstream tasks over the static ones.,20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Syntactically-informed word representations from graph neural network,7,"Alternatively, large-scale LMs have been proposed to use in downstream application models with fine-tuning approaches [6] [7] [8].",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,8,These fine-tuning methods have shown promising results with higher performance than contextual word representations in some applications such as text classification and textual entailment [7].,20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,9,"Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11 , 12], even when contextual word representations and pre-trained models are also used [13] [14] [15].",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,10,"The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Syntactically-informed word representations from graph neural network,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].",12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].",13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,11,"1; in this paper, we use the term``syntactic information""interchangeably with``POS tags""and``dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing dependency parsing tools [16 , 17].",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Syntactically-informed word representations from graph neural network,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,12,Many task-oriented neural models do not take into account such syntactic information despite potential performance gains.,20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Syntactically-informed word representations from graph neural network,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.",14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,13,"Syntactic information is integrated into existing word representations such as GloVe [18], ELMo [5] and BERT [19] by learning from automatically annotated data which are task-independent.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Syntactically-informed word representations from graph neural network,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.",15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,14,"Since in English word order is important, we preserve it by adding these connections into the graph layer.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Syntactically-informed word representations from graph neural network,15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.",16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,15,"Once the SIWR model is obtained, we apply the model to downstream task data and obtain SIWRs by combining the outputs of all layers in the model.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Syntactically-informed word representations from graph neural network,16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).",17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,16,"We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Syntactically-informed word representations from graph neural network,17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.",18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,17,"SIWRs show improvements over the base representations achieving the following relative error reductions : 3.79% in F1-score for nested NER , 6.64% in F1-score for RE, and 6.98% of accuracy for n-ary RE, which results in comparable performance to the state-of-the-art on the three tasks.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Syntactically-informed word representations from graph neural network,18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.",19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Syntactically-informed word representations from graph neural network,18,"Surprisingly, our SIWRs BERT based on contextual BERT even perform better than the fine-tuning in binary RE with the F1-score of 72.45% and 66.84% respectively.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Syntactically-informed word representations from graph neural network,19,"Meanwhile, our enhanced representations perform comparably to the fine-tuning BERT with less training parameters in the nested NER with the F1-score of 82.06% and 82.84% respectively.",20,"SIWRs allow us to incorporate syntactic information into existing NLP neural models simply by replacing the original word representations, without altering the architecture of these models with a relatively modest amount of syntactically annotated data.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,0,"To enable more socially sensitive public decision making, researchers need to reliably monitor how various social groups (e.g., political actors, news media, citizens) communicate about political decisions (Jungherr , 2015).",1,"The increasing use of social media especially allows social science researchers to conduct opinion analysis on a larger scale than with traditional methods, e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,0,"To enable more socially sensitive public decision making, researchers need to reliably monitor how various social groups (e.g., political actors, news media, citizens) communicate about political decisions (Jungherr , 2015).",2,1 Code and data can be found on GitHub: https: //github.com/UKPLab/ acl2021-label-suggestions-german-covid19 interviews or questionnaires.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,0,"To enable more socially sensitive public decision making, researchers need to reliably monitor how various social groups (e.g., political actors, news media, citizens) communicate about political decisions (Jungherr , 2015).",3,"However, the publication of research results is often delayed or temporally transient due to limitations of traditional social science research, i.e.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,0,"To enable more socially sensitive public decision making, researchers need to reliably monitor how various social groups (e.g., political actors, news media, citizens) communicate about political decisions (Jungherr , 2015).",4,"In contrast to active learning, that aims to identify a subset of annotated data which leads to optimal model training, label suggestions alleviate the annotation process by providing annotators with pre-annotations (i.e., predictions) from a model (Ringger et al. , 2008; Schulz et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,0,"To enable more socially sensitive public decision making, researchers need to reliably monitor how various social groups (e.g., political actors, news media, citizens) communicate about political decisions (Jungherr , 2015).",5,One major difficulty with label suggestions is the danger of biasing annotators towards (possibly erroneous) suggestions.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,0,"To enable more socially sensitive public decision making, researchers need to reliably monitor how various social groups (e.g., political actors, news media, citizens) communicate about political decisions (Jungherr , 2015).",6,"So far, researchers have investigated automated label suggestions for tasks that require domain-specific knowledge (Fort and Sagot , 2010; Yimam et al. , 2013; Schulz et al. , 2019); and have shown that domain experts successfully identify erroneous suggestions and are more robust to potential biases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,0,"To enable more socially sensitive public decision making, researchers need to reliably monitor how various social groups (e.g., political actors, news media, citizens) communicate about political decisions (Jungherr , 2015).",7,"However, the limited availability of such expert annotators restricts the use of label suggestions to small, focused annotation studies.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,0,"To enable more socially sensitive public decision making, researchers need to reliably monitor how various social groups (e.g., political actors, news media, citizens) communicate about political decisions (Jungherr , 2015).",8,In contrast to Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,1,"The increasing use of social media especially allows social science researchers to conduct opinion analysis on a larger scale than with traditional methods, e.g.",2,1 Code and data can be found on GitHub: https: //github.com/UKPLab/ acl2021-label-suggestions-german-covid19 interviews or questionnaires.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,1,"The increasing use of social media especially allows social science researchers to conduct opinion analysis on a larger scale than with traditional methods, e.g.",3,"However, the publication of research results is often delayed or temporally transient due to limitations of traditional social science research, i.e.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,1,"The increasing use of social media especially allows social science researchers to conduct opinion analysis on a larger scale than with traditional methods, e.g.",4,"In contrast to active learning, that aims to identify a subset of annotated data which leads to optimal model training, label suggestions alleviate the annotation process by providing annotators with pre-annotations (i.e., predictions) from a model (Ringger et al. , 2008; Schulz et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,1,"The increasing use of social media especially allows social science researchers to conduct opinion analysis on a larger scale than with traditional methods, e.g.",5,One major difficulty with label suggestions is the danger of biasing annotators towards (possibly erroneous) suggestions.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,1,"The increasing use of social media especially allows social science researchers to conduct opinion analysis on a larger scale than with traditional methods, e.g.",6,"So far, researchers have investigated automated label suggestions for tasks that require domain-specific knowledge (Fort and Sagot , 2010; Yimam et al. , 2013; Schulz et al. , 2019); and have shown that domain experts successfully identify erroneous suggestions and are more robust to potential biases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,1,"The increasing use of social media especially allows social science researchers to conduct opinion analysis on a larger scale than with traditional methods, e.g.",7,"However, the limited availability of such expert annotators restricts the use of label suggestions to small, focused annotation studies.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,1,"The increasing use of social media especially allows social science researchers to conduct opinion analysis on a larger scale than with traditional methods, e.g.",8,In contrast to Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,2,1 Code and data can be found on GitHub: https: //github.com/UKPLab/ acl2021-label-suggestions-german-covid19 interviews or questionnaires.,3,"However, the publication of research results is often delayed or temporally transient due to limitations of traditional social science research, i.e.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,2,1 Code and data can be found on GitHub: https: //github.com/UKPLab/ acl2021-label-suggestions-german-covid19 interviews or questionnaires.,4,"In contrast to active learning, that aims to identify a subset of annotated data which leads to optimal model training, label suggestions alleviate the annotation process by providing annotators with pre-annotations (i.e., predictions) from a model (Ringger et al. , 2008; Schulz et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,2,1 Code and data can be found on GitHub: https: //github.com/UKPLab/ acl2021-label-suggestions-german-covid19 interviews or questionnaires.,5,One major difficulty with label suggestions is the danger of biasing annotators towards (possibly erroneous) suggestions.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,2,1 Code and data can be found on GitHub: https: //github.com/UKPLab/ acl2021-label-suggestions-german-covid19 interviews or questionnaires.,6,"So far, researchers have investigated automated label suggestions for tasks that require domain-specific knowledge (Fort and Sagot , 2010; Yimam et al. , 2013; Schulz et al. , 2019); and have shown that domain experts successfully identify erroneous suggestions and are more robust to potential biases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,2,1 Code and data can be found on GitHub: https: //github.com/UKPLab/ acl2021-label-suggestions-german-covid19 interviews or questionnaires.,7,"However, the limited availability of such expert annotators restricts the use of label suggestions to small, focused annotation studies.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,2,1 Code and data can be found on GitHub: https: //github.com/UKPLab/ acl2021-label-suggestions-german-covid19 interviews or questionnaires.,8,In contrast to Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,3,"However, the publication of research results is often delayed or temporally transient due to limitations of traditional social science research, i.e.",4,"In contrast to active learning, that aims to identify a subset of annotated data which leads to optimal model training, label suggestions alleviate the annotation process by providing annotators with pre-annotations (i.e., predictions) from a model (Ringger et al. , 2008; Schulz et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,3,"However, the publication of research results is often delayed or temporally transient due to limitations of traditional social science research, i.e.",5,One major difficulty with label suggestions is the danger of biasing annotators towards (possibly erroneous) suggestions.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,3,"However, the publication of research results is often delayed or temporally transient due to limitations of traditional social science research, i.e.",6,"So far, researchers have investigated automated label suggestions for tasks that require domain-specific knowledge (Fort and Sagot , 2010; Yimam et al. , 2013; Schulz et al. , 2019); and have shown that domain experts successfully identify erroneous suggestions and are more robust to potential biases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,3,"However, the publication of research results is often delayed or temporally transient due to limitations of traditional social science research, i.e.",7,"However, the limited availability of such expert annotators restricts the use of label suggestions to small, focused annotation studies.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,3,"However, the publication of research results is often delayed or temporally transient due to limitations of traditional social science research, i.e.",8,In contrast to Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,4,"In contrast to active learning, that aims to identify a subset of annotated data which leads to optimal model training, label suggestions alleviate the annotation process by providing annotators with pre-annotations (i.e., predictions) from a model (Ringger et al. , 2008; Schulz et al. , 2019).",5,One major difficulty with label suggestions is the danger of biasing annotators towards (possibly erroneous) suggestions.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,4,"In contrast to active learning, that aims to identify a subset of annotated data which leads to optimal model training, label suggestions alleviate the annotation process by providing annotators with pre-annotations (i.e., predictions) from a model (Ringger et al. , 2008; Schulz et al. , 2019).",6,"So far, researchers have investigated automated label suggestions for tasks that require domain-specific knowledge (Fort and Sagot , 2010; Yimam et al. , 2013; Schulz et al. , 2019); and have shown that domain experts successfully identify erroneous suggestions and are more robust to potential biases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,4,"In contrast to active learning, that aims to identify a subset of annotated data which leads to optimal model training, label suggestions alleviate the annotation process by providing annotators with pre-annotations (i.e., predictions) from a model (Ringger et al. , 2008; Schulz et al. , 2019).",7,"However, the limited availability of such expert annotators restricts the use of label suggestions to small, focused annotation studies.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,4,"In contrast to active learning, that aims to identify a subset of annotated data which leads to optimal model training, label suggestions alleviate the annotation process by providing annotators with pre-annotations (i.e., predictions) from a model (Ringger et al. , 2008; Schulz et al. , 2019).",8,In contrast to Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,5,One major difficulty with label suggestions is the danger of biasing annotators towards (possibly erroneous) suggestions.,6,"So far, researchers have investigated automated label suggestions for tasks that require domain-specific knowledge (Fort and Sagot , 2010; Yimam et al. , 2013; Schulz et al. , 2019); and have shown that domain experts successfully identify erroneous suggestions and are more robust to potential biases.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,5,One major difficulty with label suggestions is the danger of biasing annotators towards (possibly erroneous) suggestions.,7,"However, the limited availability of such expert annotators restricts the use of label suggestions to small, focused annotation studies.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,5,One major difficulty with label suggestions is the danger of biasing annotators towards (possibly erroneous) suggestions.,8,In contrast to Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,6,"So far, researchers have investigated automated label suggestions for tasks that require domain-specific knowledge (Fort and Sagot , 2010; Yimam et al. , 2013; Schulz et al. , 2019); and have shown that domain experts successfully identify erroneous suggestions and are more robust to potential biases.",7,"However, the limited availability of such expert annotators restricts the use of label suggestions to small, focused annotation studies.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,6,"So far, researchers have investigated automated label suggestions for tasks that require domain-specific knowledge (Fort and Sagot , 2010; Yimam et al. , 2013; Schulz et al. , 2019); and have shown that domain experts successfully identify erroneous suggestions and are more robust to potential biases.",8,In contrast to Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Investigating label suggestions for opinion mining in German Covid-19 social media,7,"However, the limited availability of such expert annotators restricts the use of label suggestions to small, focused annotation studies.",8,In contrast to Schulz et al.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,0,"As a ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation.",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,1,"These tests show that the interpretabilityimparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.Distributed word representations, commonly referred to as word embeddings [2], [31], [32], [40], serve as elementary building blocks in the course of algorithm design for an expanding range of applications in natural language processing (NLP), including named entity recognition [47], [52], parsing [6], sentiment analysis [49], [55], and word-sense disambiguation [25].",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,2,"Although the empirical utility of word embeddings as an unsupervised method for capturing the semantic or syntactic features of a certain word as it is used in a given lexical resource is well-established [17], [24], [53], an understanding of what these features mean remains an open problem [7], [26] and as such word embeddings mostly remain a black box.",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,3,"Under this paradigm, dense, continuous vector representations are learned in an unsupervised manner from a large corpus, using the word cooccurrence statistics directly or indirectly, and such an approach is shown to result in vector representations that mathematically capture various semantic and syntactic relations between words [2], [32], [40].",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,4,"Recent approaches to generating word embeddings [32], [40] are rooted linguistically in the field of distributed semantics [19], where words are taken to assume meaning mainly by their degree of interaction (or lack thereof) with other words in the lexicon [13], [14].",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.",6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.",7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.",8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.",9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.",10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,5,"In the literature, researchers tackled the interpretability problem of the word embeddings using different approaches.",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.",7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.",8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.",9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.",10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,6,"Several researchers [15], [29], [37] proposed algorithms based on non-negative matrix factorization (NMF) applied to cooccurrence variant matrices.",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].",8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].",9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].",10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,7,"Other researchers suggested to obtain interpretable word vectors from existing uninterpretable word vectors by applying sparse coding [1], [11], by training a sparse auto-encoder to transform the embedding space [51], by rotating the original embeddings [39], [57] or by applying transformations based on external semantic datasets [44].",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,8,One possible explanation for this performance decrease is that the proposed transformations from the original embedding space distort the underlying semantic structure constructed by the original embedding algorithm.,14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.",10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,9,"Especially after the introduction of the word2vec algorithm by [31], [32], there has been a growing interest in algorithms that generate improved word representations under some performance metric.",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].",11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,10,"Significant effort is spent on appropriately modifying the objective functions of the algorithms in order to incorporate knowledge from external resources, with the purpose of increasing the performance of the resulting word representations [3], [22], [23], [28], [33], [54], [56].",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.",12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,11,"In our proposed method, which is built on top of the GloVe algorithm [40], the cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function.",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].",13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,12,"Significant effort is also spent on developing retrofitting objectives for the same purpose, independent of the original objectives of the embedding model, to fine-tune the embeddings without joint optimization [12], [35], [36].",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Imparting Interpretability to Word Embeddings while Preserving Semantic Structure,13,"For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to.",14,"For words that do not belong to any one of the wordgroups, the cost term is left untouched.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Question Answering Infused Pre-training of General-Purpose Contextualized Representations,0,"This paper proposes a pre-training objective based on question answering (QA) for learning general-purpose contextual representations, motivated by the intuition that the representation of a phrase in a passage should encode all questions that the phrase can answer in context.",1,"We show large improvements over both RoBERTa-large and previous state-of-theart results on zero-shot and few-shot paraphrase detection on four datasets, few-shot named entity recognition on two datasets, and zero-shot sentiment analysis on three datasets.Although masked language models build contextualized word representations, they are pre-trained with losses that minimize distance to uncontextualized word embeddings (Peters et al. , 2018; Liu et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",6,CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,0,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",18,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",6,CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,1,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",17,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",6,CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,2,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",16,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",6,CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,3,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",15,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",6,CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,4,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",6,CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,5,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction Problems (",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,6,CSPs) or Constraint Optimization problems (COPs).,18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,7,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,8,"We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1 .. n }",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,9,"Given enough data, Deep Neural Networks (DNNs) are capable of learning complex input-output relations with high accuracy.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,10,"In several domains, however, data is scarce or expensive to retrieve, while a substantial amount of expert knowledge is available.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",12,capable of learning complex input-output relations with high accuracy.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,11,"One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,12,capable of learning complex input-output relations with high accuracy.,13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,12,capable of learning complex input-output relations with high accuracy.,14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,12,capable of learning complex input-output relations with high accuracy.,15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,12,capable of learning complex input-output relations with high accuracy.,16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,12,capable of learning complex input-output relations with high accuracy.,17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,12,capable of learning complex input-output relations with high accuracy.,18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,13,"In many domains, however, there exists also a substantial degree of expert knowledge: it seems reasonable that if we can inject this additional information in the DNN, we could ease the learning process.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,14,"Indeed, methods for hybridizing learning and reasoning (or for taking into account constraints at training time) can accelerate convergence or improve the accuracy, especially when supervised data is scarce.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction",16,Problems (CSPs) or Constraint Optimization problems (COPs).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction",17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,15,"Depending on the lack or presence of a cost function, they are formally known as Constraint Satisfaction",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,16,Problems (CSPs) or Constraint Optimization problems (COPs).,17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,16,Problems (CSPs) or Constraint Optimization problems (COPs).,18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Injecting Domain Knowledge in Neural Networks: a Controlled Experiment on a Constrained Problem,17,"Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences) that are not known to the expert, despite being satisfied in historical solutions.",18,"Despite its simplicity, the PLS is NP-hard, unless we start from an empty square; the problem has practical applications (e.g.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),0,"We conclude that while self-supervised pretraining is an effective way to learn helpful inductive biases, there is likely room to improve the rate at which models learn which features matter.Self-supervised pretraining through language modeling on massive datasets has revolutionized NLP.",1,"One reason this method works is that pretraining shapes a model's hypothesis space, giving it inductive biases that help it learn linguistic tasks (Howard and Ruder , 2018).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),0,"We conclude that while self-supervised pretraining is an effective way to learn helpful inductive biases, there is likely room to improve the rate at which models learn which features matter.Self-supervised pretraining through language modeling on massive datasets has revolutionized NLP.",2,"Numerous probing studies have provided support for this idea by showing that language models learn representations that encode linguistic features (Gulordava et al. , 2019; Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),0,"We conclude that while self-supervised pretraining is an effective way to learn helpful inductive biases, there is likely room to improve the rate at which models learn which features matter.Self-supervised pretraining through language modeling on massive datasets has revolutionized NLP.",3,Models must The rumor that a CEO is losing spread.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),0,"We conclude that while self-supervised pretraining is an effective way to learn helpful inductive biases, there is likely room to improve the rate at which models learn which features matter.Self-supervised pretraining through language modeling on massive datasets has revolutionized NLP.",4,A boy who is hugging the cat sneezed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),0,"We conclude that while self-supervised pretraining is an effective way to learn helpful inductive biases, there is likely room to improve the rate at which models learn which features matter.Self-supervised pretraining through language modeling on massive datasets has revolutionized NLP.",5,A guest said that the boat is sinking.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),1,"One reason this method works is that pretraining shapes a model's hypothesis space, giving it inductive biases that help it learn linguistic tasks (Howard and Ruder , 2018).",2,"Numerous probing studies have provided support for this idea by showing that language models learn representations that encode linguistic features (Gulordava et al. , 2019; Tenney et al. , 2019; Hewitt and Manning , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),1,"One reason this method works is that pretraining shapes a model's hypothesis space, giving it inductive biases that help it learn linguistic tasks (Howard and Ruder , 2018).",3,Models must The rumor that a CEO is losing spread.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),1,"One reason this method works is that pretraining shapes a model's hypothesis space, giving it inductive biases that help it learn linguistic tasks (Howard and Ruder , 2018).",4,A boy who is hugging the cat sneezed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),1,"One reason this method works is that pretraining shapes a model's hypothesis space, giving it inductive biases that help it learn linguistic tasks (Howard and Ruder , 2018).",5,A guest said that the boat is sinking.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),2,"Numerous probing studies have provided support for this idea by showing that language models learn representations that encode linguistic features (Gulordava et al. , 2019; Tenney et al. , 2019; Hewitt and Manning , 2019).",3,Models must The rumor that a CEO is losing spread.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),2,"Numerous probing studies have provided support for this idea by showing that language models learn representations that encode linguistic features (Gulordava et al. , 2019; Tenney et al. , 2019; Hewitt and Manning , 2019).",4,A boy who is hugging the cat sneezed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),2,"Numerous probing studies have provided support for this idea by showing that language models learn representations that encode linguistic features (Gulordava et al. , 2019; Tenney et al. , 2019; Hewitt and Manning , 2019).",5,A guest said that the boat is sinking.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),3,Models must The rumor that a CEO is losing spread.,4,A boy who is hugging the cat sneezed.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),3,Models must The rumor that a CEO is losing spread.,5,A guest said that the boat is sinking.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),4,A boy who is hugging the cat sneezed.,5,A guest said that the boat is sinking.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,1,One approach to UQA is to train a QA model with questions generated automatically.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,6,"Because of this, Lewis et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,9,Another approach to UQG is based on language models (LM).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,0,Unsupervised question answering (UQA) has been proposed to avoid the high cost of creating high-quality datasets for QA.,13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,6,"Because of this, Lewis et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,9,Another approach to UQG is based on language models (LM).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,1,One approach to UQA is to train a QA model with questions generated automatically.,13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",6,"Because of this, Lewis et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",9,Another approach to UQG is based on language models (LM).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,2,"However, the generated questions are either too similar to a word sequence in the context or too drifted from the semantics of the context, thereby making it difficult to train a robust QA model.",13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,6,"Because of this, Lewis et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,9,Another approach to UQG is based on language models (LM).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,3,We also show that this method can be useful for creating a QA model with few-shot learning.Machine Reading for Question Answering (MRQA) is the task of answering questions from a context that contains the answer.,13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).",5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).",6,"Because of this, Lewis et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).",7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).",8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).",9,Another approach to UQG is based on language models (LM).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).",10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).",11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).",12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,4,"This field has seen remarkable progress in recent years, with QA models outperforming humans on a question answering (QA) benchmark like SQuAD (Rajpurkar et al. , 2016).",13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.",6,"Because of this, Lewis et al.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.",7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.",8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.",9,Another approach to UQG is based on language models (LM).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.",10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.",11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.",12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,5,"Training a QA model requires a large amount of data, and constructing such a dataset is usually laborious or sometimes even impossible for some domains and languages.",13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,6,"Because of this, Lewis et al.",7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,6,"Because of this, Lewis et al.",8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,6,"Because of this, Lewis et al.",9,Another approach to UQG is based on language models (LM).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,6,"Because of this, Lewis et al.",10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,6,"Because of this, Lewis et al.",11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,6,"Because of this, Lewis et al.",12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,6,"Because of this, Lewis et al.",13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.",8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.",9,Another approach to UQG is based on language models (LM).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.",10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.",11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.",12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,7,"( 2019) explored unsupervised question answering (UQA), a setting where manually constructed triples, (context, question, answer), are not available for training.",13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,9,Another approach to UQG is based on language models (LM).,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,8,They approached the problem with unsupervised question generation Figure 1: An example of LM-type (left) and copy-type (right) questions generated from a context.,13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,9,Another approach to UQG is based on language models (LM).,10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,9,Another approach to UQG is based on language models (LM).,11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,9,Another approach to UQG is based on language models (LM).,12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,9,Another approach to UQG is based on language models (LM).,13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.",11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.",12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,10,"( 2019) proposed an LM approach, GPT-2, that shook the natural language processing (NLP) research community with its remarkable capability of automatically generating high-quality text.",13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).",12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,11,"Naturally, GPT-2 was shown to generate high-quality questions from contexts (Klein and Nabi , 2019; Puri et al. , 2020).",13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Regularization of Distinct Strategies for Unsupervised Question Generation,12,"Despite the recent progress made by these efforts, UQG remains to be an open problem.",13,"The teacher employs two QG models 1 (assistants), LM-type and copy-type, and adopts a semantic-level regularization process newly designed to avoid a bias toward a particular question generation strategy (i.e., either copy-type or LM-type).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
When Do You Need Billions of Words of Pretraining Data?,0,"NLP is currently dominated by generalpurpose pretrained language models like RoBERTa, which achieve strong performance on NLU tasks through pretraining on billions of words.",1,"These models use massive datasets on the order of tens or even hundreds of billions of words (Brown et al. , 2020) to learn linguistic features and world knowledge, and they can be fine-tuned to achieve good performance on many downstream tasks.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",6,The ultimate goal is to aid the clinician's deliberation process [6].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,0,"In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",14,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",6,The ultimate goal is to aid the clinician's deliberation process [6].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,1,"Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",13,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",6,The ultimate goal is to aid the clinician's deliberation process [6].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,2,"We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1score of.80 for outcome classification.In the healthcare domain, there is an increasing interest in the development of intelligent systems able to support and ease clinicians' everyday activities.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",6,The ultimate goal is to aid the clinician's deliberation process [6].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,3,"These systems deal with heterogeneous kinds of data, spanning from textual documents to medical images to biometrics.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",6,The ultimate goal is to aid the clinician's deliberation process [6].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,4,"Concerning textual documents (e.g., clinical trials, clinical guidelines, and Electronic Health Records), such solutions range from the automated detection of PICO elements [1] in health records to evidence-based reasoning for decision making [2] [3] [4] [5].",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.",6,The ultimate goal is to aid the clinician's deliberation process [6].,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.",7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.",8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.",9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.",10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,5,"These applications aim at assisting clinicians in their everyday tasks by extracting, from unstructured textual documents, the exact information they necessitate and to present this information in a structured and machine-readable format, easy to be (possibly semi-automatically) analyzed.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,6,The ultimate goal is to aid the clinician's deliberation process [6].,7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,6,The ultimate goal is to aid the clinician's deliberation process [6].,8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,6,The ultimate goal is to aid the clinician's deliberation process [6].,9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,6,The ultimate goal is to aid the clinician's deliberation process [6].,10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,6,The ultimate goal is to aid the clinician's deliberation process [6].,11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,6,The ultimate goal is to aid the clinician's deliberation process [6].,12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,6,The ultimate goal is to aid the clinician's deliberation process [6].,13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,6,The ultimate goal is to aid the clinician's deliberation process [6].,14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.",8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.",9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.",10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,7,"Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument (ation) Mining (AM) [7] [8] [9] [10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.",9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.",10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,8,"Standard tasks in AM are the detection of argument components (i.e., evidence and claims), and the prediction of the relations (i.e., attack and support) holding among them.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.",10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,9,"Our motivation to rely on argumentation mining stems from its aptness in providing us with methods to automatically detect in text the argumentative structures that are at the basis of Evidence-Based Medicine (EBM), which is the``conscientious, explicit, and judicious use of current best evidence""[ 11] to guide clinical decision-making with scientific information from systematic reviews.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.",11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,10,"These information needs cannot be directly tackled by current methods (e.g., clinical document classification [12], clinical question answering [13], or extractive summarization [14] ), and require the development of novel approaches within the argumentation mining field.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.",12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,11,"Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15] [16] [17] [18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.",13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,12,"Indeed, when clinicians search for relevant evidence, they use a specialised framework called PICO, which stands for Patient Problem or Population, Intervention, Comparison or Control, and Outcome.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials,13,"The idea is to ask well-built clinical questions [19], which should be answered by clinical trials.",14,"• We experiment on the annotated data using various Machine Learning methods relying on deep bidirectional transformers combined with different neural networks, i.e., Long Short-Term Memory (LSTM) networks, Gated Recurrent Unit (GRU) networks, and Conditional Random Fields (CRFs) in order to extract argument structure and classify outcomes from RCTs.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,9,Even though dense retrievers (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,0,Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers.,12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",9,Even though dense retrievers (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,1,"In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by``numerically""combining it with another neural representation.",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",9,Even though dense retrievers (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2,"Additionally, DOCHOPPER is efficient at inference time, being 3∼10 times faster than the baselines.Recent advances in Transformer-based pretrained Language Models (e.g., BERT (Devlin et al. , 2019), RoBERTa (Liu et al. , 2019) ) have dramatically improved performance on question answering (QA) tasks (Rajpurkar et al. , 2016).",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.",4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.",5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.",6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.",7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.",8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.",9,Even though dense retrievers (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.",10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.",11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,3,"Although effective, Transformer-based models are usually limited to documents of fixed length, typically 512 tokens, due to their O (n 2) memory complexity.",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.",5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.",6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.",7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.",8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.",9,Even though dense retrievers (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.",10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.",11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,4,"This is an important restrictions for reading long documents such as Wikipedia pages, academic papers, and technical reports, which can contain tens of thousands of tokens.",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).",6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).",7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).",8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).",9,Even though dense retrievers (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).",10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).",11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,5,"To address this issue, Transformer models that use sparse self-attention have been introduced (e.g., Beltagy et al. , 2020) ).",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).",7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).",8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).",9,Even though dense retrievers (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).",10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).",11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,6,"A similar idea is also adopted by Longformer (Beltagy et al. , 2020).",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.",8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.",9,Even though dense retrievers (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.",10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.",11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,7,"An alternative way to perform question answering over long documents (Clark and Gardner , 2017) is to adopt the``retrieve and read""pipeline that is commonly used in open-domain QA.",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.",9,Even though dense retrievers (e.g.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.",10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.",11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,8,"In retrieve-and-read systems, a retriever module retrieves the top passages from the documents, and then a Transformer-based reader extracts or generates answers from the retrieved passages.",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,9,Even though dense retrievers (e.g.,10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,9,Even though dense retrievers (e.g.,11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,9,Even though dense retrievers (e.g.,12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.",11,"These models also treat each passage independently, ignoring the rich information in document structures.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,10,"DPR (Karpukhin et al. , 2020) ) show competitive retrieval performance in open-domain QA tasks, and recent work (Zhao et al. , 2021; Qi et al. , 2021; to extend the query with tokens from previously retrieved text, and re-encode the query to perform the next round of retrieval, such multi-hop retrieval process is not end-to-end differentiable, and requires careful training to avoid cascaded errors.",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,11,"These models also treat each passage independently, ignoring the rich information in document structures.",12,"Different from previous multi-hop retrieval methods (Zhao et al. , 2021; Qi et al. , 2021; Sun et al. , 2019) that treat each retrieval candidate independently, DOCHOPPER also utilizes the document structure to improve the retrieval accuracy: in particular, it performs retrieval at both paragraph-level and sentence-level.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
BERT Busters: Outlier Dimensions that Disrupt Transformers,0,Multiple studies have shown that Transformers are remarkably robust to pruning.,1,"This effect is observed across several BERT-family models and other popular pre-trained Transformer architectures, including BART, XLNet and ELECTRA; we also show a similar effect in GPT-2.Pre-trained Transformer-based models (Vaswani et al. , 2017) have become widely popular in a variety of NLP applications.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
BERT Busters: Outlier Dimensions that Disrupt Transformers,0,Multiple studies have shown that Transformers are remarkably robust to pruning.,2,"Multiple studies of BERT-family models (Devlin et al. , 2019) showed that Transformers are remarkably robust to pruning (Gordon et al. , 2020; Prasanna et al. , 2020; Michel et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
BERT Busters: Outlier Dimensions that Disrupt Transformers,0,Multiple studies have shown that Transformers are remarkably robust to pruning.,3,"that this effect holds for different Transformerfamily architectures, including multiple variants of BERT, as well as ELECTRA (Clark et al. , 2020), BART (Lewis et al. , 2020), and XLNet (Yang et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
BERT Busters: Outlier Dimensions that Disrupt Transformers,0,Multiple studies have shown that Transformers are remarkably robust to pruning.,4,"Figure 1: Transformer encoder layer, adapted from (Vaswani et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
BERT Busters: Outlier Dimensions that Disrupt Transformers,1,"This effect is observed across several BERT-family models and other popular pre-trained Transformer architectures, including BART, XLNet and ELECTRA; we also show a similar effect in GPT-2.Pre-trained Transformer-based models (Vaswani et al. , 2017) have become widely popular in a variety of NLP applications.",2,"Multiple studies of BERT-family models (Devlin et al. , 2019) showed that Transformers are remarkably robust to pruning (Gordon et al. , 2020; Prasanna et al. , 2020; Michel et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
BERT Busters: Outlier Dimensions that Disrupt Transformers,1,"This effect is observed across several BERT-family models and other popular pre-trained Transformer architectures, including BART, XLNet and ELECTRA; we also show a similar effect in GPT-2.Pre-trained Transformer-based models (Vaswani et al. , 2017) have become widely popular in a variety of NLP applications.",3,"that this effect holds for different Transformerfamily architectures, including multiple variants of BERT, as well as ELECTRA (Clark et al. , 2020), BART (Lewis et al. , 2020), and XLNet (Yang et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
BERT Busters: Outlier Dimensions that Disrupt Transformers,1,"This effect is observed across several BERT-family models and other popular pre-trained Transformer architectures, including BART, XLNet and ELECTRA; we also show a similar effect in GPT-2.Pre-trained Transformer-based models (Vaswani et al. , 2017) have become widely popular in a variety of NLP applications.",4,"Figure 1: Transformer encoder layer, adapted from (Vaswani et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
BERT Busters: Outlier Dimensions that Disrupt Transformers,2,"Multiple studies of BERT-family models (Devlin et al. , 2019) showed that Transformers are remarkably robust to pruning (Gordon et al. , 2020; Prasanna et al. , 2020; Michel et al. , 2019).",3,"that this effect holds for different Transformerfamily architectures, including multiple variants of BERT, as well as ELECTRA (Clark et al. , 2020), BART (Lewis et al. , 2020), and XLNet (Yang et al. , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
BERT Busters: Outlier Dimensions that Disrupt Transformers,2,"Multiple studies of BERT-family models (Devlin et al. , 2019) showed that Transformers are remarkably robust to pruning (Gordon et al. , 2020; Prasanna et al. , 2020; Michel et al. , 2019).",4,"Figure 1: Transformer encoder layer, adapted from (Vaswani et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
BERT Busters: Outlier Dimensions that Disrupt Transformers,3,"that this effect holds for different Transformerfamily architectures, including multiple variants of BERT, as well as ELECTRA (Clark et al. , 2020), BART (Lewis et al. , 2020), and XLNet (Yang et al. , 2019).",4,"Figure 1: Transformer encoder layer, adapted from (Vaswani et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Adverse drug events and medication relation extraction in electronic health records with ensemble deep learning methods,0,"Results: Our team ranked third with a micro-averaged F1 score of 94.72% and 87.65% for relation and end-toend relation extraction, respectively (Tracks 2 and 3).",1,1 Clinical narratives and electronic health records (EHRs) constitute a rich source for ADE evidence.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Adverse drug events and medication relation extraction in electronic health records with ensemble deep learning methods,0,"Results: Our team ranked third with a micro-averaged F1 score of 94.72% and 87.65% for relation and end-toend relation extraction, respectively (Tracks 2 and 3).",2,"To tackle this issue, natural language processing (NLP) techniques have been widely applied on EHRs to automatically extract ADE-related information using relation extraction (RE) methods.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Adverse drug events and medication relation extraction in electronic health records with ensemble deep learning methods,1,1 Clinical narratives and electronic health records (EHRs) constitute a rich source for ADE evidence.,2,"To tackle this issue, natural language processing (NLP) techniques have been widely applied on EHRs to automatically extract ADE-related information using relation extraction (RE) methods.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,0,Neural-based summarization models suffer from the length limitation of text encoder.,12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",12,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,1,"Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents.",12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",11,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,2,1Text summarization is an important task of natural language processing which aims to distil salient contents from a textual document.,12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",10,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.",4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.",5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.",6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.",7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.",8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.",9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.",10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.",11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,3,"Existing summarization models can be roughly classified into two categories, which are abstractive and extractive.",12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]",9,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,4,Abstractive summarization usually adopts natural language generation technology to produce a wordby-word summary.,12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]",8,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).",6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).",7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).",8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).",9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).",10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).",11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,5,"In general, these approaches are flexible but may yield disfluent summaries (Liu and Lapata , 2019a).",12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]",7,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).",7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).",8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).",9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).",10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).",11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,6,"By comparison, extractive approaches aim to select a subset of the sentences in the source document, thereby enjoying better fluency and efficiency (Cao et al. , 2017).",12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]",6,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.",8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.",9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.",10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.",11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,7,"Although many summarization approaches have demonstrated their success on relatively short documents, such as news articles, they usually fail Paragraph 1: Medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services.",12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]",5,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….",9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….",10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….",11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,8,"It is a multibillion dollar industry and countries like India, Thailand, Israel, Singapore, … Paragraph 2: The prime driving factors in medical tourism are increased medical costs, increased insurance premiums, increasing number of uninsured or partially insured individuals in developed countries, … …… Paragraph 5: It is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers, however, attributes, which make the product similar to other products, will not….",12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",4,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).",10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).",11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,9,"In addition, the accurate modeling of long texts remains a challenge (Frermann and Klementiev , 2019).",12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]",3,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).",11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,10,"This approach is used in other NLP tasks, such as machine reading comprehension (Wang et al. , 2019b).",12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]",2,no-link
Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,11,"However, such a paradigm is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.",12,Figure 1 shows an example to illustrate this problem.,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]",1,no-link
