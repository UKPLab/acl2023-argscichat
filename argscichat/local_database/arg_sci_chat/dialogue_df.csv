Worker_name,Assignment,Unit,Role,Message,Message Number
WIKLH0A8DL2D35XF0FV,22,43,Proponent,Hello! What is the type of knowledge that is injected in the neural networks?,0
WIKLH0A8DL2D35XF0FV,22,43,Proponent,Interesting! What is the problem used to perform the experiment?,2
WIKLH0A8DL2D35XF0FV,22,43,Proponent,"Yes, thank you",4
WIKLH0A8DL2D35XF0FV,22,43,Proponent,I understand. And how is knowledge injected in these networks?,6
WIKLH0A8DL2D35XF0FV,22,43,Proponent,"yes, thank you!",8
NA730CWH7DUOZ,22,44,Domain Expert,"Hi! We inject domain knowledge from Constrained Satisfaction Problems.
 Facts: 
1. Using a classical constrained problem as a case study grants access to reliable domain knowledge (the declarative formulation), and facilitates the generation of empirical data (problem solutions).
",1
NA730CWH7DUOZ,22,44,Domain Expert,"We employ the Partial Latin Square completion problem. Do you want to know how does it work?
 Facts: 
1. We use as a benchmark the Partial Latin Square (PLS) completion problem,
",3
NA730CWH7DUOZ,22,44,Domain Expert,"You have a partially filled NxN square and you have to complete it with all the values in the range from 1 to N preventing the same value to appear more than once in the same row or column.
 Facts: 
1. We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1..n}, such that no value appears twice on any row or column.
",5
NA730CWH7DUOZ,22,44,Domain Expert,I'm sorry but I have not enough information to answer your question. Do you want to know why we choose the to inject knowledge in a data-driven approach?,7
NA730CWH7DUOZ,22,44,Domain Expert,"Data-driven methods can take into account preferences that are hard to design in Constrained Satisfaction Problem. At the same time data-driven method struggle to preserve feasibility.
 Facts: 
1. Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences)
2. Data-driven methods for constrained problems offer a potential solution for some of these issues, but they may have trouble maintaining feasibility
",9
2MGUXRMB0OCLW,60,119,Proponent,"Hi, what is this paper about?",0
2MGUXRMB0OCLW,60,119,Proponent,This sounds very interesting. How exactly do you inject knowledge in the network?,2
2MGUXRMB0OCLW,60,119,Proponent,"Ok, thanks anyhow. Which kind of problems has the method you propose been applied to?",4
2MGUXRMB0OCLW,60,119,Proponent,"Yes, please. Which kind of CSP problems?",6
2MGUXRMB0OCLW,60,119,Proponent,Thank you. I believe that plugging knowledge into neural architectures is a crucial issue for AI in the coming years. Do you need to encode the knowledge in some language? Does knowledge injection affect training time?,8
2MGUXRMB0OCLW,60,119,Proponent,"Thank you, this is all I wanted to know!",10
NA730CWH7DUOZ,60,120,Domain Expert,"Hi! This paper assess the impact of knowledge injection in a data-driven approach.
 Facts: 
1. Using a classical constrained problem as a case study, we perform controlled experiments to probe the impact of progressively adding domain and empirical knowledge in the DNN.
",1
NA730CWH7DUOZ,60,120,Domain Expert,Unfourtunately I have not enough information to answer your question.,3
NA730CWH7DUOZ,60,120,Domain Expert,"We applied to a particular class of Constrained Satisfaction problem. Do you want to know which one?
 Facts: 
1. One such case is that of Constraint Problems, for which declarative approaches exists and pure ML solutions have obtained mixed success.
2.  As a byproduct of our analysis, we develop general techniques for taking into account constraints in data-driven methods for decision problems, based on easily accessible methods from the Constraint Programming and Machine Learning domains.
",5
NA730CWH7DUOZ,60,120,Domain Expert,"We employ the Partial Latin Square completion problem which require to complete a partially filled NxN square with all the values in the range from 1 to N such that no value appear twice in any row and column.
 Facts: 
1. We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1..n}, such that no value appears twice on any row or column.
",7
NA730CWH7DUOZ,60,120,Domain Expert,"Our method takes inspiration from Constraint Programming  and it can be applied also at test time.
 Facts: 
1. As a byproduct of our analysis, we develop general techniques for taking into account constraints in data-driven methods for decision problems, based on easily accessible methods from the Constraint Programming and Machine Learning domains.
2. We train a problem-agnostic, data-driven, solution approach on a pool of solutions, and we inject domain knowledge (constraints) both at training time and at solution generation time
",9
NA730CWH7DUOZ,60,120,Domain Expert,You are welcome!,11
EBVOMGT2U8GQQZCD462,62,123,Proponent,Hi! What is the article about?,0
EBVOMGT2U8GQQZCD462,62,123,Proponent,Can you tell me how does the attention module work?,2
EBVOMGT2U8GQQZCD462,62,123,Proponent,"Yes, tell me more about it.",4
EBVOMGT2U8GQQZCD462,62,123,Proponent,What kind of corpora was the neural architecture tested on?,6
EBVOMGT2U8GQQZCD462,62,123,Proponent,On which of the two did the architecture perform best?,8
EBVOMGT2U8GQQZCD462,62,123,Proponent,Do you know why this happened?,10
WIKLH0A8DL2D35XF0FV,62,124,Domain Expert,"The article is about a new neural architecture to perform Argument Mining. This architecture features an attention module and is validated on multiple corpora. Which aspect would you like to know more about?
 Facts: 
1. A novel approach to AM, which extends our previous work [7] by introducing an attention module and ensemble learning. Such a model performs multiple AM tasks at the same time, and does not rely on ad-hoc features or rich contextual information
2. A set of experiments designed to assess generality, whereby we test our approach on three additional corpora that vary in domain, style of writing, formatting, length, and annotation model
",1
WIKLH0A8DL2D35XF0FV,62,124,Domain Expert,"I'm sorry, but I don't have information on this aspect. Would you like to know more about the argument mining task instead?
 Facts: 
1. The model exploits neural attention and multi-task learning, jointly addressing the problems of identifying the category of argument components, and predicting the relations among them.
",3
WIKLH0A8DL2D35XF0FV,62,124,Domain Expert,"Argument Mining is a research field related to NLP that concerns the extraction and the classification of arguments and their relationships.
 Facts: 
1. A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1] . AM consists of several different tasks, that include argument detection, stance classification, topic-based argumentative content retrieval, and many others [2] .
2. Such problem comprises the detection of both argument components, and relations (or links) amongst them, and is thus one of the most difficult steps for AM systems.
",5
WIKLH0A8DL2D35XF0FV,62,124,Domain Expert,"It was tested on corpora composed by user-generated comments and by scientific publications
 Facts: 
1. We evaluate it on a challenging data set consisting of usergenerated comments, as well as on two other datasets consisting of scientific publications.
",7
WIKLH0A8DL2D35XF0FV,62,124,Domain Expert,"The best performance was achieved on the first one
 Facts: 
1. On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge. On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.
",9
WIKLH0A8DL2D35XF0FV,62,124,Domain Expert,There is no information available about this. Do you want to know more or are you satisfied?,11
NRT5ANWYUVK5HWE4VY7,63,125,Proponent,Hi! What is this paper about?,0
NRT5ANWYUVK5HWE4VY7,63,125,Proponent,What does it mean 'attentive' network?,2
NRT5ANWYUVK5HWE4VY7,63,125,Proponent,What is the attention module used for?,4
NRT5ANWYUVK5HWE4VY7,63,125,Proponent,"Yes, thank you",6
NRT5ANWYUVK5HWE4VY7,63,125,Proponent,"I would like to know more. For example, what type of argument mining did you do in this research?",8
WIKLH0A8DL2D35XF0FV,63,126,Domain Expert,"Hello! This paper is about a novel neural architecture proposed for the task of Argument Mining.
 Facts: 
1. A novel approach to AM, which extends our previous work [7] by introducing an attention module and ensemble learning
2. We explore the use of residual networks and neural attention for argument mining and in particular link prediction.
",1
WIKLH0A8DL2D35XF0FV,63,126,Domain Expert,"it is not explicitly stated, but it means that the network include a neural attention module
 Facts: 
1. The model exploits neural attention
2. this paper extends the neural architecture with attention and ensemble learning
",3
WIKLH0A8DL2D35XF0FV,63,126,Domain Expert,"I'm sorry, such information is not available. Would you like to know more about the argument mining task?",5
WIKLH0A8DL2D35XF0FV,63,126,Domain Expert,"Argument mining is a research field related to NLP, and concerns the extraction and classification of argumentative components and their relationships in documents. Are you satisfied or would you like to know more?
 Facts: 
1. A RGUMENT mining (AM) is an emerging research area in natural language processing (NLP) which aims to extract arguments from text collections [1] .
2. In this work we focus on the challenging problem of assembling the structure of the argumentation graph of a given input document. Such problem comprises the detection of both argument components, and relations (or links) amongst them, and is thus one of the most difficult steps for AM systems.
",7
WIKLH0A8DL2D35XF0FV,63,126,Domain Expert,"We focus on classifying the category of the component and predicting the relationships
 Facts:
1. The model exploits neural attention and multi-task learning, jointly addressing the problems of identifying the category of argument components, and predicting the relations among them",9
WIKLH0A8DL2D35XF0FV,64,127,Proponent,Hello! Can you give me a general overview of what is this paper about?,0
WIKLH0A8DL2D35XF0FV,64,127,Proponent,Interesting! How did they select those images?,2
WIKLH0A8DL2D35XF0FV,64,127,Proponent,How did they annotate those images? using human annotators or in some unsupervised fashion?,4
WIKLH0A8DL2D35XF0FV,64,127,Proponent,Oh interesting! and have the researchers also conducted any experiment on this dataset?,6
WIKLH0A8DL2D35XF0FV,64,127,Proponent,Why is dataset multimodal?,8
WIKLH0A8DL2D35XF0FV,64,127,Proponent,"Thank you, is there any other aspect worth of mention?",10
EBVOMGT2U8GQQZCD462,64,128,Domain Expert,"The paper explais how a novel dataset of images and potentially offensive comments was created.
 Facts: 
1. In this paper, we present a novel dataset composed of images and comments in Italian
",1
EBVOMGT2U8GQQZCD462,64,128,Domain Expert,"The images were taken randomly from Instagram, but cannot be shared as pictures.
 Facts: 
1. The images, instead, are released as a ResNet-18 neural network trained on ImageNet, similar to recent NLP works (Kruk et al., 2019) , since they were taken from Instagram and cannot be shared as pictures.
",3
EBVOMGT2U8GQQZCD462,64,128,Domain Expert,"The comments were made by teenagers during their school hours, then they were manually assigned to a semantic category.
 Facts: 
1. In this paper, we present a novel dataset composed of images and comments in Italian, created with teenagers in classes using a simulated scenario to raise awareness on cyberbullying phenomena.
2. Potentially offensive comments have been collected for more than 1,000 images and manually assigned to a semantic category.
",5
EBVOMGT2U8GQQZCD462,64,128,Domain Expert,"Unfortunately, I connot provide this information, but the dataset is freely available on Github and can be used for research purposes.
 Facts: 
1. The dataset is freely available on Github 2 and, since the comments were collected with the written consent of parents and teachers, they can be freely used for research purposes, without the ethical implications that would derive from using real data posted by teenage users.
",7
EBVOMGT2U8GQQZCD462,64,128,Domain Expert,"The dataset was analysed from different perspectives. For example the analysys could consider the presence of human subjects or the gender of the people.
 Facts: 
1. We therefore present a novel corpus containing images and potentially offensive Italian comments and we analyse it from different perspectives, to investi-gate whether the subject of the images plays a role in triggering a comment.
2. Our analysis shows that the presence of human subjects, as well as the gender of the people present in the pictures trigger different types of comment, and provides novel insight into the connection between images posted on social media and offensive messages.
",9
EBVOMGT2U8GQQZCD462,64,128,Domain Expert,"The corpus was also compared with a similar one obtained using whatsapp. This comparison showed that comments to images have different characteristics.
 Facts: 
1. We also compare our corpus with a similar one obtained with What-sApp, showing that comments to images show different characteristics compared to text-only interactions.
",11
P315HO7Q5S2GLLYN,65,129,Proponent,- Hello there! Can you provide to me some information about the paper? ,0
P315HO7Q5S2GLLYN,65,129,Proponent,With what strategy were the data collected?,2
P315HO7Q5S2GLLYN,65,129,Proponent,How was the data labeled?,4
P315HO7Q5S2GLLYN,65,129,Proponent,"According to the authors, are there any other datasets like this in other languages?",6
P315HO7Q5S2GLLYN,65,129,Proponent,I think such a dataset could be too conditioned/biased by the type of annotator. What do you think about it?,8
P315HO7Q5S2GLLYN,65,129,Proponent,Is the dataset available and free to use?,10
EBVOMGT2U8GQQZCD462,65,130,Domain Expert,"Hi! This paper explains how a dataset composed of images and comments was collected...
 Facts: 
1. In this paper, we present a novel dataset composed of images and comments in Italian, created with teenagers in classes using a simulated scenario to raise awareness on cyberbullying phenomena.
",1
EBVOMGT2U8GQQZCD462,65,130,Domain Expert,"The images were randomly selected from Instagram and the comments were created by teenagers during their school hours.
 Facts: 
1. The images, instead, are released as a ResNet-18 neural network trained on ImageNet, similar to recent NLP works (Kruk et al., 2019) , since they were taken from Instagram and cannot be shared as pictures.
2. The data collection was carried out in several school classes, being part of a 'living lab' to raise awareness on cyberbullying and, more generally, on the use of social media by teenagers.
",3
EBVOMGT2U8GQQZCD462,65,130,Domain Expert,"The comments were maually assigned to a semantic category.
 Facts: 
1. Potentially offensive comments have been collected for more than 1,000 images and manually assigned to a semantic category.
",5
EBVOMGT2U8GQQZCD462,65,130,Domain Expert,"I cannot provide a complete answer, but collecting data from teenage users can be problematic due to privacy restrictions.
 Facts: 
1. However, when it comes to specific target groups, for example teenagers, collecting such data may be problematic due to issues with consent and privacy restrictions.
",7
EBVOMGT2U8GQQZCD462,65,130,Domain Expert,"The aim of the dataset is to collect data specifically among teenagers to raise awareness on cyberbullying, but I think that collecting data while the teens know what they are doing could make them write less mean comments on purpose.
 Facts: 
1. The data collection was carried out in several school classes, being part of a 'living lab' to raise awareness on cyberbullying and, more generally, on the use of social media by teenagers.
",9
EBVOMGT2U8GQQZCD462,65,130,Domain Expert,"Yes, you can find the comments on github. Unfortunately the images cannot be shared as pictures.
 Facts: 
1. The dataset is freely available on Github 2 and, since the comments were collected with the written consent of parents and teachers, they can be freely used for research purposes, without the ethical implications that would derive from using real data posted by teenage users.
2. The images, instead, are released as a ResNet-18 neural network trained on ImageNet, similar to recent NLP works (Kruk et al., 2019) , since they were taken from Instagram and cannot be shared as pictures.
",11
NRT5ANWYUVK5HWE4VY7,66,131,Proponent,Hi! What is this paper about?,0
NRT5ANWYUVK5HWE4VY7,66,131,Proponent,How was this dataset collected?,2
NRT5ANWYUVK5HWE4VY7,66,131,Proponent,What was the purpose of this data collection?,4
NRT5ANWYUVK5HWE4VY7,66,131,Proponent,What are the limits and challenges of such collection?,6
NRT5ANWYUVK5HWE4VY7,66,131,Proponent,How do the authors used or plan to use these data?,8
NRT5ANWYUVK5HWE4VY7,66,131,Proponent,Where can I find this dataset? Is it available?,10
NRT5ANWYUVK5HWE4VY7,66,131,Proponent,What kind of subjects do the images contain?,12
EBVOMGT2U8GQQZCD462,66,132,Domain Expert,"The paper explains how a dataset of pictures and possibly offensive comments made by teenagers was collected.
 Facts: 
1. In this paper, we present a novel dataset composed of images and comments in Italian, created with teenagers in classes using a simulated scenario to raise awareness on cyberbullying phenomena.
",1
EBVOMGT2U8GQQZCD462,66,132,Domain Expert,"The images were taken from Instagram and the comments were made by teenagers during their school hours.
 Facts: 
1. The data collection was carried out in several school classes, being part of a 'living lab' to raise awareness on cyberbullying and, more generally, on the use of social media by teenagers.
2. The images, instead, are released as a ResNet-18 neural network trained on ImageNet, similar to recent NLP works (Kruk et al., 2019) , since they were taken from Instagram and cannot be shared as pictures.
",3
EBVOMGT2U8GQQZCD462,66,132,Domain Expert,"The authors wanted to collect multimodal data from a specific target group.
 Facts: 
1. However, when it comes to specific target groups, for example teenagers, collecting such data may be problematic due to issues with consent and privacy restrictions.
2. Furthermore, while text-only datasets for abusive language detection have been widely developed and used by the NLP community, limitations set by image-based social media platforms like Instagram make it difficult for researchers to experiment with multimodal data.
",5
EBVOMGT2U8GQQZCD462,66,132,Domain Expert,"Almos all the issues are related to privacy, collecting data from teenagers means that the authorization of their parents is necessary.
 Facts: 
1. However, when it comes to specific target groups, for example teenagers, collecting such data may be problematic due to issues with consent and privacy restrictions.
",7
EBVOMGT2U8GQQZCD462,66,132,Domain Expert,"The authors analysed the data in order to understand if there is a connection between the subject of the image and the comments.
 Facts: 
1.  We therefore present a novel corpus containing images and potentially offensive Italian comments and we analyse it from different perspectives, to investi-gate whether the subject of the images plays a role in triggering a comment.
",9
EBVOMGT2U8GQQZCD462,66,132,Domain Expert,"Yes, the comments are freely available on Github but the images cannot be released in their original form because they were taken from Instagram.
 Facts: 
1. The dataset is freely available on Github 2 and, since the comments were collected with the written consent of parents and teachers, they can be freely used for research purposes, without the ethical implications that would derive from using real data posted by teenage users.
2. The images, instead, are released as a ResNet-18 neural network trained on ImageNet, similar to recent NLP works (Kruk et al., 2019) , since they were taken from Instagram and cannot be shared as pictures.
",11
EBVOMGT2U8GQQZCD462,66,132,Domain Expert,"The images can contain any subject, the analysys considers the presence of humans and their genders.
 Facts: 
1. Our analysis shows that the presence of human subjects, as well as the gender of the people present in the pictures trigger different types of comment, and provides novel insight into the connection between images posted on social media and offensive messages.
",13
NA730CWH7DUOZ,80,159,Proponent,Hi!,0
NA730CWH7DUOZ,80,159,Proponent,"Yes, please. How does explaination is provided?",2
NA730CWH7DUOZ,80,159,Proponent,Can you tell me more about the experimental setup?,4
NA730CWH7DUOZ,80,159,Proponent,What should we talk about now?,6
NA730CWH7DUOZ,80,159,Proponent,Do they say something about comparison with other methods?,8
NA730CWH7DUOZ,80,159,Proponent,Which one is the best among the two methods?,10
EBVOMGT2U8GQQZCD462,80,160,Domain Expert,Hi! Is there something you want to know about the article?,1
EBVOMGT2U8GQQZCD462,80,160,Domain Expert,"I unfortunately cannot provide any detail about the explanation, but I can tell you that the algorithm, called LIME, can explain the prediction of any classifier
 Facts: 
1. LIME, an algorithm that can explain the predictions of any classifier or regressor in a faithful way, by approximating it locally with an interpretable model.
",3
EBVOMGT2U8GQQZCD462,80,160,Domain Expert,"The material I have mostly concerns the utility of this tool, I can only tell you that it was tested with human subjects that decided whether to trust a prediction or not based on the explanations provided by the tool.
 Facts: 
1. We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted
",5
EBVOMGT2U8GQQZCD462,80,160,Domain Expert,"I can tell you more about specific use cases of this tool. For example, it could be very beneficial when it comes to trusting machine learning for mediacal diagnosis.
 Facts: 
1. When using machine learning for medical diagnosis [6] or terrorism detection, for example, predictions cannot be acted upon on blind faith, as the consequences may be catastrophic.
",7
EBVOMGT2U8GQQZCD462,80,160,Domain Expert,"Unfortunately not, they propose two different methods of their own.
 Facts: 
1. • LIME, an algorithm that can explain the predictions of any classifier or regressor in a faithful way, by approximating it locally with an interpretable model. • SP-LIME, a method that selects a set of representative instances with explanations to address the ""trusting the model"" problem, via submodular optimization.
",9
EBVOMGT2U8GQQZCD462,80,160,Domain Expert,"They are different, but I think LIME is the most complete one as it was used by non experts to pick the best out of two classifiers and improve an untrustworthy one.
 Facts: 
1. In our experiments, non-experts using LIME are able to pick which classifier from a pair generalizes better in the real world.
2. Further, they are able to greatly improve an untrustworthy classifier trained on 20 newsgroups, by doing feature engineering using LIME.
",11
7YWIR0MZS3NU43Q32U,81,161,Proponent,What is this article about?,0
7YWIR0MZS3NU43Q32U,81,161,Proponent,Is the approach validated with experiments involving human users?,2
7YWIR0MZS3NU43Q32U,81,161,Proponent,How many datasets are used for validation?,4
7YWIR0MZS3NU43Q32U,81,161,Proponent,What style of interpretable model is used to explain the predictions?,6
7YWIR0MZS3NU43Q32U,81,161,Proponent,"Does the article give a formal definition of ""interpretable"" and ""faithful""?",8
7YWIR0MZS3NU43Q32U,81,161,Proponent,Is the approach applied to natural language tasks?,10
EBVOMGT2U8GQQZCD462,81,162,Domain Expert,"The article explains why understanding the reasons behind a prediction made by a machine learning model can make a difference in its actual use and proposes a new explanation technique.
 Facts: 
1. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.
2. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction.
",1
EBVOMGT2U8GQQZCD462,81,162,Domain Expert,"Yes, using LIME, non experts were able to choose the best one between different classifiers and to improve an untrustworthy one.
 Facts: 
1. In our experiments, non-experts using LIME are able to pick which classifier from a pair generalizes better in the real world.
2. Further, they are able to greatly improve an untrustworthy classifier trained on 20 newsgroups, by doing feature engineering using LIME.
",3
EBVOMGT2U8GQQZCD462,81,162,Domain Expert,"Unfortunately I cannot provide this information, but LIME can be used to explain the prediction of any classifier or regressor.
 Facts: 
1. LIME, an algorithm that can explain the predictions of any classifier or regressor in a faithful way, by approximating it locally with an interpretable model.
",5
EBVOMGT2U8GQQZCD462,81,162,Domain Expert,"I can only tell you that LIME provides this information in an interpretable and faithful manner by learning an interpretable model locally around the prediction.
 Facts: 
1. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction.
",7
EBVOMGT2U8GQQZCD462,81,162,Domain Expert,Unfortunately not in the material at my disposal.,9
EBVOMGT2U8GQQZCD462,81,162,Domain Expert,"LIME was used to improve an untrustworthy classifier trained on newsgroups.
 Facts:
1. Further, they are able to greatly improve an untrustworthy classifier trained on 20 newsgroups, by doing feature engineering using LIME.",11
2MGUXRMB0OCLW,82,163,Proponent,"Hello, what is this paper about?",0
2MGUXRMB0OCLW,82,163,Proponent,I think this is really a very important issue in AI. How does the proposed technique work? Do you extract logic rules?,2
2MGUXRMB0OCLW,82,163,Proponent,On which tasks did you apply LIME?,4
2MGUXRMB0OCLW,82,163,Proponent,"Thank you, this is very interesting indeed. Which do you think is the strongest point of your approach?",6
2MGUXRMB0OCLW,82,163,Proponent,Did you measure performance of the interpretable patterns extracted by LIME?,8
2MGUXRMB0OCLW,82,163,Proponent,"Thank you, this is all I wanted to know!",10
EBVOMGT2U8GQQZCD462,82,164,Domain Expert,"Hi! The paper explains why, in some cases, it is crucial to understand why a machine learning model made a prediction and proposes a new explanation technique.
 Facts: 
1. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.
2. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction.
",1
EBVOMGT2U8GQQZCD462,82,164,Domain Expert,"Unfortunately I cannot provide detailed information, LIME approximates the predictions of any classifier or regressor by approximating it locally with an interpretable model.
 Facts: 
1. LIME, an algorithm that can explain the predictions of any classifier or regressor in a faithful way, by approximating it locally with an interpretable model.
",3
EBVOMGT2U8GQQZCD462,82,164,Domain Expert,"Lime was used by non-experts to pick the best one between two classifiers, to improve an untrustworthy one and for the understanding of the predictions of a neural network on images.
 Facts: 
1. In our experiments, non-experts using LIME are able to pick which classifier from a pair generalizes better in the real world. Further, they are able to greatly improve an untrustworthy classifier trained on 20 newsgroups, by doing feature engineering using LIME.
2. We also show how understanding the predictions of a neural network on images helps practitioners know when and why they should not trust a model.
",5
EBVOMGT2U8GQQZCD462,82,164,Domain Expert,"I think that knowing the reasons behind a prediction could make people trust machine learning systems more, mostly in fields such as the medical one.
 Facts: 
1. When using machine learning for medical diagnosis [6] or terrorism detection, for example, predictions cannot be acted upon on blind faith, as the consequences may be catastrophic.
",7
EBVOMGT2U8GQQZCD462,82,164,Domain Expert,"Unfortunately this information is not in the material at my disposal. But LIME was evaluated with simulated and human subjects.
 Facts: 
1. Comprehensive evaluation with simulated and human subjects, where we measure the impact of explanations on trust and associated tasks.
",9
EBVOMGT2U8GQQZCD462,82,164,Domain Expert,Thank you for your interest! Do you think that a tool like LIME could be helpful in other situations?,11
NA730CWH7DUOZ,83,165,Proponent,Hi!,0
NA730CWH7DUOZ,83,165,Proponent,"Yes, please. What is the paper about?",2
NA730CWH7DUOZ,83,165,Proponent,Can you say something more about the method used to solve the tasks?,4
NA730CWH7DUOZ,83,165,Proponent,Is the method compared to other ones?,6
NA730CWH7DUOZ,83,165,Proponent,Are the results better than state-of-the-art cited in the paper?,8
7YWIR0MZS3NU43Q32U,83,166,Domain Expert,"Hi! do you want to talk about multi-task residual networks for argument mining?
 Facts: 
1. Multi-Task Attentive Residual Networks for Argument Mining
",1
7YWIR0MZS3NU43Q32U,83,166,Domain Expert,"The paper discusses residual network for several argumentative mining tasks, including link prediction
 Facts: 
1. We explore the use of residual networks and neural attention for argument mining and in particular link prediction.
2. We propose a residual architecture that exploits attention, multi-task learning, and makes use of ensemble.
",3
7YWIR0MZS3NU43Q32U,83,166,Domain Expert,"Sure. All tasks are tackled using a single neural network with an attention module and ensemble learning. All tasks are performed jointly. there is no feature engineering.
 Facts: 
1. this paper extends the neural architecture with attention and ensemble learning
2. Such a model performs multiple AM tasks at the same time, and does not rely on ad-hoc features or rich contextual information, but only on GloVe embeddings and on a widely applicable notion of distance
",5
7YWIR0MZS3NU43Q32U,83,166,Domain Expert,"Sure, the paper offers comparisons with other state-of-the-art systems.
 Facts: 
1. this paper extends the neural architecture with attention and ensemble learning, and presents a more thorough and extensive experimental evaluation, offering comparisons with state-of-the-art systems across four different argument mining corpora
",7
7YWIR0MZS3NU43Q32U,83,166,Domain Expert,"This is not clear from the information I have. The method has good performance, but the main advantage seems to be generality.
 Facts: 
1. Experimental results conducted on a variety of different corpora show that the model is robust and achieves good performance across the considered data sets.
2. AM approaches are very often tailored to specific corpora or genres [4] - [6] , with solutions that are seldom general enough to be directly applied to different data sets without the need of any adaptation.
",9
NA730CWH7DUOZ,84,167,Proponent,Hi!,0
NA730CWH7DUOZ,84,167,Proponent,"Yes, please. What are memory networks?",2
NA730CWH7DUOZ,84,167,Proponent,How are MANNs employed to detect and explain unfairness?,4
NA730CWH7DUOZ,84,167,Proponent,It seems very nice idea! Maybe it can be applied to other kind of tasks. What do you think?,6
NA730CWH7DUOZ,84,167,Proponent,Can you give me more details about the experimental setup?,8
NA730CWH7DUOZ,84,167,Proponent,"Yes, please.",10
NA730CWH7DUOZ,84,167,Proponent,"Yes, I am really interested in it.",12
NA730CWH7DUOZ,84,167,Proponent,I think it's enough. Thanks a lot!,14
7YWIR0MZS3NU43Q32U,84,168,Domain Expert,"Hi. Do you want to know something about unfairness detection in consumer contracts?
 Facts: 
1. Detecting and explaining unfairness in consumer contracts through memory networks
",1
7YWIR0MZS3NU43Q32U,84,168,Domain Expert,"Memory networks or MANNs are neural architectures that include a ""memory"" components where knowledge can be stored and used to generate the output
 Facts: 
1. The basic idea behind MANNs is to combine the successful learning strategies developed in the machine learning literature for inference with a memory component that can be read and written to.
2. A MANN can answer these questions by storing in dedicated parts of the network, called memories, all previously seen sentences, so as to retrieve the most relevant facts to a given query.
",3
7YWIR0MZS3NU43Q32U,84,168,Domain Expert,"The memories could be used to store justifications of unfairness given by legal experts. Then these justifications can be used to explain the output
 Facts: 
1. our hypothesis is that useful explanations may be given in terms of rationales, i.e.  ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair.
2. if we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels, then a possible explanation of an unfairness prediction could be constructed based on the list of memories, i.e., the rationales, used by the MANN
",5
7YWIR0MZS3NU43Q32U,84,168,Domain Expert,"Yes indeed. For example, memory networks have been used for question-answering.
 Facts: 
1. Consider for instance the following story:   Joe went to the kitchen.  Fred went to the kitchen. Joe picked up the milk. Joe travelled to the office. Joe left the milk.
2. Joe went to the bathroom. Where is the milk now? Answering the question requires comprehension of the actions ""picked up"" and ""left"" as well as of the time elements of the story (Weston et al. 2014) .  A MANN can answer these questions
",7
7YWIR0MZS3NU43Q32U,84,168,Domain Expert,"The authors created a dataset of annotated Terms of Service and compared the performance of MANNs against relevant baselines. Do you want to know about qualitative evaluation too?
 Facts: 
1. The knowledge base of rationales constituted the basis for creating a corpus of 100 annotated ToS, which we used to train different MANN architecture configurations.
2. We evaluated their performance with respect to relevant baselines, including support vector machine classifiers, convolutional neural networks and long shortmemory networks.
",9
7YWIR0MZS3NU43Q32U,84,168,Domain Expert,"The explanations were also evaluated by domain experts. If you are interested, I can tell you about the outcome of the evaluation
 Facts: 
1. We also run an initial qualitative evaluation with domain experts in order to understand the explanatory efficacy of rationales in this context.
",11
7YWIR0MZS3NU43Q32U,84,168,Domain Expert,"Results are encouraging, and some baselines were outperformed by a significant margin. One interesting thing in this paper is the application of strong supervision. Do you want to know about it?
 Facts: 
1. The results on the new corpus are encouraging. The MANN architectures were able to match or outperform the baselines on all categories of unfair clauses, in some cases by a significant margin.
2. unlike all other baselines, the MANN could provide meaningful references to the relevant rationales
",13
7YWIR0MZS3NU43Q32U,84,168,Domain Expert,Bye,15
NRT5ANWYUVK5HWE4VY7,85,169,Proponent,Hi! What is this article about?,0
NRT5ANWYUVK5HWE4VY7,85,169,Proponent,How were memory networks used for this task?,2
NRT5ANWYUVK5HWE4VY7,85,169,Proponent,"Yes, thank you",4
NRT5ANWYUVK5HWE4VY7,85,169,Proponent,Why are rationales useful?,6
NRT5ANWYUVK5HWE4VY7,85,169,Proponent,I think explainability is very useful in AI. Anything else you would like to tell me about the article?,8
NRT5ANWYUVK5HWE4VY7,85,169,Proponent,That's interesting! Can you tell me something more about this?,10
NRT5ANWYUVK5HWE4VY7,85,169,Proponent,"Ok, thank you! That's all I wanted to know",12
NRT5ANWYUVK5HWE4VY7,85,169,Proponent,Bye,14
7YWIR0MZS3NU43Q32U,85,170,Domain Expert,"This article is an application of memory networks for detecting unfairness in consumer contracts
 Facts: 
1. Detecting and explaining unfairness in consumer contracts through memory networks
",1
7YWIR0MZS3NU43Q32U,85,170,Domain Expert,"memories are used to store rationales. Do you want to know more about rationales?
 Facts: 
1. We thus consider several configurations of memory-augmented neural networks where rationales are given a special role in the modeling of context knowledge.
2. we train a MANN classifier to identify unfair clauses by using as facts the rationales behind unfairness labels
",3
7YWIR0MZS3NU43Q32U,85,170,Domain Expert,"rationales are justifications provided by experts. Anything else you wish to know?
 Facts: 
1. our hypothesis is that useful explanations may be given in terms of rationales, i.e.  ad-hoc justifications provided by legal experts motivating their conclusion to consider a given clause as unfair
",5
7YWIR0MZS3NU43Q32U,85,170,Domain Expert,"The hypothesis is that rationales are useful for explainability. Indeed, initial results are promising. What do you think about the importance of explainability?
 Facts: 
1. in recent years a rich debate has flourished around the opacity of AI systems that, in terms of accuracy, offer unprecedented results, but at the same time cannot be easily inspected in order to find reasons behind blatant and even possibly dangerous mistakes.
2. These results suggest that MANN are a promising way to address the problem of explaining unfairness in consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.
",7
7YWIR0MZS3NU43Q32U,85,170,Domain Expert,"Yes. Something I like about this study is that the method is able to provide references to relevant rationales.
 Facts: 
1. the MANN could provide meaningful references to the relevant rationales, especially if during training the MANN is fed with the information of which rationales are related to which clause, a technique known as strong supervision
",9
7YWIR0MZS3NU43Q32U,85,170,Domain Expert,"I don't have further information about strong supervision, but the method seems promising
 Facts: 
1. These results suggest that MANN are a promising way to address the problem of explaining unfairness in consumer contracts and pave the way to their extensive use in other areas of automated legal text analytics.
",11
7YWIR0MZS3NU43Q32U,85,170,Domain Expert,That's great. Take care,13
7YWIR0MZS3NU43Q32U,85,170,Domain Expert,Bye,15
7YWIR0MZS3NU43Q32U,88,175,Proponent,Hi! Why is annotation projection useful?,0
7YWIR0MZS3NU43Q32U,88,175,Proponent,Is this approach applicable only in legal texts?,2
7YWIR0MZS3NU43Q32U,88,175,Proponent,Can you tell me something more about how the method works?,4
7YWIR0MZS3NU43Q32U,88,175,Proponent,Is the quality of the translation tool an issue?,6
7YWIR0MZS3NU43Q32U,88,175,Proponent,Was the method tested with other language pairs besides English-German?,8
7YWIR0MZS3NU43Q32U,88,175,Proponent,Yes I think the problem is very important. Thank you for the chat.,10
2MGUXRMB0OCLW,88,176,Domain Expert,"Hi! Because you can avoid re-constructing a corpus from scratch, but you can leverage the information coming from the same corpus in another language
 Facts: 
1. the workforce of professionals needed for annotating legal documents may not be readily available in each language
2. Our ultimate goal is to use automatically generated annotations for training linguistic tools for the target language without resorting to expert annotators in that language
",1
2MGUXRMB0OCLW,88,176,Domain Expert,"No, it could be applied to any domain whether you have different versions of the same document.
 Facts: 
1. This would leverage the creation of classifiers that can leverage the linguistic resources available in the target language, to analyze documents in that language
",3
2MGUXRMB0OCLW,88,176,Domain Expert,"We exploit automatic translation tools and a distance between embeddings to find correspondences between the same document, available in to languages.
 Facts: 
1. The solution we propose makes use of an automated translation of the source document into the target document, obtained via a third-party tool, of a sentence-wise dissimilarity metric, and of a method for finding an alignment between warped time series
2. To carry out the present study, we built the first English-German parallel corpus for the task at hand
",5
2MGUXRMB0OCLW,88,176,Domain Expert,"It might be, but this needs further investigation. For sure, the method is language-agnostic.
 Facts: 
1. The main novelty of our study lies in the confluence of three aspects: the projection is performed at sentence-level; the multi-lingual corpus is asymmetric; and the proposed methods are language-agnostic
",7
2MGUXRMB0OCLW,88,176,Domain Expert,"Not in this paper, but we are currently testing two additional languages. Do you think this is an important problem?",9
2MGUXRMB0OCLW,88,176,Domain Expert,Thank you!,11
2MGUXRMB0OCLW,90,179,Proponent,"hello there, what exactly is the main contribution of the paper?",0
2MGUXRMB0OCLW,90,179,Proponent,do you have some sort of definition of argument mining to give me some background?,2
2MGUXRMB0OCLW,90,179,Proponent,many thanks for that. i was wondering how previously mentioned techniques could be employed in the context of argument mining.,4
2MGUXRMB0OCLW,90,179,Proponent,"therefore the idea is to encoded relations in a symbolic way and learn the importance of these relations along with the data-driven approach of deep learning, is that correct?",6
2MGUXRMB0OCLW,90,179,Proponent,"this is indeed quite interesting, i think i've seen many frameworks in this direction. I was wondering if suggested approach (at least current draft) scales well with samples and the number of relations. This is indeed one crucial point to me",8
2MGUXRMB0OCLW,90,179,Proponent,"i see, do you have any more detail that you repute important? ",10
NRT5ANWYUVK5HWE4VY7,90,180,Domain Expert,"Hello! This is a position paper which proposes to use neuro-symbolic and relational learning techniques to address the tasks in argumentation mining
 Facts: 
1. we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal
2. Deep learning is bringing remarkable contributions to the field of argumentation mining, but the existing approaches still need to fill the gap toward performing advanced reasoning tasks
",1
NRT5ANWYUVK5HWE4VY7,90,180,Domain Expert,"Sure! Argument mining is a research area in NLP which aims to extract arguments from unstructured text.
 Facts: 
1. The goal of argumentation mining (AM) is to automatically extract arguments and their relations from a given document
2. Performing and understanding argumentation requires advanced reasoning capabilities, which are natural human skills, but are difficult to learn for a machine
",3
NRT5ANWYUVK5HWE4VY7,90,180,Domain Expert,"Many argument graphs follow some typical rules (i.e., a premise supports a claim, but not the other way round). These rules could be easily encoded in some symbolic language, and used in combination with neural networks or other classifiers.
 Facts: 
1. We envisage that a significant advancement in AM could come from the combination of symbolic and sub-symbolic approaches, such as those developed in the Neural Symbolic (NeSy) (Garcez et al., 2015) or Statistical Relational Learning (SRL) (Getoor and Taskar, 2007; De Raedt et al., 2016; Kordjamshidi
2. We propose to exploit the potential of both symbolic and sub-symbolic approaches for AM, by combining both results in systems that are capable of modeling knowledge and constraints with a logic formalism, while maintaining the computational power of deep networks
",5
NRT5ANWYUVK5HWE4VY7,90,180,Domain Expert,"Yes, indeed. Do you think this might be an interesting research direction?
 Facts: 
1. Differently from existing approaches, we advocate the use of a logic-based language for the definition of contextual dependencies and constraints, independently of the structure of the underlying classifiers
2. Most importantly, the approaches we outline do not exploit a pipeline scheme, but rather perform joint detection of argument components and relations through a single learning process
",7
NRT5ANWYUVK5HWE4VY7,90,180,Domain Expert,"True: scalability is an issue in most neuro-symbolic applications. Unfortunately, we do not present experiments in this work, which is just a position paper.
 Facts: 
1. In this position paper, we posit that neural-symbolic and statistical relational learning could play a crucial role in the integration of symbolic and sub-symbolic methods to achieve this goal
",9
NRT5ANWYUVK5HWE4VY7,90,180,Domain Expert,"It is worth mentioning that this goes into the direction widely recognized nowadays in AI of not relying just on deep learning for many tasks (even in NLP) but to introduce techniques that can exploit domain knowledge, and perform reasoning.
 Facts: 
1. Despite the remarkable impact of deep neural networks in NLP, we argue that these techniques alone will not suffice to address such complex issues
2. This issue is also widely recognized as one of the major challenges for the whole field of artificial intelligence in the coming years (LeCun et al., 2015)
",11
RBZBJO7DWMF386,228,455,Proponent,"Hi, what exactly is meant by lexical inference?",0
RBZBJO7DWMF386,228,455,Proponent,"Ok, so the labels are the classical entailment labels (entailment, neutral, contradiction)?",2
RBZBJO7DWMF386,228,455,Proponent,"Ok, so do they build a dataset for that?",4
RBZBJO7DWMF386,228,455,Proponent,What makes their new models special?,6
RBZBJO7DWMF386,228,455,Proponent,"Before I can answer your question, I need to clarify something. The patterns are a form of ""prompts""? Like additional tokens prepended or appended to the input?",8
RBZBJO7DWMF386,228,455,Proponent,Ah ok. It is interesting that such simple techniques help. This is not a few-shot setting right? So the model has full access to the training data?,10
RBZBJO7DWMF386,228,455,Proponent,"I see. Thanks for the interesting conversation, I am terminating now.",12
7K6YUIHA8ADPUAF7MY,228,456,Domain Expert,"Hi, lexical inference means that the inference is focused on lexical semantics.
 Facts: 
1. Lexical inference in context (LIiC) is the task of recognizing textual entailment between two very similar sentences, i.e., sentences that only differ in one expression.
2. It can therefore be seen as a variant of the natural language inference task that is focused on lexical semantics.
",1
7K6YUIHA8ADPUAF7MY,228,456,Domain Expert,"That is a good question. Let me clarify: It is a binary classification task. So the labels are entailment vs. non-entailment.
 Facts: 
1. Lexical inference (LI) denotes the task of deciding whether or not an entailment relation holds between two lexical items.
",3
7K6YUIHA8ADPUAF7MY,228,456,Domain Expert,"No, they propose new models based on pretrained language models for the task. They evaluate them on two existing benchmarks.
 Facts: 
1. We formulate and evaluate the first approaches based on pretrained language models (LMs) for this task
2. our experiments on two established LIiC benchmarks
",5
7K6YUIHA8ADPUAF7MY,228,456,Domain Expert,"The task inputs are fed to the language models in a context of textual patterns corresponding the two classes of the task. This outperforms approaches that do not use these patterns. What do you think about this pattern-based approach?
 Facts: 
1. We introduce the concept of antipatterns, patterns that express non-entailment, and evaluate their usefulness for LIiC.
2. all our approaches consistently outperform previous work, thus setting a new state of the art for LIiC.
",7
7K6YUIHA8ADPUAF7MY,228,456,Domain Expert,"Yes, this is like ""prompts"". The additional tokens can be before the two sentences, between them, after them, or a combination of the three.
 Facts: 
1. a relation induction approach based on handcrafted patterns expressing the semantics of lexical inference
",9
7K6YUIHA8ADPUAF7MY,228,456,Domain Expert,"There are no large-scale training set for the LIiC task.
 Facts: 
1. supervised NLI models need large amounts of training data, which is unavailable for LIiC
",11
7K6YUIHA8ADPUAF7MY,228,456,Domain Expert,Thank you for your interest!,13
659GTFVXPTWQ35H4,271,541,Proponent,"Hi, it is an interesting paper title. What kind of knowledge does domain knowledge refer to here.",0
659GTFVXPTWQ35H4,271,541,Proponent,"Interesting, how are you injecting the domain knowledge?",2
659GTFVXPTWQ35H4,271,541,Proponent,Have been previous Machine Learning approaches been drastically failing on this kind of task?,4
659GTFVXPTWQ35H4,271,541,Proponent,"Yes, what are their advantages.",6
659GTFVXPTWQ35H4,271,541,Proponent,But for some cases you still require domain knowledge? How did you test that?,8
4N27DHGPN6Y1TMU,271,542,Domain Expert,"Hi! We refer to the knowledge supplied by the expert when designing a Constraint Satisfaction Problem.
 Facts: 
1. Constrained problem are classically modeled by domain experts in a fully declarative fashion
",1
4N27DHGPN6Y1TMU,271,542,Domain Expert,"We have developed a technique inspired by Constraint Programming.
 Facts: 
1. we develop general techniques for taking into account constraints in data-driven methods for decision problems, based on easily accessible methods from the Constraint Programming and Machine Learning domains.
",3
4N27DHGPN6Y1TMU,271,542,Domain Expert,"Actually, they struggle to provide feasible assignements but they have some advantages. Do you want to know which ones?
 Facts: 
1. Data-driven methods for constrained problems offer a potential solution for some of these issues, but they may have trouble maintaining feasibility
",5
4N27DHGPN6Y1TMU,271,542,Domain Expert,"They can take into account some constraints that are not easy to be modelled by the domain expert but that are satisfied in past solutions.
 Facts: 
1. Constrained problem are classically modeled by domain experts in a fully declarative fashion: however, such models can be hard to design, may rely on simplistic and unquantifiable approximations, and may fail to take into account constraints (or preferences)
",7
4N27DHGPN6Y1TMU,271,542,Domain Expert,"Unfortunately, I have not enough information to answer your question.",9
M1FC9X9WUPLX,272,543,Proponent,Hi! What is the constrained problem mentioned in the title?,0
M1FC9X9WUPLX,272,543,Proponent,"Yes, please. What is Partial Latin Square completion problem?",2
M1FC9X9WUPLX,272,543,Proponent,"Thank you for the explanation. Then, what is the domain knowledge in this case?",4
M1FC9X9WUPLX,272,543,Proponent,"I see. Then, how do they inject the domain knowledge in the neural network?",6
M1FC9X9WUPLX,272,543,Proponent,"so, is it done by adding the constraints in the loss function?",8
M1FC9X9WUPLX,272,543,Proponent,it seems fine since it is possible to obtain domain knowledge. But I'm not sure whether it is possible to adapt this approach to other domains such as NLP or computer vision. What do you think?,10
M1FC9X9WUPLX,272,543,Proponent,I see. Thank you for your explanations. Good bye,12
4N27DHGPN6Y1TMU,272,544,Domain Expert,"Hi! We consider the Partial Latin Square completion problem. Do you want to know how does it work?
 Facts: 
1. We use as a benchmark the Partial Latin Square (PLS) completion problem
",1
4N27DHGPN6Y1TMU,272,544,Domain Expert,"It requires to complete a partially filled NxN square with all the values in the range from 1 to N, preventing the same value to appear more than once in the same row or column.
 Facts: 
1. We use as a benchmark the Partial Latin Square (PLS) completion problem, which requires to complete a partially filled n × n square with values in {1..n}, such that no value appears twice on any row or column.
",3
4N27DHGPN6Y1TMU,272,544,Domain Expert,"It is the declarative formulation of the constrained problem.
 Facts: 
1. Using a classical constrained problem as a case study grants access to reliable domain knowledge (the declarative formulation)
",5
4N27DHGPN6Y1TMU,272,544,Domain Expert,"Our method is inspired by Constraint Programming.
 Facts: 
1. we develop general techniques for taking into account constraints in data-driven methods for decision problems, based on easily accessible methods from the Constraint Programming and Machine Learning domains.
",7
4N27DHGPN6Y1TMU,272,544,Domain Expert,I am sorry but I have not enough information to answer your question. Do you think that the Partial Latin Square is a suitable benchmark?,9
4N27DHGPN6Y1TMU,272,544,Domain Expert,"I think that the main application are Constraints Satisfaction Problems.
 Facts: 
1. Hence, despite our focus remains on a scientific investigation, we also regard this paper as a relevant step towards practical applicability for some data-driven solution methods for constrained problems.
",11
4N27DHGPN6Y1TMU,272,544,Domain Expert,Bye!,13
ZL1QIN1PM89T,306,611,Proponent,Hi,0
ZL1QIN1PM89T,306,611,Proponent,Is this work about natural language processing or social sciences?,2
ZL1QIN1PM89T,306,611,Proponent,How is the study conducted?,4
ZL1QIN1PM89T,306,611,Proponent,How many annotators were involved in corpus creation?,6
ZL1QIN1PM89T,306,611,Proponent,Interesting work. What features are more indicative of parody?,8
ZL1QIN1PM89T,306,611,Proponent,"There may be some links to other NLP tasks, like irony detection. What do you think?",10
ZL1QIN1PM89T,306,611,Proponent,How about fact checking?,12
ZL1QIN1PM89T,306,611,Proponent,Great work. Thanks for the chat,14
O7EHDLLLN7GRZPTQN2,306,612,Domain Expert,Hi!,1
O7EHDLLLN7GRZPTQN2,306,612,Domain Expert,"This is work about natural language processing.
 Facts: 
1. In this paper, we present the first computational study of parody.
",3
O7EHDLLLN7GRZPTQN2,306,612,Domain Expert,"First, we are collecting data from Twitter. Then, we perform on analysis of the data. Finally, we train models on our data to predict whether a tweet is parody or not.
 Facts: 
1. We introduce a new publicly available data set of tweets from real politicians and their corresponding parody accounts. We run a battery of supervised machine learning models for automatically detecting parody tweets
2. Finally, we identify the markers of parody through a linguistic analysis.
",5
O7EHDLLLN7GRZPTQN2,306,612,Domain Expert,"The corpus was created by automatically retrieving tweets from parody accounts. Parody accounts were identified by the authors of this work. In total, 4 researchers took a look at the data.
 Facts: 
1. For this task, we create a new large-scale publicly available data set containing a total of 131,666 English tweets from 184 parody accounts and corresponding real accounts of politicians from the US, UK and other countries
",7
O7EHDLLLN7GRZPTQN2,306,612,Domain Expert,"In our work we examine political parody. In political parody, exaggerated views and caricatures are the main features. Posts are also made to mimic real facts, but with a humorous twist.
 Facts: 
1. Parody tweets can often be misinterpreted as facts
2. these accounts play with stereotypes of these figures or juxtapose their public image with a very different, behind-closed-doors persona. A very popular type of parody is political parody which plays an important role in public speech by offering irreverent interpretations of political personas
",9
O7EHDLLLN7GRZPTQN2,306,612,Domain Expert,"I agree with this statement. Irony can be used to make a parody post, so detecting irony could facilitate better parody detection as well.
 Facts: 
1. While closely related figurative devices such as irony and sarcasm have been extensively studied in computational linguistics (Wallace, 2015; Joshi et al., 2017) , parody yet to be explored using computational methods.
2. We argue that understanding the expression and use of parody in natural language and automatically identifying it are important to applications in computational social science and beyond.
",11
O7EHDLLLN7GRZPTQN2,306,612,Domain Expert,"While fact checking could definitely help, I believe we would not get enough use out of fact checking. Verifying facts can be very challenging and gains would be minimal. Furthermore, while parody can indeed be misinterpreted as facts, it mostly relies on the style of writing (ie. mimicking the real politician) and not so much the content.
 Facts: 
1. Parody tweets can often be misinterpreted as facts
",13
O7EHDLLLN7GRZPTQN2,306,612,Domain Expert,"Thank you, have a nice day!",15
7K6YUIHA8ADPUAF7MY,307,613,Proponent,"Hi, how is political parody defined the paper?",0
7K6YUIHA8ADPUAF7MY,307,613,Proponent,Can it be detected automatically in social media posts?,2
7K6YUIHA8ADPUAF7MY,307,613,Proponent,"Can the model distinguish political parody from other forms of parody? The definition seemed to allow for non-political parody, too.",4
7K6YUIHA8ADPUAF7MY,307,613,Proponent,"I see. So the model distinguishes political parody from other posts without any parody, yes? Is it possible that the model only detects the political topic without learning about parody at all?",6
7K6YUIHA8ADPUAF7MY,307,613,Proponent,That is very interesting. The resource sounds very useful. Are there annotations on the tweet-level or do you assume that a parody account only tweets parody and the others don't? Could the model be fooled into an author identification task?,8
7K6YUIHA8ADPUAF7MY,307,613,Proponent,That is very convincing. Thank you for the explanations. Could you tell me a bit about the analyzing part?,10
O7EHDLLLN7GRZPTQN2,307,614,Domain Expert,"Parody is defined as a means to mimic behavior of a target for comedic purposes.
 Facts: 
1. Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts.
2. Parody is a figurative device which is used to imitate and ridicule a particular target (Rose, 1993) and has been studied in linguistics as a figurative trope distinct to irony and satire (Kreuz and Roberts, 1993; Rossen-Knill and Henry, 1997) . Traditional forms of parody include editorial cartoons
",1
O7EHDLLLN7GRZPTQN2,307,614,Domain Expert,"It can! In this work we show that we can reach an F1 score of up to 90% using neural-based deep learning methods.
 Facts: 
1. Our results show that political parody tweets can be predicted with an accuracy up to 90%
2. Experiments with feature-and neural-based machine learning models for parody detection, which achieve high predictive accuracy of up to 89.7% F1.
",3
O7EHDLLLN7GRZPTQN2,307,614,Domain Expert,"Here we only collected political parody data, so the models only learn to identify data in that domain. We have not investigated whether the same model could detect general parody. I believe that while it is possible to detect non-political parody, more general data would be needed for that task.
 Facts: 
1. Beyond NLP, parody detection can be used in: (i) political communication, to study and understand the effects of political parody in the public speech on a large scale (Hariman, 2008; Highfield, 2016) ; (ii) linguistics, to identify characteristics of figurative language (Rose, 1993; Kreuz and Rober
",5
O7EHDLLLN7GRZPTQN2,307,614,Domain Expert,"The data is all in the political domain. Data comes from politician accounts as well as political parody accounts. So, the model operates entirely within the political domain, and learns to separate between parody and non-parody data.
 Facts: 
1. For this task, we create a new large-scale publicly available data set containing a total of 131,666 English tweets from 184 parody accounts and corresponding real accounts of politicians from the US, UK and other countries
",7
O7EHDLLLN7GRZPTQN2,307,614,Domain Expert,"Annotations are on the account level. That is, a parody account only tweets parody, while a real account only tweets normal speech. I do not believe this task will be reduced to author identification though. In our experiments, we also predict parody from previously unseen accounts (both parody and real) with the model performing well on those. This goes to show that the model is able to identify parody to an adequate level.)
 Facts: 
1. test data from: a) users; b) genders; c) locations; unseen in training
2. Traditional forms of parody include editorial cartoons, sketches or articles pretending to have been authored by the parodied person. 2 A new form of parody recently emerged in social media, and Twitter in particular, through accounts that impersonate public figures.
",9
O7EHDLLLN7GRZPTQN2,307,614,Domain Expert,"We performed a linguistic analysis, showing that a major difference between politician and parody accounts is the use of first-person pronouns in parody accounts. We also analyzed errors on the model's side, with humorous tweets from real politician's sometimes being confused for parody.
 Facts: 
1. Linguistic analysis of the markers of parody tweets and of the model errors
",11
ZL1QIN1PM89T,346,691,Proponent,Hi! What is this paper about?,0
ZL1QIN1PM89T,346,691,Proponent,What architecture is used for question generation?,2
ZL1QIN1PM89T,346,691,Proponent,How about the metrics? How are results measured?,4
ZL1QIN1PM89T,346,691,Proponent,"I think it makes sense, and it also seems to work. Anything else worth mentioning about this paper?",6
ZL1QIN1PM89T,346,691,Proponent,Thank you for the clarification. The intuition makes sense. Bye,8
M1FC9X9WUPLX,346,692,Domain Expert,"Hi! The goal of this paper is to improve question generation by dividing the task into two: interrogative word prediction and the generation of the rest of the question.
 Facts: 
1. The main claim of our work is that separating the two tasks (i.e., interrogative-word classification and question generation) can lead to a better performance. 
2. In this work, we propose Interrogative-Word-Aware Question Generation (IWAQG), a pipelined system composed of two modules: an interrogative word classifier and a QG model.
",1
M1FC9X9WUPLX,346,692,Domain Expert,The exact architecture of the question generation model is not described in the Introduction.,3
M1FC9X9WUPLX,346,692,Domain Expert,"It is mentioned that their approach achieves a new state-of-the-art on SQuAD using the metrics METEOR and ROUGE-L. What do you think about their hypothesis? Does it make sense for you to generate the interrogative word independently?
 Facts: 
1. The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.
",5
M1FC9X9WUPLX,346,692,Domain Expert,"I think that's all. They mentioned that their hypothesis makes the generation of the interrogative word easier since it's a classification task.
 Facts: 
1. the interrogative word classification task is easier to solve than generating the interrogative word along with the full question in the QG model
",7
M1FC9X9WUPLX,346,692,Domain Expert,Thank you. Good bye,9
GW8BIL9F6SJ9CIN,347,693,Proponent,"hi, is the paper about question generation? ",0
GW8BIL9F6SJ9CIN,347,693,Proponent,Why is interrogative classifier used in this model?,2
GW8BIL9F6SJ9CIN,347,693,Proponent,"Yes, makes sense to me. What data set is used to train a classifier? ",4
GW8BIL9F6SJ9CIN,347,693,Proponent,"As long as I know, SQuAD is a question-answering dataset. I'm not sure if this dataset is suitable for question word clarification. What do you think?",6
M1FC9X9WUPLX,347,694,Domain Expert,"Hi! Yes! It is. They propose a pipelined composed of two parts: an interrogative word classifier and a question generation model
 Facts: 
1. In this work, we propose Interrogative-Word-Aware Question Generation (IWAQG), a pipelined system composed of two modules: an interrogative word classifier and a QG model.
",1
M1FC9X9WUPLX,347,694,Domain Expert,"That is a good question! They argue that classifying the interrogative word is easier that generating it along with the rest of the question. What do you think about this intuition? Does it make sense for you?
 Facts: 
1. The main claim of our work is that separating the two tasks (i.e., interrogative-word classification and question generation) can lead to a better performance.
2. the interrogative word classification task is easier to solve than generating the interrogative word along with the full question in the QG model
",3
M1FC9X9WUPLX,347,694,Domain Expert,"They conduct experiments on SQuAD. Do you think SQuAD is a good benchmark for this?
 Facts: 
1. The proposed model achieves new state-of-theart results on the task of QG in SQuAD, improving from 46.58 to 47.69 in 21.24 to 22.33 in METEOR, and from 44.53 to 46.94 in ROUGE-L.
",5
M1FC9X9WUPLX,347,694,Domain Expert,"It is not clarification, but prediction. Since SQuAD includes questions, answers, and context, it would be possible to use the answers to create questions for them.
 Facts: 
1. We assume this setting and consider that the answer is a span of the passage, as in SQuAD.
",7
659GTFVXPTWQ35H4,366,731,Proponent,"Hi, what is the paper about?",0
659GTFVXPTWQ35H4,366,731,Proponent,"That is interesting, how are the annotators then training during the annotation?",2
659GTFVXPTWQ35H4,366,731,Proponent,So the difficulty of their annotations increment over time. Do you think this comes with an increase in total annotation time for the coder?,4
659GTFVXPTWQ35H4,366,731,Proponent,"Ok, that's what I wanted to know. Another point I would be interested is how do you assess the difficulty of a sample? Like how do you determine the order of data you show the annotator?",6
659GTFVXPTWQ35H4,366,731,Proponent,How do the non-adaptive measures perform compared to the adaptive ones?,8
1OTOYRFX5WFOF1T,366,732,Domain Expert,"Hi, the paper is about investigating strategies that implicitly train annotators during their annotations.
 Facts: 
1. To alleviate these issues, this work proposes annotation curricula, a novel approach to implicitly train annotators.
",1
1OTOYRFX5WFOF1T,366,732,Domain Expert,"The basic idea comes from curriculum learning that aims to provide exercises to a (human) learner in an ordering that matches their learning proficiency. Our goal is to implement such a learning curriculum for annotation studies by assessing the difficulty of annotated instances.
 Facts: 
1. The learning curriculum is a fundamental concept in educational research that proposes to order exercises to match a learner's proficiency (Vygotsky 1978; Krashen 1982) and has even motivated training strategies for machine learning models (Bengio et al. 2009 ).
2. Similarly, the goal of annotation curricula (AC) is to provide an ordering of instances during annotation that is optimized for learning the task.
",3
1OTOYRFX5WFOF1T,366,732,Domain Expert,"Sorry, I am not sure if I follow the question. By coder, do you mean the person setting up the study? If you mean the annotator; we restricted our experiments to a finite set of instances that is annotated. So the total annotation time for annotating these instances does actually decrease with a good curriculum.
 Facts: 
1. The results show that annotators who receive the same instances in an optimized order require significantly less annotation time while retaining a high annotation quality.
",5
1OTOYRFX5WFOF1T,366,732,Domain Expert,"To estimate the difficulty, we investigate several methods. Non-adaptive ones like heuristics (e.g., sentence length) and adaptive ones that are models that are trained interactively to predict the annotation time (we use this as a proxy for difficulty). Finally, in this work we only investigate easy-instances-first strategies, so the annotated instances are sorted in ascending difficulty.
 Facts: 
1. evaluate heuristic and interactively trained estimators on three English datasets that provide annotation time which we use as an approximation of the annotation difficulty for evaluation.
2. We instantiate AC with an ""easy-instancesfirst"" strategy 
",7
1OTOYRFX5WFOF1T,366,732,Domain Expert,"Overall, we find that the heuristic ones perform quite well. In fact, our best performing estimator was using the BERT mlm loss (this is not in the displayed text, but an analysis is provided in the results section). 
 Facts: 
1. The results show that using a simple heuristic to order instances can already significantly reduce the total annotation time while preserving a high annotation quality.
",9
J8LYV0HJRTXHMI1,407,813,Proponent,what is the main idea of the paper?,0
J8LYV0HJRTXHMI1,407,813,Proponent,can you describe how does the query be updated?,2
J8LYV0HJRTXHMI1,407,813,Proponent,"Yes, please tell me more how to deal long documents",4
J8LYV0HJRTXHMI1,407,813,Proponent,how does the model decide when to retrieve a sentence or a paragraph?,6
QHUYA2WFITGO,407,814,Domain Expert,"Hello! The main idea is to approach multi-hop and sequential question answering on long documents using semantic indexing and dense-space query updates. This enables end-to-end training and higher performance.
 Facts: 
1. At each step, DOCHOPPER retrieves a paragraph or sentence embedding from the document, mixes the retrieved result with the query, and updates the query for the next step.
2. This means that model is end-to-end differentiable.
",1
QHUYA2WFITGO,407,814,Domain Expert,"The query is updated, intuitively speaking, by computing the residual query information that is not covered by the answer of the previous hop. This happens in the embedding space using simple vector operations. Would you like to know more about how the system deals with long documents?
 Facts: 
1.  At each retrieval step, DOCHOPPER retrieves a candidate (paragraph or sentence) from the index and updates the query for the next step of retrieval.
",3
QHUYA2WFITGO,407,814,Domain Expert,"The transformer-based model ETC is used that is based on sparse attention. This does not only allow longer input token length, but also enables modeling paragraphs (and hereby document structure) very naturally. 
 Facts: 
1. Transformer models that use sparse self-attention have been introduced
2. ETC  introduced a global-local attention mechanism, where local tokens only attend to the global tokens they are assigned to, while global tokens attend to each other to communicate information across a document.
",5
QHUYA2WFITGO,407,814,Domain Expert,"Good question! Both are represented in the vector space and the one most fitting one for the question is selected.
 Facts: 
1. At each retrieval step, DOCHOPPER retrieves a candidate (paragraph or sentence) from the index and updates the query for the next step of retrieval.
",7
659GTFVXPTWQ35H4,409,817,Proponent,"Hi, interesting paper title. How do you add the syntactic information into the word representations?",0
659GTFVXPTWQ35H4,409,817,Proponent,Which kind of graph neural network do you experimented with?,2
659GTFVXPTWQ35H4,409,817,Proponent,Do GCNs come with special properties which helps for the task?,4
659GTFVXPTWQ35H4,409,817,Proponent,"Yes, please. Which objectives did the model try to solve?",6
659GTFVXPTWQ35H4,409,817,Proponent,And which pre-trained word representations did you use?,8
659GTFVXPTWQ35H4,409,817,Proponent,How did you evaluate the improvement of the new word representations?,10
J8LYV0HJRTXHMI1,409,818,Domain Expert,"we build a syntactic graph neural model that takes pre-trained word representations as feature input. The pre-trained word representations and the GNN are used as contextualized word representations in downstream tasks.
 Facts: 
1. SIWRs are then obtained by applying the model to downstream task data and extracting the intermediate word representations.
",1
J8LYV0HJRTXHMI1,409,818,Domain Expert,"We use a graph convolutional neural network (GCN). 
 Facts: 
1. the SIWR model extends a graph convolutional neural network (GCN) and builds on top of these word representations.
",3
J8LYV0HJRTXHMI1,409,818,Domain Expert,"The word graph is built on syntactic dependency and other types of connections such as word order connections. Do you want to know what objectives the model trained on?
 Facts: 
1. Since in English word order is important, we preserve it by adding these connections into the graph layer.
",5
J8LYV0HJRTXHMI1,409,818,Domain Expert,"The model is trained for part-of-speech tagging and syntactic dependency parsing.
 Facts: 
1. The SIWR model jointly predicts part-of-speech (POS) tags and syntactic dependencies.
",7
J8LYV0HJRTXHMI1,409,818,Domain Expert,"Our model can take both static and contextualized word representations including GloVe, ELMo and BERT.
 Facts: 
1. a graph-based neural model is built on top of either static or contextualised word representations such as GloVe, ELMo and BERT.
2. We first prepare pre-trained static and contextual word representations, e.g., GloVe, ELMo, and contextual BERT, as the base representations.
",9
J8LYV0HJRTXHMI1,409,818,Domain Expert,"We compare performance of using the word representations in the downstream tasks compared to using the base representations. The downstream tasks include a nested named entity recognition and two relation extraction tasks.
 Facts: 
1. We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).
2. In addition, we implement BERT [19] in both contextual and fine-tuning methods on nested NER and binary RE.
",11
A15W4SQ7B5RKJ8X,410,819,Proponent,Hi! Thanks for joining. Can you explain what is the main idea of the paper?,0
A15W4SQ7B5RKJ8X,410,819,Proponent,What type of syntactic information do you use? Is it based on dependency or constituency? ,2
A15W4SQ7B5RKJ8X,410,819,Proponent,Sounds great! What tasks do you test?,4
A15W4SQ7B5RKJ8X,410,819,Proponent,Can you tell me why you only select part-of-speech and dependency as the syntactic information you want to use to help pretraining?,6
A15W4SQ7B5RKJ8X,410,819,Proponent,Thanks for explaining. I love to see the results of injecting other types of information. Do you think if it would be a good idea if you try to inject syntactic information beginning from pretraining from scratch?,8
J8LYV0HJRTXHMI1,410,820,Domain Expert,"This paper proposes a method to incorporate syntactic information into pre-trained word representations using a graph neural network.
 Facts: 
1. we propose new syntactically-informed word representations (SIWRs), which allow us to enrich the pre-trained word representations with syntactic information without training language models from scratch.
2. To obtain SIWRs, a graph-based neural model is built on top of either static or contextualised word representations such as GloVe, ELMo and BERT.
",1
J8LYV0HJRTXHMI1,410,820,Domain Expert,"We use part-of-speech and syntactic dependency. 
 Facts: 
1. The syntactic information, i.e., part-of-speech (POS) tags and dependencies (see example in Fig. 1 ; in this paper, we use the term ''syntactic information"" interchangeably with ''POS tags"" and ''dependencies""), has been well studied and can be obtained efficiently with high accuracy using existing 
",3
J8LYV0HJRTXHMI1,410,820,Domain Expert,"We evaluate the extracted word representations on a nested named entity recognition task and two relation extraction tasks.
 Facts: 
1. We compare the enriched SIWRs with their base representations ELMo [5] and biomedical word embeddings (PubMed) [21] on the existing models in three downstream NLP tasks: (a) nested named entity recognition (nested NER), (b) relation extraction (RE) and (c) n-ary relation extraction (n-ary RE).
2. In addition, we implement BERT [19] in both contextual and fine-tuning methods on nested NER and binary RE.
",5
J8LYV0HJRTXHMI1,410,820,Domain Expert,"Previous work shows that part-of-speech and dependency are useful for downstream tasks. However, this doesn't limit the use of other information such as coreference in our model.
 Facts: 
1. Recent studies have shown that downstream task performance may benefit from linguistic structures such as syntactic information [11, 12] , even when contextual word representations and pre-trained models are also used [13] [14] [15] .
",7
J8LYV0HJRTXHMI1,410,820,Domain Expert,"We cannot answer given the current content. We can inject syntactic information during pre-training from scratch, however, this will cost more time and computational resources. Intermediate pretraining allows us to directly incorporate additional information into pre-trained models.
 Facts:
1. We propose new syntactically-informed word representations (SIWRs), which allow us to enrich the pre-trained word representations with syntactic information without training language models from scratch.",9
J8LYV0HJRTXHMI1,412,823,Proponent,Hello! Interesting question as the title. Do you have any conclusion in this paper?,0
J8LYV0HJRTXHMI1,412,823,Proponent,10 to 100 million is a rather large range of data. What is the difference between learning from 10 or 100 million words?,2
J8LYV0HJRTXHMI1,412,823,Proponent,Can you tell me more about the information-theoretic probing?,4
J8LYV0HJRTXHMI1,412,823,Proponent,Which model did you use in your experiments?,6
J8LYV0HJRTXHMI1,412,823,Proponent,"Besides the finding regarding number of training data, do you also have other findings?",8
J8LYV0HJRTXHMI1,412,823,Proponent,"To integrate other forms of knowledge in a less data scenario, does the model require labeled data? Can we include such knowledge by defining knowledge-specific objectives and learning on the unlabeled data?",10
A15W4SQ7B5RKJ8X,412,824,Domain Expert,"Yes! We show that most linguistic features can be learned with training data between 10 million and 100 million, while the rest requires more.
 Facts: 
1. We find that LMs require only about 10M or 100M words to learn representations that reliably encode most syntactic and semantic features we test.
2. A much larger quantity of data is needed in order to acquire enough commonsense knowledge and other skills required to master typical downstream NLU tasks.
",1
A15W4SQ7B5RKJ8X,412,824,Domain Expert,"The performances of our four testing cases related to syntactic information leverage the most compared to other scales.
 Facts: 
1. We adopt four probing methods classifier probing, information-theoretic probing, unsupervised relative acceptability judgment, and fine-tuning on NLU tasks-and draw learning curves that track the growth of these different measures of linguistic ability with respect to pretraining data volume
",3
A15W4SQ7B5RKJ8X,412,824,Domain Expert,Sorry but I can only answer the questions where I can find in the abstract or introduction.,5
A15W4SQ7B5RKJ8X,412,824,Domain Expert,"We use RoBERTa-base and MiniBERTas which are RoBERTa models pretrained on scaled down data.
 Facts: 
1. with respect to pretraining data volume using the MiniBERTas, a group of RoBERTa models pretrained on 1M, 10M, 100M and 1B words.
",7
A15W4SQ7B5RKJ8X,412,824,Domain Expert,"We also find that commonsense knowledge could be a direction guiding pretraining of language models.
 Facts: 
1. A much larger quantity of data is needed in order to acquire enough commonsense knowledge and other skills required to master typical downstream NLU tasks.
2. it is likely that other forms of knowledge are the major drivers of recent improvements in language understanding among large pretrained models.
",9
A15W4SQ7B5RKJ8X,412,824,Domain Expert,"I believe we can define specific objectives regarding this, though we didn't mention what exactly to do in the paper.
 Facts: 
1. The results suggest that, while the ability to encode linguistic features is almost certainly necessary for language understanding, it is likely that other forms of knowledge are the major drivers of recent improvements in language understanding among large pretrained models.
",11
ZBI0E7L22JAUS,446,891,Proponent,"Hello there, what are some examples for explicit dialogue act labels?",0
ZBI0E7L22JAUS,446,891,Proponent,How is dialogue coherence defined?,2
ZBI0E7L22JAUS,446,891,Proponent,"I see, and how do authors suggest evaluating dialogue coherence without using ecplicit labels?",4
ZBI0E7L22JAUS,446,891,Proponent,"Sounds like an interesting approach, what type of models are examined for this purpose?",6
ZBI0E7L22JAUS,446,891,Proponent,"Yes, I think it makes sense. How do the models perform? Do the scores they give correlate with expectations?",8
GW8BIL9F6SJ9CIN,446,892,Domain Expert,"Hi, The given text does not provide any specific example of DA. However, DA seems to related to what a speaker intention is of saying a sentence
 Facts: 
1. A DA captures what a speaker's intention is of saying an utterance without regard to the actual content of the utterance. For example, a DA may indicate whether the intention of stating an utterance is to ask a question or to state a piece of information. 
",1
GW8BIL9F6SJ9CIN,446,892,Domain Expert,"dialogue coherence deals with the semantic and DA's relations between sentence in a dialogue. 
 Facts: 
1. Dialogue coherence deals with semantic relations between utterances considering their dialogue acts 
",3
GW8BIL9F6SJ9CIN,446,892,Domain Expert,"The remove DA labels from the test set. They perturb the order of sentences in a dialogue. Then check how well a coherence model can distinguish an original dialogue from its perturbation..
 Facts: 
1. We utilize perturbation methods, like utterance ordering and utterance insertion, inherited from coherence evaluation approaches for monologue texts, and also introduce two dialoguerelevant perturbations, named utterance replacement and even utterance ordering.
",5
GW8BIL9F6SJ9CIN,446,892,Domain Expert,"A neural model consisting of three modules: sentence encoder, coherence score prediction, and DA prediction. The model is trained in MTL regime. Does it make sense to you? 
 Facts: 
1. Our approach consists of three high-level components: an utterance encoder, a dialogue coherence model (DiCoh) , and a Dialogue Act Prediction (DAP) model.
",7
GW8BIL9F6SJ9CIN,446,892,Domain Expert,"the evaluation is performed on two datasets. On one the model outperforms the SoTA. On the other one the model works on par with SoTA. Do you think that alleviating the need for DA labels during evaluation is important? 
 Facts: 
1.  an empirical evaluation on two benchmark dialogue corpora, showing that our model substantially outperforms the state-of-the-art coherence model on DailyDialog, and performs on par with it on SwitchBoard.
",9
4N27DHGPN6Y1TMU,447,893,Proponent,Hi!,0
4N27DHGPN6Y1TMU,447,893,Proponent,What is the paper about?,2
4N27DHGPN6Y1TMU,447,893,Proponent,Can you give me more details about the method?,4
4N27DHGPN6Y1TMU,447,893,Proponent,It seems a pretty nice idea! How have you shown that the method work?,6
4N27DHGPN6Y1TMU,447,893,Proponent,That's good! Which evaluation metrics are employed?,8
4N27DHGPN6Y1TMU,447,893,Proponent,I think that can be done since the method has already demonstrated amazing results on quite different tasks and the aim is to learn general-purpose contextual representation. What should we talk next?,10
4N27DHGPN6Y1TMU,447,893,Proponent,Can you give more details about it?,12
RBZBJO7DWMF386,447,894,Domain Expert,Hi,1
RBZBJO7DWMF386,447,894,Domain Expert,"This paper is about a novel pre-training method for QA
 Facts: 
1. This paper proposes a pre-training objective based on question answering (QA) for learning general-purpose contextual representations
",3
RBZBJO7DWMF386,447,894,Domain Expert,"Sure, it is based on the intuition that the representations of a phrase in a passage should be similar to the representations of the questions this passage can answer. 
 Facts: 
1. This paper proposes a pre-training objective based on question answering (QA) for learning general-purpose contextual representations, motivated by the intuition that the representation of a phrase in a passage should encode all questions that the phrase can answer in context. 
",5
RBZBJO7DWMF386,447,894,Domain Expert,"They test their method on zero-shot and few-shot QA as well as on other tasks that they frame as QA. 
 Facts: 
1. We show large improvements over both RoBERTa-large and previous state-of-theart results on zero-shot and few-shot paraphrase detection on four datasets, few-shot named entity recognition on two datasets, and zero-shot sentiment analysis on three datasets.
",7
RBZBJO7DWMF386,447,894,Domain Expert,Unfortunately I can't answer that. I wonder if this technique could be applied on other tasks. What do you think about that?,9
RBZBJO7DWMF386,447,894,Domain Expert,Would you like to know about their data augmentation strategy?,11
RBZBJO7DWMF386,447,894,Domain Expert,"They use a question generation model and train it on a QA dataset to increase the training data size. Could you terminate the session? I need to go to the next one :D
 Facts: 
1. We accomplish this goal by training a bi-encoder QA model, which independently encodes passages and questions, to match the predictions of a more accurate cross-encoder model on 80 million synthesized QA pairs.
",13
ZBI0E7L22JAUS,448,895,Proponent,"Hi there, How do author suggest infusing question answering capabilities to language models during pretraining?",0
ZBI0E7L22JAUS,448,895,Proponent,"I see, do authors use a multi task learning regieme? What kind of objective do they suggest?",2
ZBI0E7L22JAUS,448,895,Proponent,"I see, do you think it makes sense for questions and passages that answer those questions to have similar representations? Or something more sophisticated is necessary?",4
ZBI0E7L22JAUS,448,895,Proponent,Sounds impressive results. Do authors also experiment with fine-tuning the models after pretrainings?,6
ZBI0E7L22JAUS,448,895,Proponent,"I see, If I understand correctly, authors use some labelled data and perform some supervised training during the pretraining. Is this correct?",8
ZBI0E7L22JAUS,448,895,Proponent,and do they also compare or combine their pretraining approach with finetuning approach? ,10
ZBI0E7L22JAUS,448,895,Proponent,"thansk, that is all I wanted to know, Bye :D",12
RBZBJO7DWMF386,448,896,Domain Expert,"Yes, it is a novel pre-training method based on QA. 
 Facts: 
1. This paper proposes a pre-training objective based on question answering (QA) for learning general-purpose contextual representations, 
",1
RBZBJO7DWMF386,448,896,Domain Expert,"Their objective is based on the notion that a question and all the passages that answer the question should have a similar representation. 
 Facts: 
1. Our intuition is that the representation for a phrase should contain enough information to identify all the questions that the phrase could answer in context.
",3
RBZBJO7DWMF386,448,896,Domain Expert,"It seems to make sense, as they report strong performance on QA and other tasks framed as QA. 
 Facts: 
1. We show large improvements over both RoBERTa-large and previous state-of-theart results on zero-shot and few-shot paraphrase detection on four datasets, few-shot named entity recognition on two datasets, and zero-shot sentiment analysis on three datasets.
",5
RBZBJO7DWMF386,448,896,Domain Expert,"I think they mostly do few-shot experiments. 
 Facts: 
1. In this paper, we introduce a new pre-training loss based on question answering that depends much more directly on context, and learns improved token-level representations for a range of zero-and few-shot tasks.
",7
RBZBJO7DWMF386,448,896,Domain Expert,"Yes, in fact they use a data augmentation approach, where they first generate questions from context passages, then train a cross-encoder to answer these questions and finally use the cross-encoder outputs to pre-train their model.
 Facts: 
1. We accomplish this goal by training a bi-encoder QA model, which independently encodes passages and questions, to match the predictions of a more accurate cross-encoder model on 80 million synthesized QA pairs.
",9
RBZBJO7DWMF386,448,896,Domain Expert,"I think yes, but I don't have more information on this unfortunately. Could you terminate the session, I think the next person is waiting :D Thanks!",11
RBZBJO7DWMF386,448,896,Domain Expert,Bye,13
Z41MJ90P9PCW65H,449,897,Proponent,"Hi, what is the subject of this article?",0
Z41MJ90P9PCW65H,449,897,Proponent,This sounds quite interesting. What is this new pre-training objective?,2
Z41MJ90P9PCW65H,449,897,Proponent,"Ah, okay. Do they use already existing datasets or did they provide one on their own?",4
Z41MJ90P9PCW65H,449,897,Proponent,"Okay. This sounds computational expensive, doesn't it?",6
Z41MJ90P9PCW65H,449,897,Proponent,Okay. Do they only use RoBERTa as pre-trained language model? ,8
Z41MJ90P9PCW65H,449,897,Proponent,Yes.,10
Z41MJ90P9PCW65H,449,897,Proponent,Okay. Thank you for your time!,12
RBZBJO7DWMF386,449,898,Domain Expert,"Hi, this article is about a novel pre-training method based on question answering. 
 Facts: 
1. This paper proposes a pre-training objective based on question answering (QA) for learning general-purpose contextual representations,
",1
RBZBJO7DWMF386,449,898,Domain Expert,"The new pre-training objective is based on the intuition that the representation of a phrase in a passage should be similar to the representations of the questions it answers.
 Facts: 
1. This paper proposes a pre-training objective based on question answering (QA) for learning general-purpose contextual representations, motivated by the intuition that the representation of a phrase in a passage should encode all questions that the phrase can answer in context. 
",3
RBZBJO7DWMF386,449,898,Domain Expert,"They use an existing dataset to train a question generation model. 
 Facts: 
1. We accomplish this goal by training a bi-encoder QA model, which independently encodes passages and questions, to match the predictions of a more accurate cross-encoder model on 80 million synthesized QA pairs.
",5
RBZBJO7DWMF386,449,898,Domain Expert,"Yes, but I think the question generation needs to be done only once to generate the pre-training data, then the model can be used in zero-shot and few-shot settings. Also it is trained as a bi-encoder, which is more efficient than a cross-encoder. 
 Facts: 
1. We show large improvements over both RoBERTa-large and previous state-of-theart results on zero-shot and few-shot paraphrase detection on four datasets, few-shot named entity recognition on two datasets, and zero-shot sentiment analysis on three datasets.
2. We accomplish this goal by training a bi-encoder QA model, which independently encodes passages and questions, to match the predictions of a more accurate cross-encoder model on 80 million synthesized QA pairs.
",7
RBZBJO7DWMF386,449,898,Domain Expert,You mean as a comparison?,9
RBZBJO7DWMF386,449,898,Domain Expert,"In the information I have only Roberta is named. 
 Facts: 
1. We show large improvements over both RoBERTa-large and previous state-of-theart results on zero-shot and few-shot paraphrase detection on four datasets, few-shot named entity recognition on two datasets, and zero-shot sentiment analysis on three datasets.
",11
RBZBJO7DWMF386,449,898,Domain Expert,"Sure, thank you for your interest!",13
Z41MJ90P9PCW65H,450,899,Proponent,"Hi, what is this paper about?",0
Z41MJ90P9PCW65H,450,899,Proponent,This sounds quite interesting. You wrote that the interactions can be across sentences. How much sentences can such an interaction span?,2
Z41MJ90P9PCW65H,450,899,Proponent,"Yes, sure! Which models are used? I can imagine that they build upon pre-trained language models, did they?",4
Z41MJ90P9PCW65H,450,899,Proponent,Okay. Did they use existing datasets or do they provide one on their own?,6
Z41MJ90P9PCW65H,450,899,Proponent,"In the title, it is said, that they are using an ensemble of models but from our discussion I understood that they just trained different approaches and compared them with each other. Is that correct?",8
Z41MJ90P9PCW65H,450,899,Proponent,"Ah, okay. Thanks for your time!",10
J8LYV0HJRTXHMI1,450,900,Domain Expert,"Hi! This papers presents an ensemble of three deep learning models for extracting interactions between drugs and medical entities. The interactions can be within sentence or across sentences. 
 Facts: 
1. This article describes our participation to the n2c2 shared-task in extracting relations between medication-related entities in electronic health records.
2. We additionally developed separate models for intra-and inter-sentence relation extraction and combined them using an ensemble method.
",1
J8LYV0HJRTXHMI1,450,900,Domain Expert,"Unfortunately, the presented text doesn't include such information. You can find it in the full paper. Do you want to know which models are used for intra- and inter-sentence relation extraction?",3
J8LYV0HJRTXHMI1,450,900,Domain Expert,"Not at all, these models only use static pre-trained word representations. The intra-sentence models are BiLSTM-based with attention mechanisms. The inter-sentence model is a Transformer-based network but not initialized by a pre-trained model.
 Facts: 
1. The intra-sentence models rely on bidirectional long short-term memory networks and attention mechanisms and are able to capture dependencies between multiple related pairs in the same sentence.
2. For the inter-sentence relations, we adopted a neural architecture that utilizes the Transformer network to improve performance in longer sequences.
",5
J8LYV0HJRTXHMI1,450,900,Domain Expert,"The data is from the n2c2 shared-task.
 Facts: 
1. This article describes our participation to the n2c2 shared-task in extracting relations between medication-related entities in electronic health records.
",7
J8LYV0HJRTXHMI1,450,900,Domain Expert,"An ensemble approach is used to combine these models. More details are described in another section.
 Facts: 
1. Our ensemble effectively takes advantages from our proposed models.
",9
J8LYV0HJRTXHMI1,450,900,Domain Expert,Thanks!,11
A15W4SQ7B5RKJ8X,451,901,Proponent,Hi! Can you explain the main idea of the paper?,0
A15W4SQ7B5RKJ8X,451,901,Proponent,Interesting! I was wondering what kinds of model are you doing with the ensemble method?,2
A15W4SQ7B5RKJ8X,451,901,Proponent,I see. How do you ensemble model/model predictions?,4
A15W4SQ7B5RKJ8X,451,901,Proponent,No problem. Would you like to explain how you do the analysis/ablation study if the information is available?,6
A15W4SQ7B5RKJ8X,451,901,Proponent,Good to hear about systems with more training data. Did you check how the pretraining affect this generalization?,8
J8LYV0HJRTXHMI1,451,902,Domain Expert,"This paper presents an ensemble of different models for the extraction of relations between drugs and medical entities.
 Facts: 
1. We proposed an ensemble approach for relation extraction and classification between drugs and medication-related entities.
2. This article describes our participation to the n2c2 shared-task in extracting relations between medication-related entities in electronic health records.
",1
J8LYV0HJRTXHMI1,451,902,Domain Expert,"We use different models for intra- and inter-sentence relation extraction. The intra-sentence models are based on BiLSTM with attention mechanisms. The inter-sentence model is a Transformer-based one. 
 Facts: 
1. The intra-sentence models rely on bidirectional long short-term memory networks and attention mechanisms and are able to capture dependencies between multiple related pairs in the same sentence.
2. For the inter-sentence relations, we adopted a neural architecture that utilizes the Transformer network to improve performance in longer sequences.
",3
J8LYV0HJRTXHMI1,451,902,Domain Expert,"Unfortunately, the presented text doesn't have information regarding the ensemble method. ",5
J8LYV0HJRTXHMI1,451,902,Domain Expert,"We have analysis showing that our approach is more generalized than systems with more training data. We also show that the use of implicit drug-drug interactions, which are not annotated, improve the performance of extracting relations between drugs and medical entities.
 Facts: 
1. Analysis of the reported results indicated that our proposed approach is more generalizable than the top-performing system, which employs additional training data-and corpus-driven processing techniques.
2. Analysis showed that by using latent Drug-Drug interactions we were able to significantly improve the performance of non-Drug-Drug pairs in EHRs.
",7
J8LYV0HJRTXHMI1,451,902,Domain Expert,"Sorry, the current text cannot address this question. ",9
659GTFVXPTWQ35H4,452,903,Proponent,"Hi, interesting paper title. What kind of deep learning methods did you use?",0
659GTFVXPTWQ35H4,452,903,Proponent,Relation extraction usually requires that you find named entities. Do you assume the named entities are given?,2
659GTFVXPTWQ35H4,452,903,Proponent,And why do you use ensemble methods? Is a simple deep network not enough?,4
659GTFVXPTWQ35H4,452,903,Proponent,How well are these methods doing?,6
659GTFVXPTWQ35H4,452,903,Proponent,This is a high F1 score. Are there any other advantages you observed during the experiments?,8
J8LYV0HJRTXHMI1,452,904,Domain Expert,"We use BiLSTM with attention mechanisms in intra-sentence models and Transformer-based network for inter-sentence relation extraction. 
 Facts: 
1. The intra-sentence models rely on bidirectional long short-term memory networks and attention mechanisms and are able to capture dependencies between multiple related pairs in the same sentence.
2. For the inter-sentence relations, we adopted a neural architecture that utilizes the Transformer network to improve performance in longer sequences.
",1
J8LYV0HJRTXHMI1,452,904,Domain Expert,"We have two scenarios. One uses named entity recognition models to obtain entities.
 Facts: 
1. We incorporated state-of-the-art named-entity recognition (NER) models based on bidirectional long short-term memory (BiLSTM) networks and conditional random fields (CRF) for end-to-end extraction.
",3
J8LYV0HJRTXHMI1,452,904,Domain Expert,"We use separate models to deal with intra- and inter-sentence relations, which performs better than using a single model. 
 Facts: 
1. We additionally developed separate models for intra-and inter-sentence relation extraction and combined them using an ensemble method.
",5
J8LYV0HJRTXHMI1,452,904,Domain Expert,"Our approach gets 94.72% in terms of micro-averaged F1 score for relation extraction and 87.65% for end-to-end RE.
 Facts: 
1. Our team ranked third with a micro-averaged F1 score of 94.72% and 87.65% for relation and end-toend relation extraction, respectively (Tracks 2 and 3).
",7
J8LYV0HJRTXHMI1,452,904,Domain Expert,"Yes, there are some interesting findings. We show that our approach is more generalized than systems with more training data or additional processing techniques. We also present the usefulness of implicit drug-drug interactions (which are not annotated) for extracting relations between drugs and medical entities.
 Facts: 
1. Analysis of the reported results indicated that our proposed approach is more generalizable than the top-performing system, which employs additional training data-and corpus-driven processing techniques.
2. Analysis showed that by using latent Drug-Drug interactions we were able to significantly improve the performance of non-Drug-Drug pairs in EHRs.
",9
4N27DHGPN6Y1TMU,453,905,Proponent,Hi!,0
4N27DHGPN6Y1TMU,453,905,Proponent,What is the paper about?,2
4N27DHGPN6Y1TMU,453,905,Proponent,Can you give me more information about what a position model is?,4
4N27DHGPN6Y1TMU,453,905,Proponent,"So embeddings and self-attention manipulations are the main position modes, is it correct?",6
4N27DHGPN6Y1TMU,453,905,Proponent,Does the authors provide a common benchmark to compare the methods?,8
4N27DHGPN6Y1TMU,453,905,Proponent,I think the theoretical comparison is much more important than the experimental one. Which one of two categories of position models is better?,10
4N27DHGPN6Y1TMU,453,905,Proponent,I was wondering if one of the two is more spread than the other.,12
7K6YUIHA8ADPUAF7MY,453,906,Domain Expert,Hi!,1
7K6YUIHA8ADPUAF7MY,453,906,Domain Expert,"The paper is about position models in the Transformer architecture.
 Facts: 
1. In this paper, we provide an overview of common methods to incorporate position information into Transformer models.
",3
7K6YUIHA8ADPUAF7MY,453,906,Domain Expert,"The Transformer itself cannot see the order of its input tokens. A position model is what helps the Transformer to see the order. This can be embeddings or other manipulations of the self-attention.
 Facts: 
1. Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.
2. A Transformer model itself is invariant with respect to re-orderings of the input.
",5
7K6YUIHA8ADPUAF7MY,453,906,Domain Expert,"Yes, this is correct. There are a lot of variants but these are the two main categories.
 Facts: 
1. Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.
",7
7K6YUIHA8ADPUAF7MY,453,906,Domain Expert,"No, there is no empirical evaluation mentioned. But they compare the methods on a theoretical level. They also characterize which position model should go with what type of application. Do you think this is useful without a new benchmark?
 Facts: 
1. enabling the reader to compare existing methods by providing a unified notation and meaningful clustering
2. indicating what characteristics of an application should be taken into account when selecting a position encoding
",9
7K6YUIHA8ADPUAF7MY,453,906,Domain Expert,"I agree that the theoretical comparison can give a lot of insights. I do not think that it can really answer the question which position model is ""best"". What criterion for ""being best"" do you have in mind?",11
7K6YUIHA8ADPUAF7MY,453,906,Domain Expert,"I do not have information about the frequency that the different types of position models occur. I believe that showing the large variety of models and analyzing their differences and common points is the main contribution of the paper.
 Facts: 
1. The objectives of this survey are to i) showcase that position information in Transformer is a vibrant and extensive research area;
",13
1OTOYRFX5WFOF1T,454,907,Proponent,"Hi, what is this work about?",0
1OTOYRFX5WFOF1T,454,907,Proponent,What do you mean with position information? Like indices of tokens?,2
1OTOYRFX5WFOF1T,454,907,Proponent,So what approaches of encoding position information does this work investigate?,4
1OTOYRFX5WFOF1T,454,907,Proponent,"Yes, some examples would be great!",6
1OTOYRFX5WFOF1T,454,907,Proponent,"So between those two, what works better and for which tasks?",8
1OTOYRFX5WFOF1T,454,907,Proponent,Then let me ask a different question; is there a possibility of including positional information can hurt the model's performance? Has this been observed?,10
1OTOYRFX5WFOF1T,454,907,Proponent,"Good question, I'd expect that in situations where positional information does not matter, models may get biased with additional noise.",12
1OTOYRFX5WFOF1T,454,907,Proponent,Maybe an attention based approach that is explicitly trained in both kind of tasks could handle them separately. What do you think?,14
7K6YUIHA8ADPUAF7MY,454,908,Domain Expert,"Hi, it is about the Transformer model and specifically about ways to encode position information.
 Facts: 
1. In this paper, we provide an overview of common methods to incorporate position information into Transformer models.
2. Transformers are arguably the main workhorse in recent Natural Language Processing research.
",1
7K6YUIHA8ADPUAF7MY,454,908,Domain Expert,"Yes, I mean word order. A sentence only makes sense in the right order. A bag of words is ambiguous.
 Facts: 
1. text data is inherently sequential
2. Without position information the meaning of a sentence is not well-defined (e.g., the sequence ""the cat chases the dog"" vs. the multi-set { the, the, dog, chases, cat }).
",3
7K6YUIHA8ADPUAF7MY,454,908,Domain Expert,"There is a large variety of position models that is investigated. One contribution of the paper is to show this variety. Shall I give you some examples?
 Facts: 
1. The objectives of this survey are to i) showcase that position information in Transformer is a vibrant and extensive research area;
2. Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.
",5
7K6YUIHA8ADPUAF7MY,454,908,Domain Expert,"Position embeddings representing absolute token index or the relative distance between tokens is an example. Another is injecting this information into the self-attention matrix. One work also uses an RNN to ""positionalize"" the input.
 Facts: 
1. Adding position information can be done by using position embeddings, manipulating attention matrices, or preprocessing the input with a recurrent neural network.
",7
7K6YUIHA8ADPUAF7MY,454,908,Domain Expert,"Unfortunately, I do not have access to that information. But there is a discussion of matching position models to tasks later in the paper.
 Facts: 
1. indicating what characteristics of an application should be taken into account when selecting a position encoding
",9
7K6YUIHA8ADPUAF7MY,454,908,Domain Expert,"This is an interesting question. For natural language, this does not seem to be the case. What do you think about that?
 Facts: 
1. it should be beneficial to incorporate this essential inductive bias into any model that processes text data.
",11
7K6YUIHA8ADPUAF7MY,454,908,Domain Expert,I agree. A task like this should have a lightweight position model if any.,13
7K6YUIHA8ADPUAF7MY,454,908,Domain Expert,"In my opinion, the invariance to order can also be a strength for certain tasks. But I think it would be harder for an attention-based approach to ignore the position model if it is once trained without and once trained with it. Was this your suggestion?
 Facts: 
1. a Transformer is invariant with respect to reorderings of the input
",15
RBZBJO7DWMF386,455,909,Proponent,"Hi, the title sounds interesting, can you tell me more about the paper?",0
RBZBJO7DWMF386,455,909,Proponent,"No thanks, I am familiar with transformers. Is it a pure literature review of different ways to encode position in transformers, or do the authors also conduct experiments?",2
RBZBJO7DWMF386,455,909,Proponent,"Ah I see, so they state if there are better and worse ones?",4
RBZBJO7DWMF386,455,909,Proponent,Do they state if there are particular things to look out for when working with long documents?,6
RBZBJO7DWMF386,455,909,Proponent,Ah that is interesting. Is there a specific purpose for the paper?,8
RBZBJO7DWMF386,455,909,Proponent,Is there a predominant method for position encodings that most people use?,10
7K6YUIHA8ADPUAF7MY,455,910,Domain Expert,"Hi, I agree that the title sounds interesting. The main topic of the paper is the Transformer model. Do you need information on this model?
 Facts: 
1. The Transformer model as introduced by Vaswani et al. (2017)
2. Transformers are arguably the main workhorse in recent Natural Language Processing research.
",1
7K6YUIHA8ADPUAF7MY,455,910,Domain Expert,"It is a survey paper. The main contribution is a theoretical overview of existing position models and no empirical analysis.
 Facts: 
1. The objectives of this survey are to i) showcase that position information in Transformer is a vibrant and extensive research area; ii) enable the reader to compare existing methods by providing a unified notation and meaningful clustering;
",3
7K6YUIHA8ADPUAF7MY,455,910,Domain Expert,"I do not think that the main goal is to define better or worse. It is more about identifying similarities and differences (supported by the unified notation). They do have a discussion on matching a given task to a certain kind of application though.
 Facts: 
1. broad overview of relevant work on position information in Transformers that systematically aggregates and categorizes existing approaches and analyzes the differences between them
2. indicating what characteristics of an application should be taken into account when selecting a position encoding
",5
7K6YUIHA8ADPUAF7MY,455,910,Domain Expert,"I do not have access to any concrete findings. But the position models of long document Transformers are certainly part of the survey. The authors state that they aim to complete the paper with newly published papers.
 Facts: 
1. We plan to actively continue adding papers that we missed or that are newly published.
",7
7K6YUIHA8ADPUAF7MY,455,910,Domain Expert,"They main purpose is to highlight the similarities and differences in existing position models. In that way, new possibilities for position encodings might be more evident. I think this work can be useful for the creators of new models.
 Facts: 
1. enabling the reader to compare existing methods by providing a unified notation and meaningful clustering
2. providing stimuli for future research
",9
7K6YUIHA8ADPUAF7MY,455,910,Domain Expert,"No, not really. There is a lot going on and even ""old"" position models sometimes come back in a slight variant because they have a specific property that is useful for a new model or task.
 Facts: 
1. Overall there is a huge variety of methods that add both absolute and relative position information to Transformer model.
",11
1OTOYRFX5WFOF1T,457,913,Proponent,"Hi, what are information-seeking questions?",0
1OTOYRFX5WFOF1T,457,913,Proponent,Can you give an example for that?,2
1OTOYRFX5WFOF1T,457,913,Proponent,"Yes, please tell me more about how the data was collected and annotated.",4
1OTOYRFX5WFOF1T,457,913,Proponent,Was there any quality assurance process included between both steps?,6
1OTOYRFX5WFOF1T,457,913,Proponent,"Hm, too bad. If we don't know how good the data is, doesn't this make it difficult to assess the performance of any model?",8
1OTOYRFX5WFOF1T,457,913,Proponent,"Hm, interesting. What models were investigated and on which QA tasks were they evaluated?",10
QHUYA2WFITGO,457,914,Domain Expert,"Hi! Information seeking questions are goal-priented questions that seek for specific information in a specific paper unlike e.g. open domain questions.
 Facts: 
1. Readers of academic research papers often read with the goal of answering specific questions
2. xisting informationseeking question answering datasets usually contain questions about generic factoid-type information.
",1
QHUYA2WFITGO,457,914,Domain Expert,"Sure! An example would be your initial question ""What are information-seeking questions?"". For this data a set of NLP experts was asked to come up with  questions on a paper based on title and abstract. Would you like to know more about the annotation process?
 Facts: 
1.  Each question is written by an NLP practitioner who read only the title and abstract of the corresponding paper, and the question seeks information present in the full text.
",3
QHUYA2WFITGO,457,914,Domain Expert,"For a limited set of papers the first set of NLP experts would come up with the mentioned information-seeking questions. Another set of experts was then presented the questions and had to write an answer and provide evidence from the paper (if possible).
 Facts: 
1. a dataset of 5,049 questions over 1,585 Natural Language Processing papers. Each question is written by an NLP practitioner 
2. questions are then answered by a separate set of NLP practitioners who also provide supporting evidence
",5
QHUYA2WFITGO,457,914,Domain Expert,"I cannot answer this from abstract and introduction. But you might be interested in model performance on the data, right?",7
QHUYA2WFITGO,457,914,Domain Expert,"Yes, this is very true. In fact, the model performance is rather low, suggesting possibly a very high complexity of the task - or possibly an ill-defined task setup.
 Facts: 
1. We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F 1 points when answering them from entire papers
",9
QHUYA2WFITGO,457,914,Domain Expert,LED and IR-baselines were used. The dataset combines multiple question types that require yes/no answers or full sentences from the paper.,11
QHUYA2WFITGO,460,919,Proponent,Hi! What is the main idea of the paper?,0
QHUYA2WFITGO,460,919,Proponent,"Yes, that sounds very smart! Is the effect of potential biases introduced this way investigated?",2
QHUYA2WFITGO,460,919,Proponent,"Yes, it does! I see that the underlying data domain are tweets on Covid-19 -- can you tell me more about the dataset used??",4
QHUYA2WFITGO,460,919,Proponent,"I see! I think it seems like a moderately difficult task, although I could imagine there are some ambiguities. I would say it is fitting. Can you tell me how the different sorting strategies looked like?",6
QHUYA2WFITGO,460,919,Proponent,"Yes, while it might not cover the whole complexity of difficulty this is the quantity we are most interested in the end. Time and hereby money for annotation. I am wondering, did the annotation quality of the ""non-trained"" annotators increase towards the end of the study too?",8
NE5B69XTPI25X7F,460,920,Domain Expert,"The main idea of this paper is to train annotators by sorting annotations by e.g. their difficulty so that they are gradually  introduced to the annotation project. Do you think that is a reasonable idea?
 Facts: 
1. The goal is to gradually introduce annotators into the task by ordering instances that are annotated according to a learning curriculum.
",1
NE5B69XTPI25X7F,460,920,Domain Expert,"We conducted a carefully constructed user study with 40 participants that showed improvements using our methods compared to not sorting and we saw no big impact in annotation quality while reducing annotation speed. Does this answer your question?
 Facts: 
1. Finally, we apply our strategy and its best estimators in a carefully designed user study with 40 participants for annotating English tweets about the Covid-19 pandemic. 
2. The results show that annotators who receive the same instances in an optimized order require significantly less annotation time while retaining a high annotation quality. 
",3
NE5B69XTPI25X7F,460,920,Domain Expert,"This dataset is about misconceptions about Covid-19, e.g. that Ginger Ale can cure it. Annotators were presented a tweet that mentioned such a misconception and were asked to select the most fitting category from a list of 4. Do you think that is a good task to evaluate on? 
 Facts: 
1. Finally, a user study is conducted with 40 voluntary participants who are asked to identify the most fitting misconception for English tweets about the Covid-19 pandemic.
",5
NE5B69XTPI25X7F,460,920,Domain Expert,"We sort by difficulty where difficulty comes either from heuristics like readability or masked language model score or learn to regress annotation times. Do you think annotation time is a good proxy for difficulty?
 Facts: 
1. We instantiate AC with an ""easy-instancesfirst"" strategy and evaluate heuristic and interactively trained estimators on three English datasets that provide annotation time which we use as an approximation of the annotation difficulty for evaluation.
",7
NE5B69XTPI25X7F,460,920,Domain Expert,"The annotation quality stayed mostly the same on a high level for all groups, we just measured improvement in annotation time. Do you have any more question?
 Facts: 
1. The results show that annotators who receive the same instances in an optimized order require significantly less annotation time while retaining a high annotation quality.
",9
FK5UAVFJSESCG5X2IL,461,921,Proponent,"Hello, could you please tell me what is Annotation Curricula?",0
FK5UAVFJSESCG5X2IL,461,921,Proponent,Sounds good but I'm not sure. What kind of task does it use for?,2
FK5UAVFJSESCG5X2IL,461,921,Proponent,Sure tell me more about that.,4
FK5UAVFJSESCG5X2IL,461,921,Proponent,That's excellent. So how do you measure annotation quality?,6
FK5UAVFJSESCG5X2IL,461,921,Proponent,"Yes. And you also said you reduced annotation time, what's the baseline you compare to?",8
FK5UAVFJSESCG5X2IL,461,921,Proponent,"One last question, how many time did you reduce?",10
NE5B69XTPI25X7F,461,922,Domain Expert,"Annotation curricula mean that we sort the instances to be annotated by their difficulty to gradually introduce annotators to the task and data. Do you think that is a good idea?
 Facts: 
1. The goal is to gradually introduce annotators into the task by ordering instances that are annotated according to a learning curriculum.
",1
NE5B69XTPI25X7F,461,922,Domain Expert,"We use it to speed up annotation or sentence and paragraph level annotation tasks, e.g. POS, NER or sentence classification. We also conduct a user study for that. Do you want to hear more about the user study?
 Facts: 
1. this work formalizes annotation curricula for sentence-and paragraph-level annotation tasks
",3
NE5B69XTPI25X7F,461,922,Domain Expert,"We conduct a user study to test wheter annotation curricula work. The data is about selecting the most fitting misconception about Covid-19 from a list. We show that using our method significantly reduces annotation time while not hurting annotation quality. 
 Facts: 
1. Finally, a user study is conducted with 40 voluntary participants who are asked to identify the most fitting misconception for English tweets about the Covid-19 pandemic. 
",5
NE5B69XTPI25X7F,461,922,Domain Expert,"We have the gold labels, so we compute accuracy. Does this sound reasonable?
 Facts: 
1. The results show that annotators who receive the same instances in an optimized order require significantly less annotation time while retaining a high annotation quality. 
",7
NE5B69XTPI25X7F,461,922,Domain Expert,"Our user study has 40 participants some get annotation curriula and others get random orders. We also have a warmup phase with a fixed order that is the same for all groups. Do you have any questions left?
 Facts: 
1. Finally, a user study is conducted with 40 voluntary participants who are asked to identify the most fitting misconception for English tweets about the Covid-19 pandemic.
2. The results show that using a simple heuristic to order instances can already significantly reduce the total annotation time while preserving a high annotation quality. 
",9
NE5B69XTPI25X7F,461,922,Domain Expert,"We were able to reduce the time by around 20% when using gold order.
 Facts: 
1.  The results show that annotators who receive the same instances in an optimized order require significantly less annotation time while retaining a high annotation quality. 
",11
1OTOYRFX5WFOF1T,462,923,Proponent,What do you mean with low resource domain?,0
1OTOYRFX5WFOF1T,462,923,Proponent,"Interesting, I agree. So how does this approach work?",2
1OTOYRFX5WFOF1T,462,923,Proponent,"Can you provide a more specific answer, like what algorithms are used and how the support comes in? ",4
1OTOYRFX5WFOF1T,462,923,Proponent,Only partly. Are the spans identified by the model as well or by the user? ,6
1OTOYRFX5WFOF1T,462,923,Proponent,so the input is the selected span and the model provides a ranking for the labels?,8
1OTOYRFX5WFOF1T,462,923,Proponent,Sounds promising! So how well do the models perform?,10
1OTOYRFX5WFOF1T,462,923,Proponent,"It depends, improvement of 35% compared to what baseline?",12
1OTOYRFX5WFOF1T,462,923,Proponent,Could you quantify if there was any bias introduced due to the recommendations?,14
1OTOYRFX5WFOF1T,462,923,Proponent,But couldn't it be that users were wrongly biased towards what the model suggested?,16
NE5B69XTPI25X7F,462,924,Domain Expert,"We say low resource domains are domains were data is scare, e.g. because of the language or because of the content. In our case, that is old English texts. Is that what you also understand as low resource?
 Facts: 
1. Throughout this work, we focus on texts from digital humanities, to be more precise, texts written in Early Modern English texts, including poems, biographies, novels as well as legal documents. 
",1
NE5B69XTPI25X7F,462,924,Domain Expert,"We need to annotate data as it does not exist yet. As annotating is annoying, we support users with machine learning algorithms during that. Do you want to hear more about the support our system can provide?
 Facts: 
1. For this initial data creation step, we developed a novel Human-In-The-Loop (HITL) annotation approach.
2. We present a generic, KB-agnostic annotation approach for low-resource settings and provide a ready-to-use implementation so that researchers can easily annotate data for their use cases.
",3
NE5B69XTPI25X7F,462,924,Domain Expert,"We help users to find spans that contain named entities and we help them to select the right one from the knowledge base search by reranking. Models are trained interactively in the loop. Does this clarify things?
 Facts: 
1. We therefore present a novel domain-agnostic Human-In-The-Loop annotation approach: 
2. we use recommenders that suggest potential concepts and adaptive candidate ranking, thereby speeding up the overall annotation process and making it less tedious for users.
",5
NE5B69XTPI25X7F,462,924,Domain Expert,"The annotator is still in charge and needs to acutally select spans, the machine learning models are just there to give suggestions.
 Facts: 
1. we use recommenders that suggest potential concepts and adaptive candidate ranking
2. we therefore add interactive machine learning annotation support that helps the user find entities in the text
",7
NE5B69XTPI25X7F,462,924,Domain Expert,"For the reranking part, the user selects a span and then searches for the right entity. These are both used as inputs for the reranking.
 Facts: 
1. e use recommenders that suggest potential concepts and adaptive candidate ranking
2. we therefore add interactive machine learning annotation support that helps the user find entities in the text and select the correct knowledge base entries for them
",9
NE5B69XTPI25X7F,462,924,Domain Expert,"Using these in a user study, we measured an annotation time improvement of up to 35%. Do you think this is useful?
 Facts: 
1. We show that statistical machine learning models can be used in an interactive entity linking setting to improve annotation speed by over 35%.
",11
NE5B69XTPI25X7F,462,924,Domain Expert,"To not using annotation support. Do you have any more questions?
 Facts:
1. In a user study, the annotation speed improves by 35 % compared to annotating without interactive support; users report that they strongly prefer our system.",13
NE5B69XTPI25X7F,462,924,Domain Expert,"That we did not measure.
 Facts: 
1. In a user study, the annotation speed improves by 35 % compared to annotating without interactive support; users report that they strongly prefer our system.
",15
NE5B69XTPI25X7F,462,924,Domain Expert,"The model suggest spans, but it does only rerank the candidates, so while it could bias I do not think that it did much
 Facts: 
1. To improve annotation speed and quality, we therefore add interactive machine learning annotation support that helps the user find entities in the text and select the correct knowledge base entries for them. 
",17
